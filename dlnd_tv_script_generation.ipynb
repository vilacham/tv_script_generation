{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Script Generation\n",
    "In this project, you'll generate your own [Simpsons](https://en.wikipedia.org/wiki/The_Simpsons) TV scripts using RNNs.  You'll be using part of the [Simpsons dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data) of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at [Moe's Tavern](https://simpsonswiki.com/wiki/Moe's_Tavern).\n",
    "## Get the Data\n",
    "The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like \"Moe's Cavern\", \"Flaming Moe's\", \"Uncle Moe's Family Feed-Bag\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "\n",
    "data_dir = './data/simpsons/moes_tavern_lines.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Ignore notice, since we don't use it for analysing the data\n",
    "text = text[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Play around with `view_sentence_range` to view different parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 11492\n",
      "Number of scenes: 262\n",
      "Average number of sentences in each scene: 15.248091603053435\n",
      "Number of lines: 4257\n",
      "Average number of words in each line: 11.50434578341555\n",
      "\n",
      "The sentences 0 to 10:\n",
      "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
      "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
      "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
      "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
      "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
      "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
      "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n",
      "Barney_Gumble: Yeah, you should only drink to enhance your social skills.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocessing Functions\n",
    "The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following tuple `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # Import\n",
    "    from collections import Counter\n",
    "    \n",
    "    # Extract words from text and sort them\n",
    "    words_count = Counter(text)\n",
    "    vocab = sorted(words_count, key=str.lower)\n",
    "    \n",
    "    # Create lookup tables (dicts)\n",
    "    vocab_to_int = {word: i for i, word in enumerate(vocab)}\n",
    "    int_to_vocab = {i: word for i, word in enumerate(vocab)}\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word \"bye\" and \"bye!\".\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( . )\n",
    "- Comma ( , )\n",
    "- Quotation Mark ( \" )\n",
    "- Semicolon ( ; )\n",
    "- Exclamation mark ( ! )\n",
    "- Question mark ( ? )\n",
    "- Left Parentheses ( ( )\n",
    "- Right Parentheses ( ) )\n",
    "- Dash ( -- )\n",
    "- Return ( \\n )\n",
    "\n",
    "This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and \n",
    "    the value is the token\n",
    "    \"\"\"\n",
    "    # Define keys and values\n",
    "    keys = ['.', ',', '\"', ';', '!', '?', '(', ')', '--', '\\n']\n",
    "    values = ['||period||', '||comma||', '||quotation_mark||', \n",
    "              '||semicolon||', '||exclamation_mark||', \n",
    "              '||question_mark||', '||left_parentheses||', \n",
    "              '||right_parentheses||', '||dash||', '||return||']\n",
    "    \n",
    "    # Create dict\n",
    "    punctuation_dict = {key: value for key, value in zip(keys, values)}\n",
    "    return punctuation_dict\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the data and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "You'll build the components necessary to build a RNN by implementing the following functions below:\n",
    "- get_inputs\n",
    "- get_init_cell\n",
    "- get_embed\n",
    "- build_rnn\n",
    "- build_nn\n",
    "- get_batches\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.9.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.3'), 'Please use TensorFlow version 1.3 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input\n",
    "Implement the `get_inputs()` function to create TF Placeholders for the Neural Network.  It should create the following placeholders:\n",
    "- Input text placeholder named \"input\" using the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) `name` parameter.\n",
    "- Targets placeholder\n",
    "- Learning Rate placeholder\n",
    "\n",
    "Return the placeholders in the following tuple `(Input, Targets, LearningRate)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    # Create placeholders\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    return (inputs, targets, learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_inputs(get_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RNN Cell and Initialize\n",
    "Stack one or more [`BasicLSTMCells`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) in a [`MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell).\n",
    "- The Rnn size should be set using `rnn_size`\n",
    "- Initalize Cell State using the MultiRNNCell's [`zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state) function\n",
    "    - Apply the name \"initial_state\" to the initial state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the cell and initial state in the following tuple `(Cell, InitialState)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_init_cell(batch_size, rnn_size):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # Build the LSTM cell\n",
    "    def build_cell(lstm_size):\n",
    "        # Use a basic LSTM cell\n",
    "        lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "        \n",
    "        # Add dropout to the cell outputs (keep_prob = 0.5)\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=0.5)\n",
    "        \n",
    "        return drop\n",
    "    \n",
    "    # Stack two LSTM layers for deep learning\n",
    "    num_layers = 2\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([build_cell(rnn_size) \n",
    "                                        for _ in range(num_layers)])\n",
    "    \n",
    "    # Initialize cell state\n",
    "    initial_state = tf.identity(cell.zero_state(batch_size, tf.float32), \n",
    "                                name='initial_state')\n",
    "    \n",
    "    return (cell, initial_state)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_init_cell(get_init_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding\n",
    "Apply embedding to `input_data` using TensorFlow.  Return the embedded sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    # Create embedding\n",
    "    embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), \n",
    "                                              -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    \n",
    "    return embed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_embed(get_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build RNN\n",
    "You created a RNN Cell in the `get_init_cell()` function.  Time to use the cell to create a RNN.\n",
    "- Build the RNN using the [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)\n",
    " - Apply the name \"final_state\" to the final state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the outputs and final_state state in the following tuple `(Outputs, FinalState)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    # Create RNN\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, \n",
    "                                             dtype=tf.float32)\n",
    "    \n",
    "    # Define final state\n",
    "    final_state = tf.identity(final_state, name='final_state')\n",
    "    \n",
    "    return (outputs, final_state)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_rnn(build_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network\n",
    "Apply the functions you implemented above to:\n",
    "- Apply embedding to `input_data` using your `get_embed(input_data, vocab_size, embed_dim)` function.\n",
    "- Build RNN using `cell` and your `build_rnn(cell, inputs)` function.\n",
    "- Apply a fully connected layer with a linear activation and `vocab_size` as the number of outputs.\n",
    "\n",
    "Return the logits and final state in the following tuple (Logits, FinalState) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    # Apply embedding\n",
    "    embed = get_embed(input_data, vocab_size, embed_dim)\n",
    "    \n",
    "    # Build RNN\n",
    "    outputs, final_state = build_rnn(cell, embed)\n",
    "    \n",
    "    # Fully connected layer with linear activation\n",
    "    logits = tf.contrib.layers.fully_connected(outputs, vocab_size, \n",
    "                                               weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                                               activation_fn=None)\n",
    "    \n",
    "    return (logits, final_state)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_nn(build_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batches\n",
    "Implement `get_batches` to create batches of input and targets using `int_text`.  The batches should be a Numpy array with the shape `(number of batches, 2, batch size, sequence length)`. Each batch contains two elements:\n",
    "- The first element is a single batch of **input** with the shape `[batch size, sequence length]`\n",
    "- The second element is a single batch of **targets** with the shape `[batch size, sequence length]`\n",
    "\n",
    "If you can't fill the last batch with enough data, drop the last batch.\n",
    "\n",
    "For example, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 3, 2)` would return a Numpy array of the following:\n",
    "```\n",
    "[\n",
    "  # First Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 1  2], [ 7  8], [13 14]]\n",
    "    # Batch of targets\n",
    "    [[ 2  3], [ 8  9], [14 15]]\n",
    "  ]\n",
    "\n",
    "  # Second Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 3  4], [ 9 10], [15 16]]\n",
    "    # Batch of targets\n",
    "    [[ 4  5], [10 11], [16 17]]\n",
    "  ]\n",
    "\n",
    "  # Third Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 5  6], [11 12], [17 18]]\n",
    "    # Batch of targets\n",
    "    [[ 6  7], [12 13], [18  1]]\n",
    "  ]\n",
    "]\n",
    "```\n",
    "\n",
    "Notice that the last target value in the last batch is the first input value of the first batch. In this case, `1`. This is a common technique used when creating sequence batches, although it is rather unintuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # Calculate number of elements per batch and number of batches\n",
    "    per_batch = batch_size * seq_length\n",
    "    n_batches = len(int_text) // per_batch\n",
    "    \n",
    "    # Limit size of arrays in order to have only full batches\n",
    "    x = np.array(int_text[:(n_batches * per_batch)])\n",
    "    y = np.array(int_text[1:(n_batches * per_batch + 1)])\n",
    "    \n",
    "    # Define last target value as the first input value \n",
    "    y[-1] = x[0]\n",
    "    \n",
    "    # Reshape both arrays\n",
    "    x = x.reshape(batch_size, -1)\n",
    "    y = y.reshape(batch_size, -1)\n",
    "    \n",
    "    # Split arrays\n",
    "    x = np.split(x, n_batches, 1)\n",
    "    y = np.split(y, n_batches, 1)\n",
    "    \n",
    "    batches = np.array(list(zip(x, y)))\n",
    "    return batches\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_batches(get_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "\n",
    "- Set `num_epochs` to the number of epochs.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `rnn_size` to the size of the RNNs.\n",
    "- Set `embed_dim` to the size of the embedding.\n",
    "- Set `seq_length` to the length of sequence.\n",
    "- Set `learning_rate` to the learning rate.\n",
    "- Set `show_every_n_batches` to the number of batches the neural network should print progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 1000\n",
    "# Batch Size\n",
    "batch_size = 69\n",
    "# RNN Size\n",
    "rnn_size = 1024\n",
    "# Embedding Dimension Size\n",
    "embed_dim = 3000\n",
    "# Sequence Length\n",
    "seq_length = 10\n",
    "# Learning Rate\n",
    "learning_rate = 0.00001\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 25\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Graph\n",
    "Build the graph using the neural network you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    input_text, targets, lr = get_inputs()\n",
    "    input_data_shape = tf.shape(input_text)\n",
    "    cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
    "    logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size, embed_dim)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    probs = tf.nn.softmax(logits, name='probs')\n",
    "\n",
    "    # Loss function\n",
    "    cost = seq2seq.sequence_loss(\n",
    "        logits,\n",
    "        targets,\n",
    "        tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "    # Gradient Clipping\n",
    "    gradients = optimizer.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "    train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the [forums](https://discussions.udacity.com/) to see if anyone is having the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/100   train_loss = 8.841\n",
      "Epoch   0 Batch   25/100   train_loss = 8.698\n",
      "Epoch   0 Batch   50/100   train_loss = 8.457\n",
      "Epoch   0 Batch   75/100   train_loss = 8.379\n",
      "Epoch   1 Batch    0/100   train_loss = 8.039\n",
      "Epoch   1 Batch   25/100   train_loss = 7.683\n",
      "Epoch   1 Batch   50/100   train_loss = 7.412\n",
      "Epoch   1 Batch   75/100   train_loss = 7.654\n",
      "Epoch   2 Batch    0/100   train_loss = 7.417\n",
      "Epoch   2 Batch   25/100   train_loss = 7.173\n",
      "Epoch   2 Batch   50/100   train_loss = 6.939\n",
      "Epoch   2 Batch   75/100   train_loss = 7.217\n",
      "Epoch   3 Batch    0/100   train_loss = 7.136\n",
      "Epoch   3 Batch   25/100   train_loss = 6.873\n",
      "Epoch   3 Batch   50/100   train_loss = 6.608\n",
      "Epoch   3 Batch   75/100   train_loss = 6.989\n",
      "Epoch   4 Batch    0/100   train_loss = 6.861\n",
      "Epoch   4 Batch   25/100   train_loss = 6.654\n",
      "Epoch   4 Batch   50/100   train_loss = 6.423\n",
      "Epoch   4 Batch   75/100   train_loss = 6.776\n",
      "Epoch   5 Batch    0/100   train_loss = 6.744\n",
      "Epoch   5 Batch   25/100   train_loss = 6.475\n",
      "Epoch   5 Batch   50/100   train_loss = 6.275\n",
      "Epoch   5 Batch   75/100   train_loss = 6.662\n",
      "Epoch   6 Batch    0/100   train_loss = 6.664\n",
      "Epoch   6 Batch   25/100   train_loss = 6.363\n",
      "Epoch   6 Batch   50/100   train_loss = 6.172\n",
      "Epoch   6 Batch   75/100   train_loss = 6.553\n",
      "Epoch   7 Batch    0/100   train_loss = 6.541\n",
      "Epoch   7 Batch   25/100   train_loss = 6.261\n",
      "Epoch   7 Batch   50/100   train_loss = 6.071\n",
      "Epoch   7 Batch   75/100   train_loss = 6.417\n",
      "Epoch   8 Batch    0/100   train_loss = 6.430\n",
      "Epoch   8 Batch   25/100   train_loss = 6.172\n",
      "Epoch   8 Batch   50/100   train_loss = 5.950\n",
      "Epoch   8 Batch   75/100   train_loss = 6.354\n",
      "Epoch   9 Batch    0/100   train_loss = 6.348\n",
      "Epoch   9 Batch   25/100   train_loss = 6.107\n",
      "Epoch   9 Batch   50/100   train_loss = 5.925\n",
      "Epoch   9 Batch   75/100   train_loss = 6.290\n",
      "Epoch  10 Batch    0/100   train_loss = 6.262\n",
      "Epoch  10 Batch   25/100   train_loss = 6.069\n",
      "Epoch  10 Batch   50/100   train_loss = 5.907\n",
      "Epoch  10 Batch   75/100   train_loss = 6.301\n",
      "Epoch  11 Batch    0/100   train_loss = 6.184\n",
      "Epoch  11 Batch   25/100   train_loss = 5.974\n",
      "Epoch  11 Batch   50/100   train_loss = 5.819\n",
      "Epoch  11 Batch   75/100   train_loss = 6.181\n",
      "Epoch  12 Batch    0/100   train_loss = 6.177\n",
      "Epoch  12 Batch   25/100   train_loss = 5.944\n",
      "Epoch  12 Batch   50/100   train_loss = 5.786\n",
      "Epoch  12 Batch   75/100   train_loss = 6.152\n",
      "Epoch  13 Batch    0/100   train_loss = 6.129\n",
      "Epoch  13 Batch   25/100   train_loss = 5.863\n",
      "Epoch  13 Batch   50/100   train_loss = 5.730\n",
      "Epoch  13 Batch   75/100   train_loss = 6.104\n",
      "Epoch  14 Batch    0/100   train_loss = 6.054\n",
      "Epoch  14 Batch   25/100   train_loss = 5.782\n",
      "Epoch  14 Batch   50/100   train_loss = 5.637\n",
      "Epoch  14 Batch   75/100   train_loss = 6.027\n",
      "Epoch  15 Batch    0/100   train_loss = 6.038\n",
      "Epoch  15 Batch   25/100   train_loss = 5.818\n",
      "Epoch  15 Batch   50/100   train_loss = 5.604\n",
      "Epoch  15 Batch   75/100   train_loss = 5.992\n",
      "Epoch  16 Batch    0/100   train_loss = 6.041\n",
      "Epoch  16 Batch   25/100   train_loss = 5.747\n",
      "Epoch  16 Batch   50/100   train_loss = 5.577\n",
      "Epoch  16 Batch   75/100   train_loss = 5.990\n",
      "Epoch  17 Batch    0/100   train_loss = 5.971\n",
      "Epoch  17 Batch   25/100   train_loss = 5.723\n",
      "Epoch  17 Batch   50/100   train_loss = 5.565\n",
      "Epoch  17 Batch   75/100   train_loss = 5.952\n",
      "Epoch  18 Batch    0/100   train_loss = 5.915\n",
      "Epoch  18 Batch   25/100   train_loss = 5.652\n",
      "Epoch  18 Batch   50/100   train_loss = 5.459\n",
      "Epoch  18 Batch   75/100   train_loss = 5.916\n",
      "Epoch  19 Batch    0/100   train_loss = 5.898\n",
      "Epoch  19 Batch   25/100   train_loss = 5.687\n",
      "Epoch  19 Batch   50/100   train_loss = 5.489\n",
      "Epoch  19 Batch   75/100   train_loss = 5.833\n",
      "Epoch  20 Batch    0/100   train_loss = 5.859\n",
      "Epoch  20 Batch   25/100   train_loss = 5.628\n",
      "Epoch  20 Batch   50/100   train_loss = 5.413\n",
      "Epoch  20 Batch   75/100   train_loss = 5.836\n",
      "Epoch  21 Batch    0/100   train_loss = 5.817\n",
      "Epoch  21 Batch   25/100   train_loss = 5.601\n",
      "Epoch  21 Batch   50/100   train_loss = 5.462\n",
      "Epoch  21 Batch   75/100   train_loss = 5.873\n",
      "Epoch  22 Batch    0/100   train_loss = 5.777\n",
      "Epoch  22 Batch   25/100   train_loss = 5.593\n",
      "Epoch  22 Batch   50/100   train_loss = 5.434\n",
      "Epoch  22 Batch   75/100   train_loss = 5.777\n",
      "Epoch  23 Batch    0/100   train_loss = 5.757\n",
      "Epoch  23 Batch   25/100   train_loss = 5.513\n",
      "Epoch  23 Batch   50/100   train_loss = 5.381\n",
      "Epoch  23 Batch   75/100   train_loss = 5.813\n",
      "Epoch  24 Batch    0/100   train_loss = 5.747\n",
      "Epoch  24 Batch   25/100   train_loss = 5.453\n",
      "Epoch  24 Batch   50/100   train_loss = 5.393\n",
      "Epoch  24 Batch   75/100   train_loss = 5.749\n",
      "Epoch  25 Batch    0/100   train_loss = 5.693\n",
      "Epoch  25 Batch   25/100   train_loss = 5.492\n",
      "Epoch  25 Batch   50/100   train_loss = 5.359\n",
      "Epoch  25 Batch   75/100   train_loss = 5.707\n",
      "Epoch  26 Batch    0/100   train_loss = 5.698\n",
      "Epoch  26 Batch   25/100   train_loss = 5.467\n",
      "Epoch  26 Batch   50/100   train_loss = 5.337\n",
      "Epoch  26 Batch   75/100   train_loss = 5.698\n",
      "Epoch  27 Batch    0/100   train_loss = 5.694\n",
      "Epoch  27 Batch   25/100   train_loss = 5.437\n",
      "Epoch  27 Batch   50/100   train_loss = 5.338\n",
      "Epoch  27 Batch   75/100   train_loss = 5.701\n",
      "Epoch  28 Batch    0/100   train_loss = 5.608\n",
      "Epoch  28 Batch   25/100   train_loss = 5.379\n",
      "Epoch  28 Batch   50/100   train_loss = 5.300\n",
      "Epoch  28 Batch   75/100   train_loss = 5.644\n",
      "Epoch  29 Batch    0/100   train_loss = 5.595\n",
      "Epoch  29 Batch   25/100   train_loss = 5.383\n",
      "Epoch  29 Batch   50/100   train_loss = 5.262\n",
      "Epoch  29 Batch   75/100   train_loss = 5.656\n",
      "Epoch  30 Batch    0/100   train_loss = 5.547\n",
      "Epoch  30 Batch   25/100   train_loss = 5.369\n",
      "Epoch  30 Batch   50/100   train_loss = 5.220\n",
      "Epoch  30 Batch   75/100   train_loss = 5.590\n",
      "Epoch  31 Batch    0/100   train_loss = 5.500\n",
      "Epoch  31 Batch   25/100   train_loss = 5.380\n",
      "Epoch  31 Batch   50/100   train_loss = 5.221\n",
      "Epoch  31 Batch   75/100   train_loss = 5.528\n",
      "Epoch  32 Batch    0/100   train_loss = 5.486\n",
      "Epoch  32 Batch   25/100   train_loss = 5.320\n",
      "Epoch  32 Batch   50/100   train_loss = 5.237\n",
      "Epoch  32 Batch   75/100   train_loss = 5.569\n",
      "Epoch  33 Batch    0/100   train_loss = 5.404\n",
      "Epoch  33 Batch   25/100   train_loss = 5.287\n",
      "Epoch  33 Batch   50/100   train_loss = 5.162\n",
      "Epoch  33 Batch   75/100   train_loss = 5.567\n",
      "Epoch  34 Batch    0/100   train_loss = 5.488\n",
      "Epoch  34 Batch   25/100   train_loss = 5.326\n",
      "Epoch  34 Batch   50/100   train_loss = 5.174\n",
      "Epoch  34 Batch   75/100   train_loss = 5.498\n",
      "Epoch  35 Batch    0/100   train_loss = 5.460\n",
      "Epoch  35 Batch   25/100   train_loss = 5.270\n",
      "Epoch  35 Batch   50/100   train_loss = 5.153\n",
      "Epoch  35 Batch   75/100   train_loss = 5.493\n",
      "Epoch  36 Batch    0/100   train_loss = 5.425\n",
      "Epoch  36 Batch   25/100   train_loss = 5.278\n",
      "Epoch  36 Batch   50/100   train_loss = 5.082\n",
      "Epoch  36 Batch   75/100   train_loss = 5.460\n",
      "Epoch  37 Batch    0/100   train_loss = 5.389\n",
      "Epoch  37 Batch   25/100   train_loss = 5.263\n",
      "Epoch  37 Batch   50/100   train_loss = 5.089\n",
      "Epoch  37 Batch   75/100   train_loss = 5.415\n",
      "Epoch  38 Batch    0/100   train_loss = 5.343\n",
      "Epoch  38 Batch   25/100   train_loss = 5.221\n",
      "Epoch  38 Batch   50/100   train_loss = 5.079\n",
      "Epoch  38 Batch   75/100   train_loss = 5.397\n",
      "Epoch  39 Batch    0/100   train_loss = 5.316\n",
      "Epoch  39 Batch   25/100   train_loss = 5.192\n",
      "Epoch  39 Batch   50/100   train_loss = 5.060\n",
      "Epoch  39 Batch   75/100   train_loss = 5.367\n",
      "Epoch  40 Batch    0/100   train_loss = 5.362\n",
      "Epoch  40 Batch   25/100   train_loss = 5.200\n",
      "Epoch  40 Batch   50/100   train_loss = 5.123\n",
      "Epoch  40 Batch   75/100   train_loss = 5.379\n",
      "Epoch  41 Batch    0/100   train_loss = 5.370\n",
      "Epoch  41 Batch   25/100   train_loss = 5.129\n",
      "Epoch  41 Batch   50/100   train_loss = 5.047\n",
      "Epoch  41 Batch   75/100   train_loss = 5.347\n",
      "Epoch  42 Batch    0/100   train_loss = 5.243\n",
      "Epoch  42 Batch   25/100   train_loss = 5.188\n",
      "Epoch  42 Batch   50/100   train_loss = 5.066\n",
      "Epoch  42 Batch   75/100   train_loss = 5.337\n",
      "Epoch  43 Batch    0/100   train_loss = 5.257\n",
      "Epoch  43 Batch   25/100   train_loss = 5.167\n",
      "Epoch  43 Batch   50/100   train_loss = 4.946\n",
      "Epoch  43 Batch   75/100   train_loss = 5.337\n",
      "Epoch  44 Batch    0/100   train_loss = 5.200\n",
      "Epoch  44 Batch   25/100   train_loss = 5.139\n",
      "Epoch  44 Batch   50/100   train_loss = 4.954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  44 Batch   75/100   train_loss = 5.302\n",
      "Epoch  45 Batch    0/100   train_loss = 5.255\n",
      "Epoch  45 Batch   25/100   train_loss = 5.130\n",
      "Epoch  45 Batch   50/100   train_loss = 4.936\n",
      "Epoch  45 Batch   75/100   train_loss = 5.312\n",
      "Epoch  46 Batch    0/100   train_loss = 5.190\n",
      "Epoch  46 Batch   25/100   train_loss = 5.075\n",
      "Epoch  46 Batch   50/100   train_loss = 4.973\n",
      "Epoch  46 Batch   75/100   train_loss = 5.291\n",
      "Epoch  47 Batch    0/100   train_loss = 5.232\n",
      "Epoch  47 Batch   25/100   train_loss = 5.101\n",
      "Epoch  47 Batch   50/100   train_loss = 4.915\n",
      "Epoch  47 Batch   75/100   train_loss = 5.247\n",
      "Epoch  48 Batch    0/100   train_loss = 5.138\n",
      "Epoch  48 Batch   25/100   train_loss = 5.013\n",
      "Epoch  48 Batch   50/100   train_loss = 4.887\n",
      "Epoch  48 Batch   75/100   train_loss = 5.191\n",
      "Epoch  49 Batch    0/100   train_loss = 5.125\n",
      "Epoch  49 Batch   25/100   train_loss = 5.020\n",
      "Epoch  49 Batch   50/100   train_loss = 4.884\n",
      "Epoch  49 Batch   75/100   train_loss = 5.191\n",
      "Epoch  50 Batch    0/100   train_loss = 5.090\n",
      "Epoch  50 Batch   25/100   train_loss = 5.021\n",
      "Epoch  50 Batch   50/100   train_loss = 4.857\n",
      "Epoch  50 Batch   75/100   train_loss = 5.211\n",
      "Epoch  51 Batch    0/100   train_loss = 5.091\n",
      "Epoch  51 Batch   25/100   train_loss = 4.952\n",
      "Epoch  51 Batch   50/100   train_loss = 4.876\n",
      "Epoch  51 Batch   75/100   train_loss = 5.130\n",
      "Epoch  52 Batch    0/100   train_loss = 5.061\n",
      "Epoch  52 Batch   25/100   train_loss = 4.940\n",
      "Epoch  52 Batch   50/100   train_loss = 4.838\n",
      "Epoch  52 Batch   75/100   train_loss = 5.138\n",
      "Epoch  53 Batch    0/100   train_loss = 4.983\n",
      "Epoch  53 Batch   25/100   train_loss = 4.987\n",
      "Epoch  53 Batch   50/100   train_loss = 4.847\n",
      "Epoch  53 Batch   75/100   train_loss = 5.154\n",
      "Epoch  54 Batch    0/100   train_loss = 5.034\n",
      "Epoch  54 Batch   25/100   train_loss = 4.957\n",
      "Epoch  54 Batch   50/100   train_loss = 4.793\n",
      "Epoch  54 Batch   75/100   train_loss = 5.100\n",
      "Epoch  55 Batch    0/100   train_loss = 5.005\n",
      "Epoch  55 Batch   25/100   train_loss = 4.945\n",
      "Epoch  55 Batch   50/100   train_loss = 4.778\n",
      "Epoch  55 Batch   75/100   train_loss = 5.119\n",
      "Epoch  56 Batch    0/100   train_loss = 5.017\n",
      "Epoch  56 Batch   25/100   train_loss = 4.940\n",
      "Epoch  56 Batch   50/100   train_loss = 4.765\n",
      "Epoch  56 Batch   75/100   train_loss = 5.078\n",
      "Epoch  57 Batch    0/100   train_loss = 4.976\n",
      "Epoch  57 Batch   25/100   train_loss = 4.886\n",
      "Epoch  57 Batch   50/100   train_loss = 4.713\n",
      "Epoch  57 Batch   75/100   train_loss = 5.108\n",
      "Epoch  58 Batch    0/100   train_loss = 4.935\n",
      "Epoch  58 Batch   25/100   train_loss = 4.888\n",
      "Epoch  58 Batch   50/100   train_loss = 4.685\n",
      "Epoch  58 Batch   75/100   train_loss = 5.021\n",
      "Epoch  59 Batch    0/100   train_loss = 4.958\n",
      "Epoch  59 Batch   25/100   train_loss = 4.849\n",
      "Epoch  59 Batch   50/100   train_loss = 4.698\n",
      "Epoch  59 Batch   75/100   train_loss = 5.003\n",
      "Epoch  60 Batch    0/100   train_loss = 4.949\n",
      "Epoch  60 Batch   25/100   train_loss = 4.833\n",
      "Epoch  60 Batch   50/100   train_loss = 4.701\n",
      "Epoch  60 Batch   75/100   train_loss = 5.024\n",
      "Epoch  61 Batch    0/100   train_loss = 4.926\n",
      "Epoch  61 Batch   25/100   train_loss = 4.858\n",
      "Epoch  61 Batch   50/100   train_loss = 4.649\n",
      "Epoch  61 Batch   75/100   train_loss = 4.999\n",
      "Epoch  62 Batch    0/100   train_loss = 4.944\n",
      "Epoch  62 Batch   25/100   train_loss = 4.832\n",
      "Epoch  62 Batch   50/100   train_loss = 4.656\n",
      "Epoch  62 Batch   75/100   train_loss = 4.918\n",
      "Epoch  63 Batch    0/100   train_loss = 4.877\n",
      "Epoch  63 Batch   25/100   train_loss = 4.773\n",
      "Epoch  63 Batch   50/100   train_loss = 4.669\n",
      "Epoch  63 Batch   75/100   train_loss = 4.992\n",
      "Epoch  64 Batch    0/100   train_loss = 4.848\n",
      "Epoch  64 Batch   25/100   train_loss = 4.803\n",
      "Epoch  64 Batch   50/100   train_loss = 4.650\n",
      "Epoch  64 Batch   75/100   train_loss = 4.936\n",
      "Epoch  65 Batch    0/100   train_loss = 4.823\n",
      "Epoch  65 Batch   25/100   train_loss = 4.813\n",
      "Epoch  65 Batch   50/100   train_loss = 4.632\n",
      "Epoch  65 Batch   75/100   train_loss = 4.936\n",
      "Epoch  66 Batch    0/100   train_loss = 4.844\n",
      "Epoch  66 Batch   25/100   train_loss = 4.713\n",
      "Epoch  66 Batch   50/100   train_loss = 4.602\n",
      "Epoch  66 Batch   75/100   train_loss = 4.904\n",
      "Epoch  67 Batch    0/100   train_loss = 4.808\n",
      "Epoch  67 Batch   25/100   train_loss = 4.709\n",
      "Epoch  67 Batch   50/100   train_loss = 4.574\n",
      "Epoch  67 Batch   75/100   train_loss = 4.879\n",
      "Epoch  68 Batch    0/100   train_loss = 4.792\n",
      "Epoch  68 Batch   25/100   train_loss = 4.717\n",
      "Epoch  68 Batch   50/100   train_loss = 4.516\n",
      "Epoch  68 Batch   75/100   train_loss = 4.810\n",
      "Epoch  69 Batch    0/100   train_loss = 4.794\n",
      "Epoch  69 Batch   25/100   train_loss = 4.695\n",
      "Epoch  69 Batch   50/100   train_loss = 4.577\n",
      "Epoch  69 Batch   75/100   train_loss = 4.789\n",
      "Epoch  70 Batch    0/100   train_loss = 4.743\n",
      "Epoch  70 Batch   25/100   train_loss = 4.627\n",
      "Epoch  70 Batch   50/100   train_loss = 4.506\n",
      "Epoch  70 Batch   75/100   train_loss = 4.812\n",
      "Epoch  71 Batch    0/100   train_loss = 4.704\n",
      "Epoch  71 Batch   25/100   train_loss = 4.671\n",
      "Epoch  71 Batch   50/100   train_loss = 4.548\n",
      "Epoch  71 Batch   75/100   train_loss = 4.798\n",
      "Epoch  72 Batch    0/100   train_loss = 4.707\n",
      "Epoch  72 Batch   25/100   train_loss = 4.656\n",
      "Epoch  72 Batch   50/100   train_loss = 4.488\n",
      "Epoch  72 Batch   75/100   train_loss = 4.834\n",
      "Epoch  73 Batch    0/100   train_loss = 4.667\n",
      "Epoch  73 Batch   25/100   train_loss = 4.677\n",
      "Epoch  73 Batch   50/100   train_loss = 4.473\n",
      "Epoch  73 Batch   75/100   train_loss = 4.840\n",
      "Epoch  74 Batch    0/100   train_loss = 4.654\n",
      "Epoch  74 Batch   25/100   train_loss = 4.583\n",
      "Epoch  74 Batch   50/100   train_loss = 4.444\n",
      "Epoch  74 Batch   75/100   train_loss = 4.732\n",
      "Epoch  75 Batch    0/100   train_loss = 4.619\n",
      "Epoch  75 Batch   25/100   train_loss = 4.641\n",
      "Epoch  75 Batch   50/100   train_loss = 4.452\n",
      "Epoch  75 Batch   75/100   train_loss = 4.718\n",
      "Epoch  76 Batch    0/100   train_loss = 4.577\n",
      "Epoch  76 Batch   25/100   train_loss = 4.583\n",
      "Epoch  76 Batch   50/100   train_loss = 4.453\n",
      "Epoch  76 Batch   75/100   train_loss = 4.679\n",
      "Epoch  77 Batch    0/100   train_loss = 4.581\n",
      "Epoch  77 Batch   25/100   train_loss = 4.597\n",
      "Epoch  77 Batch   50/100   train_loss = 4.416\n",
      "Epoch  77 Batch   75/100   train_loss = 4.764\n",
      "Epoch  78 Batch    0/100   train_loss = 4.599\n",
      "Epoch  78 Batch   25/100   train_loss = 4.622\n",
      "Epoch  78 Batch   50/100   train_loss = 4.418\n",
      "Epoch  78 Batch   75/100   train_loss = 4.645\n",
      "Epoch  79 Batch    0/100   train_loss = 4.527\n",
      "Epoch  79 Batch   25/100   train_loss = 4.523\n",
      "Epoch  79 Batch   50/100   train_loss = 4.375\n",
      "Epoch  79 Batch   75/100   train_loss = 4.702\n",
      "Epoch  80 Batch    0/100   train_loss = 4.491\n",
      "Epoch  80 Batch   25/100   train_loss = 4.506\n",
      "Epoch  80 Batch   50/100   train_loss = 4.380\n",
      "Epoch  80 Batch   75/100   train_loss = 4.637\n",
      "Epoch  81 Batch    0/100   train_loss = 4.532\n",
      "Epoch  81 Batch   25/100   train_loss = 4.533\n",
      "Epoch  81 Batch   50/100   train_loss = 4.388\n",
      "Epoch  81 Batch   75/100   train_loss = 4.598\n",
      "Epoch  82 Batch    0/100   train_loss = 4.483\n",
      "Epoch  82 Batch   25/100   train_loss = 4.522\n",
      "Epoch  82 Batch   50/100   train_loss = 4.306\n",
      "Epoch  82 Batch   75/100   train_loss = 4.577\n",
      "Epoch  83 Batch    0/100   train_loss = 4.455\n",
      "Epoch  83 Batch   25/100   train_loss = 4.495\n",
      "Epoch  83 Batch   50/100   train_loss = 4.318\n",
      "Epoch  83 Batch   75/100   train_loss = 4.621\n",
      "Epoch  84 Batch    0/100   train_loss = 4.459\n",
      "Epoch  84 Batch   25/100   train_loss = 4.458\n",
      "Epoch  84 Batch   50/100   train_loss = 4.300\n",
      "Epoch  84 Batch   75/100   train_loss = 4.512\n",
      "Epoch  85 Batch    0/100   train_loss = 4.433\n",
      "Epoch  85 Batch   25/100   train_loss = 4.483\n",
      "Epoch  85 Batch   50/100   train_loss = 4.241\n",
      "Epoch  85 Batch   75/100   train_loss = 4.574\n",
      "Epoch  86 Batch    0/100   train_loss = 4.486\n",
      "Epoch  86 Batch   25/100   train_loss = 4.439\n",
      "Epoch  86 Batch   50/100   train_loss = 4.319\n",
      "Epoch  86 Batch   75/100   train_loss = 4.537\n",
      "Epoch  87 Batch    0/100   train_loss = 4.455\n",
      "Epoch  87 Batch   25/100   train_loss = 4.408\n",
      "Epoch  87 Batch   50/100   train_loss = 4.232\n",
      "Epoch  87 Batch   75/100   train_loss = 4.533\n",
      "Epoch  88 Batch    0/100   train_loss = 4.399\n",
      "Epoch  88 Batch   25/100   train_loss = 4.441\n",
      "Epoch  88 Batch   50/100   train_loss = 4.210\n",
      "Epoch  88 Batch   75/100   train_loss = 4.511\n",
      "Epoch  89 Batch    0/100   train_loss = 4.375\n",
      "Epoch  89 Batch   25/100   train_loss = 4.387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  89 Batch   50/100   train_loss = 4.272\n",
      "Epoch  89 Batch   75/100   train_loss = 4.459\n",
      "Epoch  90 Batch    0/100   train_loss = 4.337\n",
      "Epoch  90 Batch   25/100   train_loss = 4.415\n",
      "Epoch  90 Batch   50/100   train_loss = 4.206\n",
      "Epoch  90 Batch   75/100   train_loss = 4.443\n",
      "Epoch  91 Batch    0/100   train_loss = 4.305\n",
      "Epoch  91 Batch   25/100   train_loss = 4.329\n",
      "Epoch  91 Batch   50/100   train_loss = 4.258\n",
      "Epoch  91 Batch   75/100   train_loss = 4.437\n",
      "Epoch  92 Batch    0/100   train_loss = 4.336\n",
      "Epoch  92 Batch   25/100   train_loss = 4.418\n",
      "Epoch  92 Batch   50/100   train_loss = 4.175\n",
      "Epoch  92 Batch   75/100   train_loss = 4.398\n",
      "Epoch  93 Batch    0/100   train_loss = 4.275\n",
      "Epoch  93 Batch   25/100   train_loss = 4.345\n",
      "Epoch  93 Batch   50/100   train_loss = 4.152\n",
      "Epoch  93 Batch   75/100   train_loss = 4.375\n",
      "Epoch  94 Batch    0/100   train_loss = 4.295\n",
      "Epoch  94 Batch   25/100   train_loss = 4.305\n",
      "Epoch  94 Batch   50/100   train_loss = 4.169\n",
      "Epoch  94 Batch   75/100   train_loss = 4.420\n",
      "Epoch  95 Batch    0/100   train_loss = 4.253\n",
      "Epoch  95 Batch   25/100   train_loss = 4.320\n",
      "Epoch  95 Batch   50/100   train_loss = 4.111\n",
      "Epoch  95 Batch   75/100   train_loss = 4.339\n",
      "Epoch  96 Batch    0/100   train_loss = 4.229\n",
      "Epoch  96 Batch   25/100   train_loss = 4.285\n",
      "Epoch  96 Batch   50/100   train_loss = 4.142\n",
      "Epoch  96 Batch   75/100   train_loss = 4.349\n",
      "Epoch  97 Batch    0/100   train_loss = 4.201\n",
      "Epoch  97 Batch   25/100   train_loss = 4.272\n",
      "Epoch  97 Batch   50/100   train_loss = 4.115\n",
      "Epoch  97 Batch   75/100   train_loss = 4.359\n",
      "Epoch  98 Batch    0/100   train_loss = 4.228\n",
      "Epoch  98 Batch   25/100   train_loss = 4.231\n",
      "Epoch  98 Batch   50/100   train_loss = 4.122\n",
      "Epoch  98 Batch   75/100   train_loss = 4.282\n",
      "Epoch  99 Batch    0/100   train_loss = 4.211\n",
      "Epoch  99 Batch   25/100   train_loss = 4.288\n",
      "Epoch  99 Batch   50/100   train_loss = 4.099\n",
      "Epoch  99 Batch   75/100   train_loss = 4.321\n",
      "Epoch 100 Batch    0/100   train_loss = 4.174\n",
      "Epoch 100 Batch   25/100   train_loss = 4.250\n",
      "Epoch 100 Batch   50/100   train_loss = 4.035\n",
      "Epoch 100 Batch   75/100   train_loss = 4.309\n",
      "Epoch 101 Batch    0/100   train_loss = 4.186\n",
      "Epoch 101 Batch   25/100   train_loss = 4.216\n",
      "Epoch 101 Batch   50/100   train_loss = 4.056\n",
      "Epoch 101 Batch   75/100   train_loss = 4.328\n",
      "Epoch 102 Batch    0/100   train_loss = 4.153\n",
      "Epoch 102 Batch   25/100   train_loss = 4.226\n",
      "Epoch 102 Batch   50/100   train_loss = 4.041\n",
      "Epoch 102 Batch   75/100   train_loss = 4.307\n",
      "Epoch 103 Batch    0/100   train_loss = 4.085\n",
      "Epoch 103 Batch   25/100   train_loss = 4.169\n",
      "Epoch 103 Batch   50/100   train_loss = 4.023\n",
      "Epoch 103 Batch   75/100   train_loss = 4.265\n",
      "Epoch 104 Batch    0/100   train_loss = 4.165\n",
      "Epoch 104 Batch   25/100   train_loss = 4.181\n",
      "Epoch 104 Batch   50/100   train_loss = 4.085\n",
      "Epoch 104 Batch   75/100   train_loss = 4.210\n",
      "Epoch 105 Batch    0/100   train_loss = 4.075\n",
      "Epoch 105 Batch   25/100   train_loss = 4.151\n",
      "Epoch 105 Batch   50/100   train_loss = 4.023\n",
      "Epoch 105 Batch   75/100   train_loss = 4.252\n",
      "Epoch 106 Batch    0/100   train_loss = 4.072\n",
      "Epoch 106 Batch   25/100   train_loss = 4.166\n",
      "Epoch 106 Batch   50/100   train_loss = 3.922\n",
      "Epoch 106 Batch   75/100   train_loss = 4.217\n",
      "Epoch 107 Batch    0/100   train_loss = 4.051\n",
      "Epoch 107 Batch   25/100   train_loss = 4.153\n",
      "Epoch 107 Batch   50/100   train_loss = 3.968\n",
      "Epoch 107 Batch   75/100   train_loss = 4.185\n",
      "Epoch 108 Batch    0/100   train_loss = 4.101\n",
      "Epoch 108 Batch   25/100   train_loss = 4.095\n",
      "Epoch 108 Batch   50/100   train_loss = 3.934\n",
      "Epoch 108 Batch   75/100   train_loss = 4.184\n",
      "Epoch 109 Batch    0/100   train_loss = 3.983\n",
      "Epoch 109 Batch   25/100   train_loss = 4.102\n",
      "Epoch 109 Batch   50/100   train_loss = 3.926\n",
      "Epoch 109 Batch   75/100   train_loss = 4.143\n",
      "Epoch 110 Batch    0/100   train_loss = 4.005\n",
      "Epoch 110 Batch   25/100   train_loss = 4.146\n",
      "Epoch 110 Batch   50/100   train_loss = 3.891\n",
      "Epoch 110 Batch   75/100   train_loss = 4.116\n",
      "Epoch 111 Batch    0/100   train_loss = 4.038\n",
      "Epoch 111 Batch   25/100   train_loss = 4.065\n",
      "Epoch 111 Batch   50/100   train_loss = 3.948\n",
      "Epoch 111 Batch   75/100   train_loss = 4.120\n",
      "Epoch 112 Batch    0/100   train_loss = 3.927\n",
      "Epoch 112 Batch   25/100   train_loss = 4.115\n",
      "Epoch 112 Batch   50/100   train_loss = 3.869\n",
      "Epoch 112 Batch   75/100   train_loss = 4.135\n",
      "Epoch 113 Batch    0/100   train_loss = 3.972\n",
      "Epoch 113 Batch   25/100   train_loss = 4.069\n",
      "Epoch 113 Batch   50/100   train_loss = 3.903\n",
      "Epoch 113 Batch   75/100   train_loss = 4.086\n",
      "Epoch 114 Batch    0/100   train_loss = 4.013\n",
      "Epoch 114 Batch   25/100   train_loss = 3.978\n",
      "Epoch 114 Batch   50/100   train_loss = 3.825\n",
      "Epoch 114 Batch   75/100   train_loss = 4.055\n",
      "Epoch 115 Batch    0/100   train_loss = 3.981\n",
      "Epoch 115 Batch   25/100   train_loss = 3.977\n",
      "Epoch 115 Batch   50/100   train_loss = 3.872\n",
      "Epoch 115 Batch   75/100   train_loss = 4.066\n",
      "Epoch 116 Batch    0/100   train_loss = 3.953\n",
      "Epoch 116 Batch   25/100   train_loss = 4.001\n",
      "Epoch 116 Batch   50/100   train_loss = 3.799\n",
      "Epoch 116 Batch   75/100   train_loss = 4.088\n",
      "Epoch 117 Batch    0/100   train_loss = 3.925\n",
      "Epoch 117 Batch   25/100   train_loss = 3.971\n",
      "Epoch 117 Batch   50/100   train_loss = 3.771\n",
      "Epoch 117 Batch   75/100   train_loss = 4.006\n",
      "Epoch 118 Batch    0/100   train_loss = 3.962\n",
      "Epoch 118 Batch   25/100   train_loss = 3.985\n",
      "Epoch 118 Batch   50/100   train_loss = 3.873\n",
      "Epoch 118 Batch   75/100   train_loss = 4.009\n",
      "Epoch 119 Batch    0/100   train_loss = 3.872\n",
      "Epoch 119 Batch   25/100   train_loss = 3.917\n",
      "Epoch 119 Batch   50/100   train_loss = 3.748\n",
      "Epoch 119 Batch   75/100   train_loss = 4.002\n",
      "Epoch 120 Batch    0/100   train_loss = 3.884\n",
      "Epoch 120 Batch   25/100   train_loss = 3.905\n",
      "Epoch 120 Batch   50/100   train_loss = 3.748\n",
      "Epoch 120 Batch   75/100   train_loss = 4.000\n",
      "Epoch 121 Batch    0/100   train_loss = 3.833\n",
      "Epoch 121 Batch   25/100   train_loss = 3.895\n",
      "Epoch 121 Batch   50/100   train_loss = 3.782\n",
      "Epoch 121 Batch   75/100   train_loss = 3.955\n",
      "Epoch 122 Batch    0/100   train_loss = 3.840\n",
      "Epoch 122 Batch   25/100   train_loss = 3.925\n",
      "Epoch 122 Batch   50/100   train_loss = 3.736\n",
      "Epoch 122 Batch   75/100   train_loss = 3.949\n",
      "Epoch 123 Batch    0/100   train_loss = 3.836\n",
      "Epoch 123 Batch   25/100   train_loss = 3.882\n",
      "Epoch 123 Batch   50/100   train_loss = 3.742\n",
      "Epoch 123 Batch   75/100   train_loss = 4.006\n",
      "Epoch 124 Batch    0/100   train_loss = 3.803\n",
      "Epoch 124 Batch   25/100   train_loss = 3.867\n",
      "Epoch 124 Batch   50/100   train_loss = 3.731\n",
      "Epoch 124 Batch   75/100   train_loss = 3.915\n",
      "Epoch 125 Batch    0/100   train_loss = 3.734\n",
      "Epoch 125 Batch   25/100   train_loss = 3.901\n",
      "Epoch 125 Batch   50/100   train_loss = 3.697\n",
      "Epoch 125 Batch   75/100   train_loss = 4.023\n",
      "Epoch 126 Batch    0/100   train_loss = 3.797\n",
      "Epoch 126 Batch   25/100   train_loss = 3.832\n",
      "Epoch 126 Batch   50/100   train_loss = 3.649\n",
      "Epoch 126 Batch   75/100   train_loss = 3.818\n",
      "Epoch 127 Batch    0/100   train_loss = 3.781\n",
      "Epoch 127 Batch   25/100   train_loss = 3.906\n",
      "Epoch 127 Batch   50/100   train_loss = 3.706\n",
      "Epoch 127 Batch   75/100   train_loss = 3.879\n",
      "Epoch 128 Batch    0/100   train_loss = 3.823\n",
      "Epoch 128 Batch   25/100   train_loss = 3.852\n",
      "Epoch 128 Batch   50/100   train_loss = 3.639\n",
      "Epoch 128 Batch   75/100   train_loss = 3.874\n",
      "Epoch 129 Batch    0/100   train_loss = 3.737\n",
      "Epoch 129 Batch   25/100   train_loss = 3.856\n",
      "Epoch 129 Batch   50/100   train_loss = 3.642\n",
      "Epoch 129 Batch   75/100   train_loss = 3.827\n",
      "Epoch 130 Batch    0/100   train_loss = 3.715\n",
      "Epoch 130 Batch   25/100   train_loss = 3.785\n",
      "Epoch 130 Batch   50/100   train_loss = 3.644\n",
      "Epoch 130 Batch   75/100   train_loss = 3.840\n",
      "Epoch 131 Batch    0/100   train_loss = 3.670\n",
      "Epoch 131 Batch   25/100   train_loss = 3.731\n",
      "Epoch 131 Batch   50/100   train_loss = 3.647\n",
      "Epoch 131 Batch   75/100   train_loss = 3.863\n",
      "Epoch 132 Batch    0/100   train_loss = 3.695\n",
      "Epoch 132 Batch   25/100   train_loss = 3.777\n",
      "Epoch 132 Batch   50/100   train_loss = 3.640\n",
      "Epoch 132 Batch   75/100   train_loss = 3.777\n",
      "Epoch 133 Batch    0/100   train_loss = 3.627\n",
      "Epoch 133 Batch   25/100   train_loss = 3.792\n",
      "Epoch 133 Batch   50/100   train_loss = 3.561\n",
      "Epoch 133 Batch   75/100   train_loss = 3.809\n",
      "Epoch 134 Batch    0/100   train_loss = 3.653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 Batch   25/100   train_loss = 3.769\n",
      "Epoch 134 Batch   50/100   train_loss = 3.601\n",
      "Epoch 134 Batch   75/100   train_loss = 3.823\n",
      "Epoch 135 Batch    0/100   train_loss = 3.581\n",
      "Epoch 135 Batch   25/100   train_loss = 3.776\n",
      "Epoch 135 Batch   50/100   train_loss = 3.531\n",
      "Epoch 135 Batch   75/100   train_loss = 3.756\n",
      "Epoch 136 Batch    0/100   train_loss = 3.636\n",
      "Epoch 136 Batch   25/100   train_loss = 3.778\n",
      "Epoch 136 Batch   50/100   train_loss = 3.622\n",
      "Epoch 136 Batch   75/100   train_loss = 3.711\n",
      "Epoch 137 Batch    0/100   train_loss = 3.611\n",
      "Epoch 137 Batch   25/100   train_loss = 3.686\n",
      "Epoch 137 Batch   50/100   train_loss = 3.600\n",
      "Epoch 137 Batch   75/100   train_loss = 3.774\n",
      "Epoch 138 Batch    0/100   train_loss = 3.560\n",
      "Epoch 138 Batch   25/100   train_loss = 3.783\n",
      "Epoch 138 Batch   50/100   train_loss = 3.523\n",
      "Epoch 138 Batch   75/100   train_loss = 3.742\n",
      "Epoch 139 Batch    0/100   train_loss = 3.518\n",
      "Epoch 139 Batch   25/100   train_loss = 3.645\n",
      "Epoch 139 Batch   50/100   train_loss = 3.556\n",
      "Epoch 139 Batch   75/100   train_loss = 3.675\n",
      "Epoch 140 Batch    0/100   train_loss = 3.482\n",
      "Epoch 140 Batch   25/100   train_loss = 3.678\n",
      "Epoch 140 Batch   50/100   train_loss = 3.537\n",
      "Epoch 140 Batch   75/100   train_loss = 3.664\n",
      "Epoch 141 Batch    0/100   train_loss = 3.563\n",
      "Epoch 141 Batch   25/100   train_loss = 3.563\n",
      "Epoch 141 Batch   50/100   train_loss = 3.521\n",
      "Epoch 141 Batch   75/100   train_loss = 3.674\n",
      "Epoch 142 Batch    0/100   train_loss = 3.508\n",
      "Epoch 142 Batch   25/100   train_loss = 3.627\n",
      "Epoch 142 Batch   50/100   train_loss = 3.487\n",
      "Epoch 142 Batch   75/100   train_loss = 3.664\n",
      "Epoch 143 Batch    0/100   train_loss = 3.520\n",
      "Epoch 143 Batch   25/100   train_loss = 3.628\n",
      "Epoch 143 Batch   50/100   train_loss = 3.493\n",
      "Epoch 143 Batch   75/100   train_loss = 3.601\n",
      "Epoch 144 Batch    0/100   train_loss = 3.455\n",
      "Epoch 144 Batch   25/100   train_loss = 3.624\n",
      "Epoch 144 Batch   50/100   train_loss = 3.480\n",
      "Epoch 144 Batch   75/100   train_loss = 3.685\n",
      "Epoch 145 Batch    0/100   train_loss = 3.454\n",
      "Epoch 145 Batch   25/100   train_loss = 3.563\n",
      "Epoch 145 Batch   50/100   train_loss = 3.484\n",
      "Epoch 145 Batch   75/100   train_loss = 3.542\n",
      "Epoch 146 Batch    0/100   train_loss = 3.468\n",
      "Epoch 146 Batch   25/100   train_loss = 3.527\n",
      "Epoch 146 Batch   50/100   train_loss = 3.412\n",
      "Epoch 146 Batch   75/100   train_loss = 3.645\n",
      "Epoch 147 Batch    0/100   train_loss = 3.470\n",
      "Epoch 147 Batch   25/100   train_loss = 3.613\n",
      "Epoch 147 Batch   50/100   train_loss = 3.484\n",
      "Epoch 147 Batch   75/100   train_loss = 3.618\n",
      "Epoch 148 Batch    0/100   train_loss = 3.544\n",
      "Epoch 148 Batch   25/100   train_loss = 3.567\n",
      "Epoch 148 Batch   50/100   train_loss = 3.408\n",
      "Epoch 148 Batch   75/100   train_loss = 3.589\n",
      "Epoch 149 Batch    0/100   train_loss = 3.428\n",
      "Epoch 149 Batch   25/100   train_loss = 3.595\n",
      "Epoch 149 Batch   50/100   train_loss = 3.338\n",
      "Epoch 149 Batch   75/100   train_loss = 3.571\n",
      "Epoch 150 Batch    0/100   train_loss = 3.381\n",
      "Epoch 150 Batch   25/100   train_loss = 3.561\n",
      "Epoch 150 Batch   50/100   train_loss = 3.402\n",
      "Epoch 150 Batch   75/100   train_loss = 3.473\n",
      "Epoch 151 Batch    0/100   train_loss = 3.442\n",
      "Epoch 151 Batch   25/100   train_loss = 3.512\n",
      "Epoch 151 Batch   50/100   train_loss = 3.367\n",
      "Epoch 151 Batch   75/100   train_loss = 3.598\n",
      "Epoch 152 Batch    0/100   train_loss = 3.412\n",
      "Epoch 152 Batch   25/100   train_loss = 3.596\n",
      "Epoch 152 Batch   50/100   train_loss = 3.334\n",
      "Epoch 152 Batch   75/100   train_loss = 3.512\n",
      "Epoch 153 Batch    0/100   train_loss = 3.380\n",
      "Epoch 153 Batch   25/100   train_loss = 3.538\n",
      "Epoch 153 Batch   50/100   train_loss = 3.399\n",
      "Epoch 153 Batch   75/100   train_loss = 3.531\n",
      "Epoch 154 Batch    0/100   train_loss = 3.358\n",
      "Epoch 154 Batch   25/100   train_loss = 3.394\n",
      "Epoch 154 Batch   50/100   train_loss = 3.393\n",
      "Epoch 154 Batch   75/100   train_loss = 3.506\n",
      "Epoch 155 Batch    0/100   train_loss = 3.369\n",
      "Epoch 155 Batch   25/100   train_loss = 3.478\n",
      "Epoch 155 Batch   50/100   train_loss = 3.256\n",
      "Epoch 155 Batch   75/100   train_loss = 3.459\n",
      "Epoch 156 Batch    0/100   train_loss = 3.300\n",
      "Epoch 156 Batch   25/100   train_loss = 3.437\n",
      "Epoch 156 Batch   50/100   train_loss = 3.342\n",
      "Epoch 156 Batch   75/100   train_loss = 3.422\n",
      "Epoch 157 Batch    0/100   train_loss = 3.231\n",
      "Epoch 157 Batch   25/100   train_loss = 3.462\n",
      "Epoch 157 Batch   50/100   train_loss = 3.313\n",
      "Epoch 157 Batch   75/100   train_loss = 3.508\n",
      "Epoch 158 Batch    0/100   train_loss = 3.238\n",
      "Epoch 158 Batch   25/100   train_loss = 3.439\n",
      "Epoch 158 Batch   50/100   train_loss = 3.261\n",
      "Epoch 158 Batch   75/100   train_loss = 3.532\n",
      "Epoch 159 Batch    0/100   train_loss = 3.242\n",
      "Epoch 159 Batch   25/100   train_loss = 3.386\n",
      "Epoch 159 Batch   50/100   train_loss = 3.278\n",
      "Epoch 159 Batch   75/100   train_loss = 3.366\n",
      "Epoch 160 Batch    0/100   train_loss = 3.307\n",
      "Epoch 160 Batch   25/100   train_loss = 3.449\n",
      "Epoch 160 Batch   50/100   train_loss = 3.266\n",
      "Epoch 160 Batch   75/100   train_loss = 3.462\n",
      "Epoch 161 Batch    0/100   train_loss = 3.274\n",
      "Epoch 161 Batch   25/100   train_loss = 3.409\n",
      "Epoch 161 Batch   50/100   train_loss = 3.253\n",
      "Epoch 161 Batch   75/100   train_loss = 3.380\n",
      "Epoch 162 Batch    0/100   train_loss = 3.320\n",
      "Epoch 162 Batch   25/100   train_loss = 3.368\n",
      "Epoch 162 Batch   50/100   train_loss = 3.280\n",
      "Epoch 162 Batch   75/100   train_loss = 3.378\n",
      "Epoch 163 Batch    0/100   train_loss = 3.260\n",
      "Epoch 163 Batch   25/100   train_loss = 3.405\n",
      "Epoch 163 Batch   50/100   train_loss = 3.236\n",
      "Epoch 163 Batch   75/100   train_loss = 3.304\n",
      "Epoch 164 Batch    0/100   train_loss = 3.326\n",
      "Epoch 164 Batch   25/100   train_loss = 3.394\n",
      "Epoch 164 Batch   50/100   train_loss = 3.176\n",
      "Epoch 164 Batch   75/100   train_loss = 3.433\n",
      "Epoch 165 Batch    0/100   train_loss = 3.275\n",
      "Epoch 165 Batch   25/100   train_loss = 3.392\n",
      "Epoch 165 Batch   50/100   train_loss = 3.254\n",
      "Epoch 165 Batch   75/100   train_loss = 3.419\n",
      "Epoch 166 Batch    0/100   train_loss = 3.190\n",
      "Epoch 166 Batch   25/100   train_loss = 3.307\n",
      "Epoch 166 Batch   50/100   train_loss = 3.148\n",
      "Epoch 166 Batch   75/100   train_loss = 3.359\n",
      "Epoch 167 Batch    0/100   train_loss = 3.202\n",
      "Epoch 167 Batch   25/100   train_loss = 3.297\n",
      "Epoch 167 Batch   50/100   train_loss = 3.255\n",
      "Epoch 167 Batch   75/100   train_loss = 3.319\n",
      "Epoch 168 Batch    0/100   train_loss = 3.172\n",
      "Epoch 168 Batch   25/100   train_loss = 3.344\n",
      "Epoch 168 Batch   50/100   train_loss = 3.195\n",
      "Epoch 168 Batch   75/100   train_loss = 3.332\n",
      "Epoch 169 Batch    0/100   train_loss = 3.176\n",
      "Epoch 169 Batch   25/100   train_loss = 3.320\n",
      "Epoch 169 Batch   50/100   train_loss = 3.113\n",
      "Epoch 169 Batch   75/100   train_loss = 3.257\n",
      "Epoch 170 Batch    0/100   train_loss = 3.186\n",
      "Epoch 170 Batch   25/100   train_loss = 3.329\n",
      "Epoch 170 Batch   50/100   train_loss = 3.112\n",
      "Epoch 170 Batch   75/100   train_loss = 3.327\n",
      "Epoch 171 Batch    0/100   train_loss = 3.074\n",
      "Epoch 171 Batch   25/100   train_loss = 3.285\n",
      "Epoch 171 Batch   50/100   train_loss = 3.119\n",
      "Epoch 171 Batch   75/100   train_loss = 3.269\n",
      "Epoch 172 Batch    0/100   train_loss = 3.164\n",
      "Epoch 172 Batch   25/100   train_loss = 3.306\n",
      "Epoch 172 Batch   50/100   train_loss = 3.161\n",
      "Epoch 172 Batch   75/100   train_loss = 3.277\n",
      "Epoch 173 Batch    0/100   train_loss = 3.087\n",
      "Epoch 173 Batch   25/100   train_loss = 3.242\n",
      "Epoch 173 Batch   50/100   train_loss = 3.123\n",
      "Epoch 173 Batch   75/100   train_loss = 3.249\n",
      "Epoch 174 Batch    0/100   train_loss = 3.101\n",
      "Epoch 174 Batch   25/100   train_loss = 3.258\n",
      "Epoch 174 Batch   50/100   train_loss = 3.119\n",
      "Epoch 174 Batch   75/100   train_loss = 3.221\n",
      "Epoch 175 Batch    0/100   train_loss = 3.146\n",
      "Epoch 175 Batch   25/100   train_loss = 3.266\n",
      "Epoch 175 Batch   50/100   train_loss = 3.038\n",
      "Epoch 175 Batch   75/100   train_loss = 3.203\n",
      "Epoch 176 Batch    0/100   train_loss = 3.115\n",
      "Epoch 176 Batch   25/100   train_loss = 3.199\n",
      "Epoch 176 Batch   50/100   train_loss = 3.129\n",
      "Epoch 176 Batch   75/100   train_loss = 3.237\n",
      "Epoch 177 Batch    0/100   train_loss = 3.092\n",
      "Epoch 177 Batch   25/100   train_loss = 3.280\n",
      "Epoch 177 Batch   50/100   train_loss = 3.064\n",
      "Epoch 177 Batch   75/100   train_loss = 3.181\n",
      "Epoch 178 Batch    0/100   train_loss = 3.045\n",
      "Epoch 178 Batch   25/100   train_loss = 3.206\n",
      "Epoch 178 Batch   50/100   train_loss = 3.164\n",
      "Epoch 178 Batch   75/100   train_loss = 3.187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179 Batch    0/100   train_loss = 2.982\n",
      "Epoch 179 Batch   25/100   train_loss = 3.193\n",
      "Epoch 179 Batch   50/100   train_loss = 3.107\n",
      "Epoch 179 Batch   75/100   train_loss = 3.159\n",
      "Epoch 180 Batch    0/100   train_loss = 3.069\n",
      "Epoch 180 Batch   25/100   train_loss = 3.172\n",
      "Epoch 180 Batch   50/100   train_loss = 3.125\n",
      "Epoch 180 Batch   75/100   train_loss = 3.147\n",
      "Epoch 181 Batch    0/100   train_loss = 3.079\n",
      "Epoch 181 Batch   25/100   train_loss = 3.189\n",
      "Epoch 181 Batch   50/100   train_loss = 3.082\n",
      "Epoch 181 Batch   75/100   train_loss = 3.121\n",
      "Epoch 182 Batch    0/100   train_loss = 3.009\n",
      "Epoch 182 Batch   25/100   train_loss = 3.160\n",
      "Epoch 182 Batch   50/100   train_loss = 2.978\n",
      "Epoch 182 Batch   75/100   train_loss = 3.135\n",
      "Epoch 183 Batch    0/100   train_loss = 2.997\n",
      "Epoch 183 Batch   25/100   train_loss = 3.143\n",
      "Epoch 183 Batch   50/100   train_loss = 2.999\n",
      "Epoch 183 Batch   75/100   train_loss = 3.207\n",
      "Epoch 184 Batch    0/100   train_loss = 2.996\n",
      "Epoch 184 Batch   25/100   train_loss = 3.109\n",
      "Epoch 184 Batch   50/100   train_loss = 3.040\n",
      "Epoch 184 Batch   75/100   train_loss = 3.113\n",
      "Epoch 185 Batch    0/100   train_loss = 2.950\n",
      "Epoch 185 Batch   25/100   train_loss = 3.073\n",
      "Epoch 185 Batch   50/100   train_loss = 3.066\n",
      "Epoch 185 Batch   75/100   train_loss = 3.167\n",
      "Epoch 186 Batch    0/100   train_loss = 2.958\n",
      "Epoch 186 Batch   25/100   train_loss = 3.033\n",
      "Epoch 186 Batch   50/100   train_loss = 3.002\n",
      "Epoch 186 Batch   75/100   train_loss = 3.088\n",
      "Epoch 187 Batch    0/100   train_loss = 2.972\n",
      "Epoch 187 Batch   25/100   train_loss = 3.131\n",
      "Epoch 187 Batch   50/100   train_loss = 3.017\n",
      "Epoch 187 Batch   75/100   train_loss = 3.111\n",
      "Epoch 188 Batch    0/100   train_loss = 2.966\n",
      "Epoch 188 Batch   25/100   train_loss = 3.080\n",
      "Epoch 188 Batch   50/100   train_loss = 2.929\n",
      "Epoch 188 Batch   75/100   train_loss = 3.087\n",
      "Epoch 189 Batch    0/100   train_loss = 2.912\n",
      "Epoch 189 Batch   25/100   train_loss = 3.113\n",
      "Epoch 189 Batch   50/100   train_loss = 2.992\n",
      "Epoch 189 Batch   75/100   train_loss = 3.074\n",
      "Epoch 190 Batch    0/100   train_loss = 2.978\n",
      "Epoch 190 Batch   25/100   train_loss = 3.019\n",
      "Epoch 190 Batch   50/100   train_loss = 2.914\n",
      "Epoch 190 Batch   75/100   train_loss = 3.100\n",
      "Epoch 191 Batch    0/100   train_loss = 2.897\n",
      "Epoch 191 Batch   25/100   train_loss = 3.047\n",
      "Epoch 191 Batch   50/100   train_loss = 2.957\n",
      "Epoch 191 Batch   75/100   train_loss = 3.083\n",
      "Epoch 192 Batch    0/100   train_loss = 2.885\n",
      "Epoch 192 Batch   25/100   train_loss = 3.016\n",
      "Epoch 192 Batch   50/100   train_loss = 2.929\n",
      "Epoch 192 Batch   75/100   train_loss = 3.107\n",
      "Epoch 193 Batch    0/100   train_loss = 2.919\n",
      "Epoch 193 Batch   25/100   train_loss = 3.003\n",
      "Epoch 193 Batch   50/100   train_loss = 2.852\n",
      "Epoch 193 Batch   75/100   train_loss = 3.070\n",
      "Epoch 194 Batch    0/100   train_loss = 2.885\n",
      "Epoch 194 Batch   25/100   train_loss = 3.049\n",
      "Epoch 194 Batch   50/100   train_loss = 2.888\n",
      "Epoch 194 Batch   75/100   train_loss = 3.086\n",
      "Epoch 195 Batch    0/100   train_loss = 2.893\n",
      "Epoch 195 Batch   25/100   train_loss = 3.020\n",
      "Epoch 195 Batch   50/100   train_loss = 2.883\n",
      "Epoch 195 Batch   75/100   train_loss = 3.026\n",
      "Epoch 196 Batch    0/100   train_loss = 2.828\n",
      "Epoch 196 Batch   25/100   train_loss = 3.015\n",
      "Epoch 196 Batch   50/100   train_loss = 2.921\n",
      "Epoch 196 Batch   75/100   train_loss = 3.030\n",
      "Epoch 197 Batch    0/100   train_loss = 2.780\n",
      "Epoch 197 Batch   25/100   train_loss = 3.028\n",
      "Epoch 197 Batch   50/100   train_loss = 2.883\n",
      "Epoch 197 Batch   75/100   train_loss = 2.995\n",
      "Epoch 198 Batch    0/100   train_loss = 2.848\n",
      "Epoch 198 Batch   25/100   train_loss = 3.015\n",
      "Epoch 198 Batch   50/100   train_loss = 2.903\n",
      "Epoch 198 Batch   75/100   train_loss = 2.926\n",
      "Epoch 199 Batch    0/100   train_loss = 2.836\n",
      "Epoch 199 Batch   25/100   train_loss = 2.977\n",
      "Epoch 199 Batch   50/100   train_loss = 2.878\n",
      "Epoch 199 Batch   75/100   train_loss = 3.040\n",
      "Epoch 200 Batch    0/100   train_loss = 2.762\n",
      "Epoch 200 Batch   25/100   train_loss = 2.966\n",
      "Epoch 200 Batch   50/100   train_loss = 2.909\n",
      "Epoch 200 Batch   75/100   train_loss = 2.977\n",
      "Epoch 201 Batch    0/100   train_loss = 2.868\n",
      "Epoch 201 Batch   25/100   train_loss = 2.969\n",
      "Epoch 201 Batch   50/100   train_loss = 2.851\n",
      "Epoch 201 Batch   75/100   train_loss = 2.970\n",
      "Epoch 202 Batch    0/100   train_loss = 2.769\n",
      "Epoch 202 Batch   25/100   train_loss = 2.923\n",
      "Epoch 202 Batch   50/100   train_loss = 2.820\n",
      "Epoch 202 Batch   75/100   train_loss = 2.961\n",
      "Epoch 203 Batch    0/100   train_loss = 2.772\n",
      "Epoch 203 Batch   25/100   train_loss = 2.947\n",
      "Epoch 203 Batch   50/100   train_loss = 2.875\n",
      "Epoch 203 Batch   75/100   train_loss = 2.991\n",
      "Epoch 204 Batch    0/100   train_loss = 2.806\n",
      "Epoch 204 Batch   25/100   train_loss = 2.979\n",
      "Epoch 204 Batch   50/100   train_loss = 2.779\n",
      "Epoch 204 Batch   75/100   train_loss = 2.945\n",
      "Epoch 205 Batch    0/100   train_loss = 2.755\n",
      "Epoch 205 Batch   25/100   train_loss = 2.947\n",
      "Epoch 205 Batch   50/100   train_loss = 2.769\n",
      "Epoch 205 Batch   75/100   train_loss = 2.964\n",
      "Epoch 206 Batch    0/100   train_loss = 2.725\n",
      "Epoch 206 Batch   25/100   train_loss = 2.931\n",
      "Epoch 206 Batch   50/100   train_loss = 2.838\n",
      "Epoch 206 Batch   75/100   train_loss = 2.893\n",
      "Epoch 207 Batch    0/100   train_loss = 2.764\n",
      "Epoch 207 Batch   25/100   train_loss = 2.905\n",
      "Epoch 207 Batch   50/100   train_loss = 2.765\n",
      "Epoch 207 Batch   75/100   train_loss = 2.905\n",
      "Epoch 208 Batch    0/100   train_loss = 2.702\n",
      "Epoch 208 Batch   25/100   train_loss = 2.832\n",
      "Epoch 208 Batch   50/100   train_loss = 2.809\n",
      "Epoch 208 Batch   75/100   train_loss = 2.881\n",
      "Epoch 209 Batch    0/100   train_loss = 2.697\n",
      "Epoch 209 Batch   25/100   train_loss = 2.942\n",
      "Epoch 209 Batch   50/100   train_loss = 2.749\n",
      "Epoch 209 Batch   75/100   train_loss = 2.888\n",
      "Epoch 210 Batch    0/100   train_loss = 2.759\n",
      "Epoch 210 Batch   25/100   train_loss = 2.849\n",
      "Epoch 210 Batch   50/100   train_loss = 2.756\n",
      "Epoch 210 Batch   75/100   train_loss = 2.855\n",
      "Epoch 211 Batch    0/100   train_loss = 2.756\n",
      "Epoch 211 Batch   25/100   train_loss = 2.754\n",
      "Epoch 211 Batch   50/100   train_loss = 2.789\n",
      "Epoch 211 Batch   75/100   train_loss = 2.814\n",
      "Epoch 212 Batch    0/100   train_loss = 2.723\n",
      "Epoch 212 Batch   25/100   train_loss = 2.889\n",
      "Epoch 212 Batch   50/100   train_loss = 2.729\n",
      "Epoch 212 Batch   75/100   train_loss = 2.836\n",
      "Epoch 213 Batch    0/100   train_loss = 2.658\n",
      "Epoch 213 Batch   25/100   train_loss = 2.814\n",
      "Epoch 213 Batch   50/100   train_loss = 2.797\n",
      "Epoch 213 Batch   75/100   train_loss = 2.820\n",
      "Epoch 214 Batch    0/100   train_loss = 2.699\n",
      "Epoch 214 Batch   25/100   train_loss = 2.776\n",
      "Epoch 214 Batch   50/100   train_loss = 2.706\n",
      "Epoch 214 Batch   75/100   train_loss = 2.909\n",
      "Epoch 215 Batch    0/100   train_loss = 2.698\n",
      "Epoch 215 Batch   25/100   train_loss = 2.822\n",
      "Epoch 215 Batch   50/100   train_loss = 2.670\n",
      "Epoch 215 Batch   75/100   train_loss = 2.882\n",
      "Epoch 216 Batch    0/100   train_loss = 2.657\n",
      "Epoch 216 Batch   25/100   train_loss = 2.744\n",
      "Epoch 216 Batch   50/100   train_loss = 2.682\n",
      "Epoch 216 Batch   75/100   train_loss = 2.772\n",
      "Epoch 217 Batch    0/100   train_loss = 2.647\n",
      "Epoch 217 Batch   25/100   train_loss = 2.755\n",
      "Epoch 217 Batch   50/100   train_loss = 2.746\n",
      "Epoch 217 Batch   75/100   train_loss = 2.832\n",
      "Epoch 218 Batch    0/100   train_loss = 2.686\n",
      "Epoch 218 Batch   25/100   train_loss = 2.786\n",
      "Epoch 218 Batch   50/100   train_loss = 2.629\n",
      "Epoch 218 Batch   75/100   train_loss = 2.814\n",
      "Epoch 219 Batch    0/100   train_loss = 2.655\n",
      "Epoch 219 Batch   25/100   train_loss = 2.784\n",
      "Epoch 219 Batch   50/100   train_loss = 2.686\n",
      "Epoch 219 Batch   75/100   train_loss = 2.764\n",
      "Epoch 220 Batch    0/100   train_loss = 2.597\n",
      "Epoch 220 Batch   25/100   train_loss = 2.718\n",
      "Epoch 220 Batch   50/100   train_loss = 2.661\n",
      "Epoch 220 Batch   75/100   train_loss = 2.746\n",
      "Epoch 221 Batch    0/100   train_loss = 2.690\n",
      "Epoch 221 Batch   25/100   train_loss = 2.761\n",
      "Epoch 221 Batch   50/100   train_loss = 2.701\n",
      "Epoch 221 Batch   75/100   train_loss = 2.750\n",
      "Epoch 222 Batch    0/100   train_loss = 2.563\n",
      "Epoch 222 Batch   25/100   train_loss = 2.748\n",
      "Epoch 222 Batch   50/100   train_loss = 2.582\n",
      "Epoch 222 Batch   75/100   train_loss = 2.692\n",
      "Epoch 223 Batch    0/100   train_loss = 2.567\n",
      "Epoch 223 Batch   25/100   train_loss = 2.745\n",
      "Epoch 223 Batch   50/100   train_loss = 2.652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223 Batch   75/100   train_loss = 2.748\n",
      "Epoch 224 Batch    0/100   train_loss = 2.579\n",
      "Epoch 224 Batch   25/100   train_loss = 2.701\n",
      "Epoch 224 Batch   50/100   train_loss = 2.583\n",
      "Epoch 224 Batch   75/100   train_loss = 2.715\n",
      "Epoch 225 Batch    0/100   train_loss = 2.598\n",
      "Epoch 225 Batch   25/100   train_loss = 2.746\n",
      "Epoch 225 Batch   50/100   train_loss = 2.588\n",
      "Epoch 225 Batch   75/100   train_loss = 2.743\n",
      "Epoch 226 Batch    0/100   train_loss = 2.607\n",
      "Epoch 226 Batch   25/100   train_loss = 2.647\n",
      "Epoch 226 Batch   50/100   train_loss = 2.643\n",
      "Epoch 226 Batch   75/100   train_loss = 2.611\n",
      "Epoch 227 Batch    0/100   train_loss = 2.619\n",
      "Epoch 227 Batch   25/100   train_loss = 2.730\n",
      "Epoch 227 Batch   50/100   train_loss = 2.656\n",
      "Epoch 227 Batch   75/100   train_loss = 2.740\n",
      "Epoch 228 Batch    0/100   train_loss = 2.606\n",
      "Epoch 228 Batch   25/100   train_loss = 2.735\n",
      "Epoch 228 Batch   50/100   train_loss = 2.593\n",
      "Epoch 228 Batch   75/100   train_loss = 2.715\n",
      "Epoch 229 Batch    0/100   train_loss = 2.511\n",
      "Epoch 229 Batch   25/100   train_loss = 2.699\n",
      "Epoch 229 Batch   50/100   train_loss = 2.622\n",
      "Epoch 229 Batch   75/100   train_loss = 2.728\n",
      "Epoch 230 Batch    0/100   train_loss = 2.499\n",
      "Epoch 230 Batch   25/100   train_loss = 2.674\n",
      "Epoch 230 Batch   50/100   train_loss = 2.632\n",
      "Epoch 230 Batch   75/100   train_loss = 2.669\n",
      "Epoch 231 Batch    0/100   train_loss = 2.539\n",
      "Epoch 231 Batch   25/100   train_loss = 2.759\n",
      "Epoch 231 Batch   50/100   train_loss = 2.569\n",
      "Epoch 231 Batch   75/100   train_loss = 2.679\n",
      "Epoch 232 Batch    0/100   train_loss = 2.541\n",
      "Epoch 232 Batch   25/100   train_loss = 2.677\n",
      "Epoch 232 Batch   50/100   train_loss = 2.505\n",
      "Epoch 232 Batch   75/100   train_loss = 2.704\n",
      "Epoch 233 Batch    0/100   train_loss = 2.523\n",
      "Epoch 233 Batch   25/100   train_loss = 2.653\n",
      "Epoch 233 Batch   50/100   train_loss = 2.551\n",
      "Epoch 233 Batch   75/100   train_loss = 2.607\n",
      "Epoch 234 Batch    0/100   train_loss = 2.483\n",
      "Epoch 234 Batch   25/100   train_loss = 2.619\n",
      "Epoch 234 Batch   50/100   train_loss = 2.468\n",
      "Epoch 234 Batch   75/100   train_loss = 2.657\n",
      "Epoch 235 Batch    0/100   train_loss = 2.499\n",
      "Epoch 235 Batch   25/100   train_loss = 2.581\n",
      "Epoch 235 Batch   50/100   train_loss = 2.530\n",
      "Epoch 235 Batch   75/100   train_loss = 2.609\n",
      "Epoch 236 Batch    0/100   train_loss = 2.525\n",
      "Epoch 236 Batch   25/100   train_loss = 2.631\n",
      "Epoch 236 Batch   50/100   train_loss = 2.500\n",
      "Epoch 236 Batch   75/100   train_loss = 2.597\n",
      "Epoch 237 Batch    0/100   train_loss = 2.526\n",
      "Epoch 237 Batch   25/100   train_loss = 2.558\n",
      "Epoch 237 Batch   50/100   train_loss = 2.506\n",
      "Epoch 237 Batch   75/100   train_loss = 2.560\n",
      "Epoch 238 Batch    0/100   train_loss = 2.510\n",
      "Epoch 238 Batch   25/100   train_loss = 2.601\n",
      "Epoch 238 Batch   50/100   train_loss = 2.512\n",
      "Epoch 238 Batch   75/100   train_loss = 2.555\n",
      "Epoch 239 Batch    0/100   train_loss = 2.491\n",
      "Epoch 239 Batch   25/100   train_loss = 2.561\n",
      "Epoch 239 Batch   50/100   train_loss = 2.474\n",
      "Epoch 239 Batch   75/100   train_loss = 2.570\n",
      "Epoch 240 Batch    0/100   train_loss = 2.412\n",
      "Epoch 240 Batch   25/100   train_loss = 2.554\n",
      "Epoch 240 Batch   50/100   train_loss = 2.462\n",
      "Epoch 240 Batch   75/100   train_loss = 2.517\n",
      "Epoch 241 Batch    0/100   train_loss = 2.453\n",
      "Epoch 241 Batch   25/100   train_loss = 2.543\n",
      "Epoch 241 Batch   50/100   train_loss = 2.459\n",
      "Epoch 241 Batch   75/100   train_loss = 2.557\n",
      "Epoch 242 Batch    0/100   train_loss = 2.401\n",
      "Epoch 242 Batch   25/100   train_loss = 2.573\n",
      "Epoch 242 Batch   50/100   train_loss = 2.502\n",
      "Epoch 242 Batch   75/100   train_loss = 2.551\n",
      "Epoch 243 Batch    0/100   train_loss = 2.433\n",
      "Epoch 243 Batch   25/100   train_loss = 2.545\n",
      "Epoch 243 Batch   50/100   train_loss = 2.460\n",
      "Epoch 243 Batch   75/100   train_loss = 2.555\n",
      "Epoch 244 Batch    0/100   train_loss = 2.456\n",
      "Epoch 244 Batch   25/100   train_loss = 2.494\n",
      "Epoch 244 Batch   50/100   train_loss = 2.450\n",
      "Epoch 244 Batch   75/100   train_loss = 2.570\n",
      "Epoch 245 Batch    0/100   train_loss = 2.393\n",
      "Epoch 245 Batch   25/100   train_loss = 2.531\n",
      "Epoch 245 Batch   50/100   train_loss = 2.438\n",
      "Epoch 245 Batch   75/100   train_loss = 2.503\n",
      "Epoch 246 Batch    0/100   train_loss = 2.358\n",
      "Epoch 246 Batch   25/100   train_loss = 2.480\n",
      "Epoch 246 Batch   50/100   train_loss = 2.469\n",
      "Epoch 246 Batch   75/100   train_loss = 2.504\n",
      "Epoch 247 Batch    0/100   train_loss = 2.384\n",
      "Epoch 247 Batch   25/100   train_loss = 2.474\n",
      "Epoch 247 Batch   50/100   train_loss = 2.319\n",
      "Epoch 247 Batch   75/100   train_loss = 2.539\n",
      "Epoch 248 Batch    0/100   train_loss = 2.334\n",
      "Epoch 248 Batch   25/100   train_loss = 2.493\n",
      "Epoch 248 Batch   50/100   train_loss = 2.436\n",
      "Epoch 248 Batch   75/100   train_loss = 2.470\n",
      "Epoch 249 Batch    0/100   train_loss = 2.402\n",
      "Epoch 249 Batch   25/100   train_loss = 2.577\n",
      "Epoch 249 Batch   50/100   train_loss = 2.442\n",
      "Epoch 249 Batch   75/100   train_loss = 2.519\n",
      "Epoch 250 Batch    0/100   train_loss = 2.400\n",
      "Epoch 250 Batch   25/100   train_loss = 2.486\n",
      "Epoch 250 Batch   50/100   train_loss = 2.420\n",
      "Epoch 250 Batch   75/100   train_loss = 2.424\n",
      "Epoch 251 Batch    0/100   train_loss = 2.358\n",
      "Epoch 251 Batch   25/100   train_loss = 2.419\n",
      "Epoch 251 Batch   50/100   train_loss = 2.345\n",
      "Epoch 251 Batch   75/100   train_loss = 2.474\n",
      "Epoch 252 Batch    0/100   train_loss = 2.330\n",
      "Epoch 252 Batch   25/100   train_loss = 2.499\n",
      "Epoch 252 Batch   50/100   train_loss = 2.370\n",
      "Epoch 252 Batch   75/100   train_loss = 2.452\n",
      "Epoch 253 Batch    0/100   train_loss = 2.343\n",
      "Epoch 253 Batch   25/100   train_loss = 2.478\n",
      "Epoch 253 Batch   50/100   train_loss = 2.362\n",
      "Epoch 253 Batch   75/100   train_loss = 2.458\n",
      "Epoch 254 Batch    0/100   train_loss = 2.309\n",
      "Epoch 254 Batch   25/100   train_loss = 2.444\n",
      "Epoch 254 Batch   50/100   train_loss = 2.388\n",
      "Epoch 254 Batch   75/100   train_loss = 2.434\n",
      "Epoch 255 Batch    0/100   train_loss = 2.334\n",
      "Epoch 255 Batch   25/100   train_loss = 2.390\n",
      "Epoch 255 Batch   50/100   train_loss = 2.353\n",
      "Epoch 255 Batch   75/100   train_loss = 2.444\n",
      "Epoch 256 Batch    0/100   train_loss = 2.339\n",
      "Epoch 256 Batch   25/100   train_loss = 2.421\n",
      "Epoch 256 Batch   50/100   train_loss = 2.331\n",
      "Epoch 256 Batch   75/100   train_loss = 2.442\n",
      "Epoch 257 Batch    0/100   train_loss = 2.341\n",
      "Epoch 257 Batch   25/100   train_loss = 2.467\n",
      "Epoch 257 Batch   50/100   train_loss = 2.335\n",
      "Epoch 257 Batch   75/100   train_loss = 2.472\n",
      "Epoch 258 Batch    0/100   train_loss = 2.238\n",
      "Epoch 258 Batch   25/100   train_loss = 2.492\n",
      "Epoch 258 Batch   50/100   train_loss = 2.433\n",
      "Epoch 258 Batch   75/100   train_loss = 2.438\n",
      "Epoch 259 Batch    0/100   train_loss = 2.196\n",
      "Epoch 259 Batch   25/100   train_loss = 2.417\n",
      "Epoch 259 Batch   50/100   train_loss = 2.333\n",
      "Epoch 259 Batch   75/100   train_loss = 2.433\n",
      "Epoch 260 Batch    0/100   train_loss = 2.288\n",
      "Epoch 260 Batch   25/100   train_loss = 2.416\n",
      "Epoch 260 Batch   50/100   train_loss = 2.304\n",
      "Epoch 260 Batch   75/100   train_loss = 2.450\n",
      "Epoch 261 Batch    0/100   train_loss = 2.231\n",
      "Epoch 261 Batch   25/100   train_loss = 2.399\n",
      "Epoch 261 Batch   50/100   train_loss = 2.300\n",
      "Epoch 261 Batch   75/100   train_loss = 2.438\n",
      "Epoch 262 Batch    0/100   train_loss = 2.268\n",
      "Epoch 262 Batch   25/100   train_loss = 2.343\n",
      "Epoch 262 Batch   50/100   train_loss = 2.328\n",
      "Epoch 262 Batch   75/100   train_loss = 2.371\n",
      "Epoch 263 Batch    0/100   train_loss = 2.255\n",
      "Epoch 263 Batch   25/100   train_loss = 2.346\n",
      "Epoch 263 Batch   50/100   train_loss = 2.211\n",
      "Epoch 263 Batch   75/100   train_loss = 2.396\n",
      "Epoch 264 Batch    0/100   train_loss = 2.261\n",
      "Epoch 264 Batch   25/100   train_loss = 2.420\n",
      "Epoch 264 Batch   50/100   train_loss = 2.271\n",
      "Epoch 264 Batch   75/100   train_loss = 2.358\n",
      "Epoch 265 Batch    0/100   train_loss = 2.231\n",
      "Epoch 265 Batch   25/100   train_loss = 2.387\n",
      "Epoch 265 Batch   50/100   train_loss = 2.227\n",
      "Epoch 265 Batch   75/100   train_loss = 2.379\n",
      "Epoch 266 Batch    0/100   train_loss = 2.190\n",
      "Epoch 266 Batch   25/100   train_loss = 2.368\n",
      "Epoch 266 Batch   50/100   train_loss = 2.233\n",
      "Epoch 266 Batch   75/100   train_loss = 2.330\n",
      "Epoch 267 Batch    0/100   train_loss = 2.184\n",
      "Epoch 267 Batch   25/100   train_loss = 2.371\n",
      "Epoch 267 Batch   50/100   train_loss = 2.276\n",
      "Epoch 267 Batch   75/100   train_loss = 2.368\n",
      "Epoch 268 Batch    0/100   train_loss = 2.232\n",
      "Epoch 268 Batch   25/100   train_loss = 2.290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 268 Batch   50/100   train_loss = 2.241\n",
      "Epoch 268 Batch   75/100   train_loss = 2.366\n",
      "Epoch 269 Batch    0/100   train_loss = 2.214\n",
      "Epoch 269 Batch   25/100   train_loss = 2.296\n",
      "Epoch 269 Batch   50/100   train_loss = 2.246\n",
      "Epoch 269 Batch   75/100   train_loss = 2.331\n",
      "Epoch 270 Batch    0/100   train_loss = 2.224\n",
      "Epoch 270 Batch   25/100   train_loss = 2.300\n",
      "Epoch 270 Batch   50/100   train_loss = 2.194\n",
      "Epoch 270 Batch   75/100   train_loss = 2.326\n",
      "Epoch 271 Batch    0/100   train_loss = 2.260\n",
      "Epoch 271 Batch   25/100   train_loss = 2.355\n",
      "Epoch 271 Batch   50/100   train_loss = 2.206\n",
      "Epoch 271 Batch   75/100   train_loss = 2.315\n",
      "Epoch 272 Batch    0/100   train_loss = 2.261\n",
      "Epoch 272 Batch   25/100   train_loss = 2.271\n",
      "Epoch 272 Batch   50/100   train_loss = 2.244\n",
      "Epoch 272 Batch   75/100   train_loss = 2.341\n",
      "Epoch 273 Batch    0/100   train_loss = 2.212\n",
      "Epoch 273 Batch   25/100   train_loss = 2.313\n",
      "Epoch 273 Batch   50/100   train_loss = 2.182\n",
      "Epoch 273 Batch   75/100   train_loss = 2.315\n",
      "Epoch 274 Batch    0/100   train_loss = 2.225\n",
      "Epoch 274 Batch   25/100   train_loss = 2.286\n",
      "Epoch 274 Batch   50/100   train_loss = 2.179\n",
      "Epoch 274 Batch   75/100   train_loss = 2.412\n",
      "Epoch 275 Batch    0/100   train_loss = 2.177\n",
      "Epoch 275 Batch   25/100   train_loss = 2.277\n",
      "Epoch 275 Batch   50/100   train_loss = 2.265\n",
      "Epoch 275 Batch   75/100   train_loss = 2.303\n",
      "Epoch 276 Batch    0/100   train_loss = 2.183\n",
      "Epoch 276 Batch   25/100   train_loss = 2.306\n",
      "Epoch 276 Batch   50/100   train_loss = 2.216\n",
      "Epoch 276 Batch   75/100   train_loss = 2.268\n",
      "Epoch 277 Batch    0/100   train_loss = 2.184\n",
      "Epoch 277 Batch   25/100   train_loss = 2.355\n",
      "Epoch 277 Batch   50/100   train_loss = 2.209\n",
      "Epoch 277 Batch   75/100   train_loss = 2.242\n",
      "Epoch 278 Batch    0/100   train_loss = 2.158\n",
      "Epoch 278 Batch   25/100   train_loss = 2.299\n",
      "Epoch 278 Batch   50/100   train_loss = 2.190\n",
      "Epoch 278 Batch   75/100   train_loss = 2.207\n",
      "Epoch 279 Batch    0/100   train_loss = 2.132\n",
      "Epoch 279 Batch   25/100   train_loss = 2.214\n",
      "Epoch 279 Batch   50/100   train_loss = 2.169\n",
      "Epoch 279 Batch   75/100   train_loss = 2.279\n",
      "Epoch 280 Batch    0/100   train_loss = 2.129\n",
      "Epoch 280 Batch   25/100   train_loss = 2.260\n",
      "Epoch 280 Batch   50/100   train_loss = 2.152\n",
      "Epoch 280 Batch   75/100   train_loss = 2.295\n",
      "Epoch 281 Batch    0/100   train_loss = 2.176\n",
      "Epoch 281 Batch   25/100   train_loss = 2.271\n",
      "Epoch 281 Batch   50/100   train_loss = 2.158\n",
      "Epoch 281 Batch   75/100   train_loss = 2.246\n",
      "Epoch 282 Batch    0/100   train_loss = 2.117\n",
      "Epoch 282 Batch   25/100   train_loss = 2.224\n",
      "Epoch 282 Batch   50/100   train_loss = 2.109\n",
      "Epoch 282 Batch   75/100   train_loss = 2.206\n",
      "Epoch 283 Batch    0/100   train_loss = 2.141\n",
      "Epoch 283 Batch   25/100   train_loss = 2.281\n",
      "Epoch 283 Batch   50/100   train_loss = 2.110\n",
      "Epoch 283 Batch   75/100   train_loss = 2.191\n",
      "Epoch 284 Batch    0/100   train_loss = 2.142\n",
      "Epoch 284 Batch   25/100   train_loss = 2.227\n",
      "Epoch 284 Batch   50/100   train_loss = 2.184\n",
      "Epoch 284 Batch   75/100   train_loss = 2.174\n",
      "Epoch 285 Batch    0/100   train_loss = 2.103\n",
      "Epoch 285 Batch   25/100   train_loss = 2.214\n",
      "Epoch 285 Batch   50/100   train_loss = 2.163\n",
      "Epoch 285 Batch   75/100   train_loss = 2.185\n",
      "Epoch 286 Batch    0/100   train_loss = 2.108\n",
      "Epoch 286 Batch   25/100   train_loss = 2.190\n",
      "Epoch 286 Batch   50/100   train_loss = 2.133\n",
      "Epoch 286 Batch   75/100   train_loss = 2.215\n",
      "Epoch 287 Batch    0/100   train_loss = 2.044\n",
      "Epoch 287 Batch   25/100   train_loss = 2.208\n",
      "Epoch 287 Batch   50/100   train_loss = 2.127\n",
      "Epoch 287 Batch   75/100   train_loss = 2.199\n",
      "Epoch 288 Batch    0/100   train_loss = 2.069\n",
      "Epoch 288 Batch   25/100   train_loss = 2.179\n",
      "Epoch 288 Batch   50/100   train_loss = 2.140\n",
      "Epoch 288 Batch   75/100   train_loss = 2.139\n",
      "Epoch 289 Batch    0/100   train_loss = 2.074\n",
      "Epoch 289 Batch   25/100   train_loss = 2.184\n",
      "Epoch 289 Batch   50/100   train_loss = 2.025\n",
      "Epoch 289 Batch   75/100   train_loss = 2.195\n",
      "Epoch 290 Batch    0/100   train_loss = 2.131\n",
      "Epoch 290 Batch   25/100   train_loss = 2.168\n",
      "Epoch 290 Batch   50/100   train_loss = 2.110\n",
      "Epoch 290 Batch   75/100   train_loss = 2.159\n",
      "Epoch 291 Batch    0/100   train_loss = 2.046\n",
      "Epoch 291 Batch   25/100   train_loss = 2.121\n",
      "Epoch 291 Batch   50/100   train_loss = 2.023\n",
      "Epoch 291 Batch   75/100   train_loss = 2.148\n",
      "Epoch 292 Batch    0/100   train_loss = 2.057\n",
      "Epoch 292 Batch   25/100   train_loss = 2.126\n",
      "Epoch 292 Batch   50/100   train_loss = 2.058\n",
      "Epoch 292 Batch   75/100   train_loss = 2.197\n",
      "Epoch 293 Batch    0/100   train_loss = 2.081\n",
      "Epoch 293 Batch   25/100   train_loss = 2.176\n",
      "Epoch 293 Batch   50/100   train_loss = 2.065\n",
      "Epoch 293 Batch   75/100   train_loss = 2.114\n",
      "Epoch 294 Batch    0/100   train_loss = 2.111\n",
      "Epoch 294 Batch   25/100   train_loss = 2.164\n",
      "Epoch 294 Batch   50/100   train_loss = 2.006\n",
      "Epoch 294 Batch   75/100   train_loss = 2.171\n",
      "Epoch 295 Batch    0/100   train_loss = 2.059\n",
      "Epoch 295 Batch   25/100   train_loss = 2.176\n",
      "Epoch 295 Batch   50/100   train_loss = 2.035\n",
      "Epoch 295 Batch   75/100   train_loss = 2.181\n",
      "Epoch 296 Batch    0/100   train_loss = 2.033\n",
      "Epoch 296 Batch   25/100   train_loss = 2.149\n",
      "Epoch 296 Batch   50/100   train_loss = 2.073\n",
      "Epoch 296 Batch   75/100   train_loss = 2.134\n",
      "Epoch 297 Batch    0/100   train_loss = 2.023\n",
      "Epoch 297 Batch   25/100   train_loss = 2.160\n",
      "Epoch 297 Batch   50/100   train_loss = 2.086\n",
      "Epoch 297 Batch   75/100   train_loss = 2.114\n",
      "Epoch 298 Batch    0/100   train_loss = 2.005\n",
      "Epoch 298 Batch   25/100   train_loss = 2.129\n",
      "Epoch 298 Batch   50/100   train_loss = 1.967\n",
      "Epoch 298 Batch   75/100   train_loss = 2.230\n",
      "Epoch 299 Batch    0/100   train_loss = 2.012\n",
      "Epoch 299 Batch   25/100   train_loss = 2.083\n",
      "Epoch 299 Batch   50/100   train_loss = 2.046\n",
      "Epoch 299 Batch   75/100   train_loss = 2.085\n",
      "Epoch 300 Batch    0/100   train_loss = 1.969\n",
      "Epoch 300 Batch   25/100   train_loss = 2.167\n",
      "Epoch 300 Batch   50/100   train_loss = 1.943\n",
      "Epoch 300 Batch   75/100   train_loss = 2.075\n",
      "Epoch 301 Batch    0/100   train_loss = 2.034\n",
      "Epoch 301 Batch   25/100   train_loss = 2.154\n",
      "Epoch 301 Batch   50/100   train_loss = 2.072\n",
      "Epoch 301 Batch   75/100   train_loss = 2.118\n",
      "Epoch 302 Batch    0/100   train_loss = 1.995\n",
      "Epoch 302 Batch   25/100   train_loss = 2.159\n",
      "Epoch 302 Batch   50/100   train_loss = 2.069\n",
      "Epoch 302 Batch   75/100   train_loss = 2.090\n",
      "Epoch 303 Batch    0/100   train_loss = 1.973\n",
      "Epoch 303 Batch   25/100   train_loss = 2.108\n",
      "Epoch 303 Batch   50/100   train_loss = 2.017\n",
      "Epoch 303 Batch   75/100   train_loss = 2.105\n",
      "Epoch 304 Batch    0/100   train_loss = 1.982\n",
      "Epoch 304 Batch   25/100   train_loss = 2.096\n",
      "Epoch 304 Batch   50/100   train_loss = 1.992\n",
      "Epoch 304 Batch   75/100   train_loss = 2.071\n",
      "Epoch 305 Batch    0/100   train_loss = 1.983\n",
      "Epoch 305 Batch   25/100   train_loss = 2.106\n",
      "Epoch 305 Batch   50/100   train_loss = 2.035\n",
      "Epoch 305 Batch   75/100   train_loss = 2.120\n",
      "Epoch 306 Batch    0/100   train_loss = 2.035\n",
      "Epoch 306 Batch   25/100   train_loss = 2.069\n",
      "Epoch 306 Batch   50/100   train_loss = 1.975\n",
      "Epoch 306 Batch   75/100   train_loss = 2.071\n",
      "Epoch 307 Batch    0/100   train_loss = 1.933\n",
      "Epoch 307 Batch   25/100   train_loss = 2.034\n",
      "Epoch 307 Batch   50/100   train_loss = 1.960\n",
      "Epoch 307 Batch   75/100   train_loss = 2.086\n",
      "Epoch 308 Batch    0/100   train_loss = 1.957\n",
      "Epoch 308 Batch   25/100   train_loss = 2.066\n",
      "Epoch 308 Batch   50/100   train_loss = 1.955\n",
      "Epoch 308 Batch   75/100   train_loss = 2.109\n",
      "Epoch 309 Batch    0/100   train_loss = 1.931\n",
      "Epoch 309 Batch   25/100   train_loss = 2.069\n",
      "Epoch 309 Batch   50/100   train_loss = 1.983\n",
      "Epoch 309 Batch   75/100   train_loss = 1.996\n",
      "Epoch 310 Batch    0/100   train_loss = 1.965\n",
      "Epoch 310 Batch   25/100   train_loss = 2.024\n",
      "Epoch 310 Batch   50/100   train_loss = 1.982\n",
      "Epoch 310 Batch   75/100   train_loss = 2.096\n",
      "Epoch 311 Batch    0/100   train_loss = 1.925\n",
      "Epoch 311 Batch   25/100   train_loss = 2.007\n",
      "Epoch 311 Batch   50/100   train_loss = 2.022\n",
      "Epoch 311 Batch   75/100   train_loss = 2.037\n",
      "Epoch 312 Batch    0/100   train_loss = 1.953\n",
      "Epoch 312 Batch   25/100   train_loss = 1.998\n",
      "Epoch 312 Batch   50/100   train_loss = 1.962\n",
      "Epoch 312 Batch   75/100   train_loss = 1.961\n",
      "Epoch 313 Batch    0/100   train_loss = 1.927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313 Batch   25/100   train_loss = 2.103\n",
      "Epoch 313 Batch   50/100   train_loss = 1.918\n",
      "Epoch 313 Batch   75/100   train_loss = 2.047\n",
      "Epoch 314 Batch    0/100   train_loss = 1.964\n",
      "Epoch 314 Batch   25/100   train_loss = 2.011\n",
      "Epoch 314 Batch   50/100   train_loss = 1.991\n",
      "Epoch 314 Batch   75/100   train_loss = 1.969\n",
      "Epoch 315 Batch    0/100   train_loss = 2.000\n",
      "Epoch 315 Batch   25/100   train_loss = 2.000\n",
      "Epoch 315 Batch   50/100   train_loss = 1.951\n",
      "Epoch 315 Batch   75/100   train_loss = 2.066\n",
      "Epoch 316 Batch    0/100   train_loss = 1.979\n",
      "Epoch 316 Batch   25/100   train_loss = 2.011\n",
      "Epoch 316 Batch   50/100   train_loss = 1.978\n",
      "Epoch 316 Batch   75/100   train_loss = 2.027\n",
      "Epoch 317 Batch    0/100   train_loss = 1.872\n",
      "Epoch 317 Batch   25/100   train_loss = 1.962\n",
      "Epoch 317 Batch   50/100   train_loss = 1.964\n",
      "Epoch 317 Batch   75/100   train_loss = 1.992\n",
      "Epoch 318 Batch    0/100   train_loss = 1.889\n",
      "Epoch 318 Batch   25/100   train_loss = 1.950\n",
      "Epoch 318 Batch   50/100   train_loss = 1.905\n",
      "Epoch 318 Batch   75/100   train_loss = 1.971\n",
      "Epoch 319 Batch    0/100   train_loss = 1.882\n",
      "Epoch 319 Batch   25/100   train_loss = 1.983\n",
      "Epoch 319 Batch   50/100   train_loss = 1.947\n",
      "Epoch 319 Batch   75/100   train_loss = 2.011\n",
      "Epoch 320 Batch    0/100   train_loss = 1.878\n",
      "Epoch 320 Batch   25/100   train_loss = 1.990\n",
      "Epoch 320 Batch   50/100   train_loss = 1.861\n",
      "Epoch 320 Batch   75/100   train_loss = 1.902\n",
      "Epoch 321 Batch    0/100   train_loss = 1.921\n",
      "Epoch 321 Batch   25/100   train_loss = 2.020\n",
      "Epoch 321 Batch   50/100   train_loss = 1.935\n",
      "Epoch 321 Batch   75/100   train_loss = 2.045\n",
      "Epoch 322 Batch    0/100   train_loss = 1.854\n",
      "Epoch 322 Batch   25/100   train_loss = 1.959\n",
      "Epoch 322 Batch   50/100   train_loss = 1.957\n",
      "Epoch 322 Batch   75/100   train_loss = 2.010\n",
      "Epoch 323 Batch    0/100   train_loss = 1.903\n",
      "Epoch 323 Batch   25/100   train_loss = 1.946\n",
      "Epoch 323 Batch   50/100   train_loss = 1.940\n",
      "Epoch 323 Batch   75/100   train_loss = 1.959\n",
      "Epoch 324 Batch    0/100   train_loss = 1.951\n",
      "Epoch 324 Batch   25/100   train_loss = 1.995\n",
      "Epoch 324 Batch   50/100   train_loss = 1.916\n",
      "Epoch 324 Batch   75/100   train_loss = 2.037\n",
      "Epoch 325 Batch    0/100   train_loss = 1.804\n",
      "Epoch 325 Batch   25/100   train_loss = 1.931\n",
      "Epoch 325 Batch   50/100   train_loss = 1.880\n",
      "Epoch 325 Batch   75/100   train_loss = 1.962\n",
      "Epoch 326 Batch    0/100   train_loss = 1.862\n",
      "Epoch 326 Batch   25/100   train_loss = 1.964\n",
      "Epoch 326 Batch   50/100   train_loss = 1.854\n",
      "Epoch 326 Batch   75/100   train_loss = 1.955\n",
      "Epoch 327 Batch    0/100   train_loss = 1.846\n",
      "Epoch 327 Batch   25/100   train_loss = 1.907\n",
      "Epoch 327 Batch   50/100   train_loss = 1.889\n",
      "Epoch 327 Batch   75/100   train_loss = 1.925\n",
      "Epoch 328 Batch    0/100   train_loss = 1.828\n",
      "Epoch 328 Batch   25/100   train_loss = 1.960\n",
      "Epoch 328 Batch   50/100   train_loss = 1.894\n",
      "Epoch 328 Batch   75/100   train_loss = 1.996\n",
      "Epoch 329 Batch    0/100   train_loss = 1.813\n",
      "Epoch 329 Batch   25/100   train_loss = 1.958\n",
      "Epoch 329 Batch   50/100   train_loss = 1.842\n",
      "Epoch 329 Batch   75/100   train_loss = 1.934\n",
      "Epoch 330 Batch    0/100   train_loss = 1.820\n",
      "Epoch 330 Batch   25/100   train_loss = 1.960\n",
      "Epoch 330 Batch   50/100   train_loss = 1.827\n",
      "Epoch 330 Batch   75/100   train_loss = 1.944\n",
      "Epoch 331 Batch    0/100   train_loss = 1.783\n",
      "Epoch 331 Batch   25/100   train_loss = 1.902\n",
      "Epoch 331 Batch   50/100   train_loss = 1.790\n",
      "Epoch 331 Batch   75/100   train_loss = 1.980\n",
      "Epoch 332 Batch    0/100   train_loss = 1.835\n",
      "Epoch 332 Batch   25/100   train_loss = 1.909\n",
      "Epoch 332 Batch   50/100   train_loss = 1.859\n",
      "Epoch 332 Batch   75/100   train_loss = 1.931\n",
      "Epoch 333 Batch    0/100   train_loss = 1.797\n",
      "Epoch 333 Batch   25/100   train_loss = 1.933\n",
      "Epoch 333 Batch   50/100   train_loss = 1.874\n",
      "Epoch 333 Batch   75/100   train_loss = 1.987\n",
      "Epoch 334 Batch    0/100   train_loss = 1.773\n",
      "Epoch 334 Batch   25/100   train_loss = 1.942\n",
      "Epoch 334 Batch   50/100   train_loss = 1.808\n",
      "Epoch 334 Batch   75/100   train_loss = 1.893\n",
      "Epoch 335 Batch    0/100   train_loss = 1.795\n",
      "Epoch 335 Batch   25/100   train_loss = 1.917\n",
      "Epoch 335 Batch   50/100   train_loss = 1.788\n",
      "Epoch 335 Batch   75/100   train_loss = 1.875\n",
      "Epoch 336 Batch    0/100   train_loss = 1.799\n",
      "Epoch 336 Batch   25/100   train_loss = 1.889\n",
      "Epoch 336 Batch   50/100   train_loss = 1.823\n",
      "Epoch 336 Batch   75/100   train_loss = 1.939\n",
      "Epoch 337 Batch    0/100   train_loss = 1.768\n",
      "Epoch 337 Batch   25/100   train_loss = 1.826\n",
      "Epoch 337 Batch   50/100   train_loss = 1.728\n",
      "Epoch 337 Batch   75/100   train_loss = 1.921\n",
      "Epoch 338 Batch    0/100   train_loss = 1.794\n",
      "Epoch 338 Batch   25/100   train_loss = 1.819\n",
      "Epoch 338 Batch   50/100   train_loss = 1.707\n",
      "Epoch 338 Batch   75/100   train_loss = 1.816\n",
      "Epoch 339 Batch    0/100   train_loss = 1.810\n",
      "Epoch 339 Batch   25/100   train_loss = 1.869\n",
      "Epoch 339 Batch   50/100   train_loss = 1.848\n",
      "Epoch 339 Batch   75/100   train_loss = 1.910\n",
      "Epoch 340 Batch    0/100   train_loss = 1.840\n",
      "Epoch 340 Batch   25/100   train_loss = 1.823\n",
      "Epoch 340 Batch   50/100   train_loss = 1.797\n",
      "Epoch 340 Batch   75/100   train_loss = 1.843\n",
      "Epoch 341 Batch    0/100   train_loss = 1.771\n",
      "Epoch 341 Batch   25/100   train_loss = 1.877\n",
      "Epoch 341 Batch   50/100   train_loss = 1.831\n",
      "Epoch 341 Batch   75/100   train_loss = 1.913\n",
      "Epoch 342 Batch    0/100   train_loss = 1.792\n",
      "Epoch 342 Batch   25/100   train_loss = 1.855\n",
      "Epoch 342 Batch   50/100   train_loss = 1.722\n",
      "Epoch 342 Batch   75/100   train_loss = 1.862\n",
      "Epoch 343 Batch    0/100   train_loss = 1.787\n",
      "Epoch 343 Batch   25/100   train_loss = 1.876\n",
      "Epoch 343 Batch   50/100   train_loss = 1.794\n",
      "Epoch 343 Batch   75/100   train_loss = 1.839\n",
      "Epoch 344 Batch    0/100   train_loss = 1.737\n",
      "Epoch 344 Batch   25/100   train_loss = 1.948\n",
      "Epoch 344 Batch   50/100   train_loss = 1.800\n",
      "Epoch 344 Batch   75/100   train_loss = 1.878\n",
      "Epoch 345 Batch    0/100   train_loss = 1.700\n",
      "Epoch 345 Batch   25/100   train_loss = 1.810\n",
      "Epoch 345 Batch   50/100   train_loss = 1.744\n",
      "Epoch 345 Batch   75/100   train_loss = 1.862\n",
      "Epoch 346 Batch    0/100   train_loss = 1.803\n",
      "Epoch 346 Batch   25/100   train_loss = 1.810\n",
      "Epoch 346 Batch   50/100   train_loss = 1.727\n",
      "Epoch 346 Batch   75/100   train_loss = 1.915\n",
      "Epoch 347 Batch    0/100   train_loss = 1.835\n",
      "Epoch 347 Batch   25/100   train_loss = 1.824\n",
      "Epoch 347 Batch   50/100   train_loss = 1.772\n",
      "Epoch 347 Batch   75/100   train_loss = 1.857\n",
      "Epoch 348 Batch    0/100   train_loss = 1.739\n",
      "Epoch 348 Batch   25/100   train_loss = 1.896\n",
      "Epoch 348 Batch   50/100   train_loss = 1.741\n",
      "Epoch 348 Batch   75/100   train_loss = 1.843\n",
      "Epoch 349 Batch    0/100   train_loss = 1.674\n",
      "Epoch 349 Batch   25/100   train_loss = 1.841\n",
      "Epoch 349 Batch   50/100   train_loss = 1.731\n",
      "Epoch 349 Batch   75/100   train_loss = 1.821\n",
      "Epoch 350 Batch    0/100   train_loss = 1.711\n",
      "Epoch 350 Batch   25/100   train_loss = 1.800\n",
      "Epoch 350 Batch   50/100   train_loss = 1.718\n",
      "Epoch 350 Batch   75/100   train_loss = 1.823\n",
      "Epoch 351 Batch    0/100   train_loss = 1.732\n",
      "Epoch 351 Batch   25/100   train_loss = 1.858\n",
      "Epoch 351 Batch   50/100   train_loss = 1.763\n",
      "Epoch 351 Batch   75/100   train_loss = 1.808\n",
      "Epoch 352 Batch    0/100   train_loss = 1.694\n",
      "Epoch 352 Batch   25/100   train_loss = 1.891\n",
      "Epoch 352 Batch   50/100   train_loss = 1.718\n",
      "Epoch 352 Batch   75/100   train_loss = 1.814\n",
      "Epoch 353 Batch    0/100   train_loss = 1.729\n",
      "Epoch 353 Batch   25/100   train_loss = 1.786\n",
      "Epoch 353 Batch   50/100   train_loss = 1.734\n",
      "Epoch 353 Batch   75/100   train_loss = 1.836\n",
      "Epoch 354 Batch    0/100   train_loss = 1.695\n",
      "Epoch 354 Batch   25/100   train_loss = 1.772\n",
      "Epoch 354 Batch   50/100   train_loss = 1.680\n",
      "Epoch 354 Batch   75/100   train_loss = 1.806\n",
      "Epoch 355 Batch    0/100   train_loss = 1.702\n",
      "Epoch 355 Batch   25/100   train_loss = 1.859\n",
      "Epoch 355 Batch   50/100   train_loss = 1.670\n",
      "Epoch 355 Batch   75/100   train_loss = 1.700\n",
      "Epoch 356 Batch    0/100   train_loss = 1.702\n",
      "Epoch 356 Batch   25/100   train_loss = 1.762\n",
      "Epoch 356 Batch   50/100   train_loss = 1.697\n",
      "Epoch 356 Batch   75/100   train_loss = 1.824\n",
      "Epoch 357 Batch    0/100   train_loss = 1.653\n",
      "Epoch 357 Batch   25/100   train_loss = 1.876\n",
      "Epoch 357 Batch   50/100   train_loss = 1.758\n",
      "Epoch 357 Batch   75/100   train_loss = 1.775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358 Batch    0/100   train_loss = 1.685\n",
      "Epoch 358 Batch   25/100   train_loss = 1.774\n",
      "Epoch 358 Batch   50/100   train_loss = 1.666\n",
      "Epoch 358 Batch   75/100   train_loss = 1.773\n",
      "Epoch 359 Batch    0/100   train_loss = 1.666\n",
      "Epoch 359 Batch   25/100   train_loss = 1.835\n",
      "Epoch 359 Batch   50/100   train_loss = 1.695\n",
      "Epoch 359 Batch   75/100   train_loss = 1.745\n",
      "Epoch 360 Batch    0/100   train_loss = 1.704\n",
      "Epoch 360 Batch   25/100   train_loss = 1.720\n",
      "Epoch 360 Batch   50/100   train_loss = 1.671\n",
      "Epoch 360 Batch   75/100   train_loss = 1.732\n",
      "Epoch 361 Batch    0/100   train_loss = 1.689\n",
      "Epoch 361 Batch   25/100   train_loss = 1.760\n",
      "Epoch 361 Batch   50/100   train_loss = 1.664\n",
      "Epoch 361 Batch   75/100   train_loss = 1.770\n",
      "Epoch 362 Batch    0/100   train_loss = 1.703\n",
      "Epoch 362 Batch   25/100   train_loss = 1.791\n",
      "Epoch 362 Batch   50/100   train_loss = 1.718\n",
      "Epoch 362 Batch   75/100   train_loss = 1.759\n",
      "Epoch 363 Batch    0/100   train_loss = 1.703\n",
      "Epoch 363 Batch   25/100   train_loss = 1.789\n",
      "Epoch 363 Batch   50/100   train_loss = 1.725\n",
      "Epoch 363 Batch   75/100   train_loss = 1.721\n",
      "Epoch 364 Batch    0/100   train_loss = 1.658\n",
      "Epoch 364 Batch   25/100   train_loss = 1.716\n",
      "Epoch 364 Batch   50/100   train_loss = 1.679\n",
      "Epoch 364 Batch   75/100   train_loss = 1.742\n",
      "Epoch 365 Batch    0/100   train_loss = 1.663\n",
      "Epoch 365 Batch   25/100   train_loss = 1.769\n",
      "Epoch 365 Batch   50/100   train_loss = 1.707\n",
      "Epoch 365 Batch   75/100   train_loss = 1.782\n",
      "Epoch 366 Batch    0/100   train_loss = 1.603\n",
      "Epoch 366 Batch   25/100   train_loss = 1.727\n",
      "Epoch 366 Batch   50/100   train_loss = 1.630\n",
      "Epoch 366 Batch   75/100   train_loss = 1.697\n",
      "Epoch 367 Batch    0/100   train_loss = 1.680\n",
      "Epoch 367 Batch   25/100   train_loss = 1.762\n",
      "Epoch 367 Batch   50/100   train_loss = 1.650\n",
      "Epoch 367 Batch   75/100   train_loss = 1.745\n",
      "Epoch 368 Batch    0/100   train_loss = 1.696\n",
      "Epoch 368 Batch   25/100   train_loss = 1.785\n",
      "Epoch 368 Batch   50/100   train_loss = 1.661\n",
      "Epoch 368 Batch   75/100   train_loss = 1.737\n",
      "Epoch 369 Batch    0/100   train_loss = 1.685\n",
      "Epoch 369 Batch   25/100   train_loss = 1.802\n",
      "Epoch 369 Batch   50/100   train_loss = 1.672\n",
      "Epoch 369 Batch   75/100   train_loss = 1.713\n",
      "Epoch 370 Batch    0/100   train_loss = 1.593\n",
      "Epoch 370 Batch   25/100   train_loss = 1.711\n",
      "Epoch 370 Batch   50/100   train_loss = 1.605\n",
      "Epoch 370 Batch   75/100   train_loss = 1.732\n",
      "Epoch 371 Batch    0/100   train_loss = 1.604\n",
      "Epoch 371 Batch   25/100   train_loss = 1.699\n",
      "Epoch 371 Batch   50/100   train_loss = 1.628\n",
      "Epoch 371 Batch   75/100   train_loss = 1.729\n",
      "Epoch 372 Batch    0/100   train_loss = 1.595\n",
      "Epoch 372 Batch   25/100   train_loss = 1.682\n",
      "Epoch 372 Batch   50/100   train_loss = 1.609\n",
      "Epoch 372 Batch   75/100   train_loss = 1.697\n",
      "Epoch 373 Batch    0/100   train_loss = 1.636\n",
      "Epoch 373 Batch   25/100   train_loss = 1.766\n",
      "Epoch 373 Batch   50/100   train_loss = 1.642\n",
      "Epoch 373 Batch   75/100   train_loss = 1.708\n",
      "Epoch 374 Batch    0/100   train_loss = 1.630\n",
      "Epoch 374 Batch   25/100   train_loss = 1.726\n",
      "Epoch 374 Batch   50/100   train_loss = 1.628\n",
      "Epoch 374 Batch   75/100   train_loss = 1.654\n",
      "Epoch 375 Batch    0/100   train_loss = 1.624\n",
      "Epoch 375 Batch   25/100   train_loss = 1.708\n",
      "Epoch 375 Batch   50/100   train_loss = 1.588\n",
      "Epoch 375 Batch   75/100   train_loss = 1.751\n",
      "Epoch 376 Batch    0/100   train_loss = 1.677\n",
      "Epoch 376 Batch   25/100   train_loss = 1.769\n",
      "Epoch 376 Batch   50/100   train_loss = 1.689\n",
      "Epoch 376 Batch   75/100   train_loss = 1.677\n",
      "Epoch 377 Batch    0/100   train_loss = 1.608\n",
      "Epoch 377 Batch   25/100   train_loss = 1.735\n",
      "Epoch 377 Batch   50/100   train_loss = 1.595\n",
      "Epoch 377 Batch   75/100   train_loss = 1.647\n",
      "Epoch 378 Batch    0/100   train_loss = 1.669\n",
      "Epoch 378 Batch   25/100   train_loss = 1.750\n",
      "Epoch 378 Batch   50/100   train_loss = 1.568\n",
      "Epoch 378 Batch   75/100   train_loss = 1.671\n",
      "Epoch 379 Batch    0/100   train_loss = 1.633\n",
      "Epoch 379 Batch   25/100   train_loss = 1.710\n",
      "Epoch 379 Batch   50/100   train_loss = 1.614\n",
      "Epoch 379 Batch   75/100   train_loss = 1.711\n",
      "Epoch 380 Batch    0/100   train_loss = 1.664\n",
      "Epoch 380 Batch   25/100   train_loss = 1.723\n",
      "Epoch 380 Batch   50/100   train_loss = 1.538\n",
      "Epoch 380 Batch   75/100   train_loss = 1.656\n",
      "Epoch 381 Batch    0/100   train_loss = 1.537\n",
      "Epoch 381 Batch   25/100   train_loss = 1.691\n",
      "Epoch 381 Batch   50/100   train_loss = 1.565\n",
      "Epoch 381 Batch   75/100   train_loss = 1.642\n",
      "Epoch 382 Batch    0/100   train_loss = 1.609\n",
      "Epoch 382 Batch   25/100   train_loss = 1.710\n",
      "Epoch 382 Batch   50/100   train_loss = 1.538\n",
      "Epoch 382 Batch   75/100   train_loss = 1.691\n",
      "Epoch 383 Batch    0/100   train_loss = 1.567\n",
      "Epoch 383 Batch   25/100   train_loss = 1.632\n",
      "Epoch 383 Batch   50/100   train_loss = 1.559\n",
      "Epoch 383 Batch   75/100   train_loss = 1.694\n",
      "Epoch 384 Batch    0/100   train_loss = 1.520\n",
      "Epoch 384 Batch   25/100   train_loss = 1.750\n",
      "Epoch 384 Batch   50/100   train_loss = 1.532\n",
      "Epoch 384 Batch   75/100   train_loss = 1.675\n",
      "Epoch 385 Batch    0/100   train_loss = 1.528\n",
      "Epoch 385 Batch   25/100   train_loss = 1.680\n",
      "Epoch 385 Batch   50/100   train_loss = 1.551\n",
      "Epoch 385 Batch   75/100   train_loss = 1.713\n",
      "Epoch 386 Batch    0/100   train_loss = 1.547\n",
      "Epoch 386 Batch   25/100   train_loss = 1.633\n",
      "Epoch 386 Batch   50/100   train_loss = 1.611\n",
      "Epoch 386 Batch   75/100   train_loss = 1.663\n",
      "Epoch 387 Batch    0/100   train_loss = 1.565\n",
      "Epoch 387 Batch   25/100   train_loss = 1.641\n",
      "Epoch 387 Batch   50/100   train_loss = 1.579\n",
      "Epoch 387 Batch   75/100   train_loss = 1.678\n",
      "Epoch 388 Batch    0/100   train_loss = 1.557\n",
      "Epoch 388 Batch   25/100   train_loss = 1.642\n",
      "Epoch 388 Batch   50/100   train_loss = 1.570\n",
      "Epoch 388 Batch   75/100   train_loss = 1.615\n",
      "Epoch 389 Batch    0/100   train_loss = 1.564\n",
      "Epoch 389 Batch   25/100   train_loss = 1.670\n",
      "Epoch 389 Batch   50/100   train_loss = 1.565\n",
      "Epoch 389 Batch   75/100   train_loss = 1.618\n",
      "Epoch 390 Batch    0/100   train_loss = 1.535\n",
      "Epoch 390 Batch   25/100   train_loss = 1.619\n",
      "Epoch 390 Batch   50/100   train_loss = 1.571\n",
      "Epoch 390 Batch   75/100   train_loss = 1.585\n",
      "Epoch 391 Batch    0/100   train_loss = 1.503\n",
      "Epoch 391 Batch   25/100   train_loss = 1.662\n",
      "Epoch 391 Batch   50/100   train_loss = 1.630\n",
      "Epoch 391 Batch   75/100   train_loss = 1.644\n",
      "Epoch 392 Batch    0/100   train_loss = 1.511\n",
      "Epoch 392 Batch   25/100   train_loss = 1.578\n",
      "Epoch 392 Batch   50/100   train_loss = 1.605\n",
      "Epoch 392 Batch   75/100   train_loss = 1.646\n",
      "Epoch 393 Batch    0/100   train_loss = 1.519\n",
      "Epoch 393 Batch   25/100   train_loss = 1.561\n",
      "Epoch 393 Batch   50/100   train_loss = 1.508\n",
      "Epoch 393 Batch   75/100   train_loss = 1.636\n",
      "Epoch 394 Batch    0/100   train_loss = 1.528\n",
      "Epoch 394 Batch   25/100   train_loss = 1.618\n",
      "Epoch 394 Batch   50/100   train_loss = 1.512\n",
      "Epoch 394 Batch   75/100   train_loss = 1.673\n",
      "Epoch 395 Batch    0/100   train_loss = 1.509\n",
      "Epoch 395 Batch   25/100   train_loss = 1.567\n",
      "Epoch 395 Batch   50/100   train_loss = 1.529\n",
      "Epoch 395 Batch   75/100   train_loss = 1.661\n",
      "Epoch 396 Batch    0/100   train_loss = 1.589\n",
      "Epoch 396 Batch   25/100   train_loss = 1.625\n",
      "Epoch 396 Batch   50/100   train_loss = 1.486\n",
      "Epoch 396 Batch   75/100   train_loss = 1.641\n",
      "Epoch 397 Batch    0/100   train_loss = 1.522\n",
      "Epoch 397 Batch   25/100   train_loss = 1.622\n",
      "Epoch 397 Batch   50/100   train_loss = 1.513\n",
      "Epoch 397 Batch   75/100   train_loss = 1.623\n",
      "Epoch 398 Batch    0/100   train_loss = 1.563\n",
      "Epoch 398 Batch   25/100   train_loss = 1.578\n",
      "Epoch 398 Batch   50/100   train_loss = 1.546\n",
      "Epoch 398 Batch   75/100   train_loss = 1.619\n",
      "Epoch 399 Batch    0/100   train_loss = 1.490\n",
      "Epoch 399 Batch   25/100   train_loss = 1.565\n",
      "Epoch 399 Batch   50/100   train_loss = 1.567\n",
      "Epoch 399 Batch   75/100   train_loss = 1.575\n",
      "Epoch 400 Batch    0/100   train_loss = 1.556\n",
      "Epoch 400 Batch   25/100   train_loss = 1.561\n",
      "Epoch 400 Batch   50/100   train_loss = 1.529\n",
      "Epoch 400 Batch   75/100   train_loss = 1.566\n",
      "Epoch 401 Batch    0/100   train_loss = 1.505\n",
      "Epoch 401 Batch   25/100   train_loss = 1.540\n",
      "Epoch 401 Batch   50/100   train_loss = 1.500\n",
      "Epoch 401 Batch   75/100   train_loss = 1.556\n",
      "Epoch 402 Batch    0/100   train_loss = 1.469\n",
      "Epoch 402 Batch   25/100   train_loss = 1.618\n",
      "Epoch 402 Batch   50/100   train_loss = 1.506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402 Batch   75/100   train_loss = 1.594\n",
      "Epoch 403 Batch    0/100   train_loss = 1.451\n",
      "Epoch 403 Batch   25/100   train_loss = 1.604\n",
      "Epoch 403 Batch   50/100   train_loss = 1.489\n",
      "Epoch 403 Batch   75/100   train_loss = 1.566\n",
      "Epoch 404 Batch    0/100   train_loss = 1.493\n",
      "Epoch 404 Batch   25/100   train_loss = 1.491\n",
      "Epoch 404 Batch   50/100   train_loss = 1.522\n",
      "Epoch 404 Batch   75/100   train_loss = 1.542\n",
      "Epoch 405 Batch    0/100   train_loss = 1.484\n",
      "Epoch 405 Batch   25/100   train_loss = 1.517\n",
      "Epoch 405 Batch   50/100   train_loss = 1.491\n",
      "Epoch 405 Batch   75/100   train_loss = 1.529\n",
      "Epoch 406 Batch    0/100   train_loss = 1.492\n",
      "Epoch 406 Batch   25/100   train_loss = 1.543\n",
      "Epoch 406 Batch   50/100   train_loss = 1.454\n",
      "Epoch 406 Batch   75/100   train_loss = 1.585\n",
      "Epoch 407 Batch    0/100   train_loss = 1.451\n",
      "Epoch 407 Batch   25/100   train_loss = 1.559\n",
      "Epoch 407 Batch   50/100   train_loss = 1.491\n",
      "Epoch 407 Batch   75/100   train_loss = 1.541\n",
      "Epoch 408 Batch    0/100   train_loss = 1.516\n",
      "Epoch 408 Batch   25/100   train_loss = 1.573\n",
      "Epoch 408 Batch   50/100   train_loss = 1.473\n",
      "Epoch 408 Batch   75/100   train_loss = 1.535\n",
      "Epoch 409 Batch    0/100   train_loss = 1.428\n",
      "Epoch 409 Batch   25/100   train_loss = 1.590\n",
      "Epoch 409 Batch   50/100   train_loss = 1.511\n",
      "Epoch 409 Batch   75/100   train_loss = 1.541\n",
      "Epoch 410 Batch    0/100   train_loss = 1.403\n",
      "Epoch 410 Batch   25/100   train_loss = 1.564\n",
      "Epoch 410 Batch   50/100   train_loss = 1.457\n",
      "Epoch 410 Batch   75/100   train_loss = 1.502\n",
      "Epoch 411 Batch    0/100   train_loss = 1.425\n",
      "Epoch 411 Batch   25/100   train_loss = 1.578\n",
      "Epoch 411 Batch   50/100   train_loss = 1.445\n",
      "Epoch 411 Batch   75/100   train_loss = 1.522\n",
      "Epoch 412 Batch    0/100   train_loss = 1.454\n",
      "Epoch 412 Batch   25/100   train_loss = 1.580\n",
      "Epoch 412 Batch   50/100   train_loss = 1.468\n",
      "Epoch 412 Batch   75/100   train_loss = 1.564\n",
      "Epoch 413 Batch    0/100   train_loss = 1.469\n",
      "Epoch 413 Batch   25/100   train_loss = 1.515\n",
      "Epoch 413 Batch   50/100   train_loss = 1.437\n",
      "Epoch 413 Batch   75/100   train_loss = 1.515\n",
      "Epoch 414 Batch    0/100   train_loss = 1.489\n",
      "Epoch 414 Batch   25/100   train_loss = 1.567\n",
      "Epoch 414 Batch   50/100   train_loss = 1.385\n",
      "Epoch 414 Batch   75/100   train_loss = 1.481\n",
      "Epoch 415 Batch    0/100   train_loss = 1.454\n",
      "Epoch 415 Batch   25/100   train_loss = 1.541\n",
      "Epoch 415 Batch   50/100   train_loss = 1.434\n",
      "Epoch 415 Batch   75/100   train_loss = 1.510\n",
      "Epoch 416 Batch    0/100   train_loss = 1.431\n",
      "Epoch 416 Batch   25/100   train_loss = 1.467\n",
      "Epoch 416 Batch   50/100   train_loss = 1.409\n",
      "Epoch 416 Batch   75/100   train_loss = 1.458\n",
      "Epoch 417 Batch    0/100   train_loss = 1.430\n",
      "Epoch 417 Batch   25/100   train_loss = 1.527\n",
      "Epoch 417 Batch   50/100   train_loss = 1.390\n",
      "Epoch 417 Batch   75/100   train_loss = 1.559\n",
      "Epoch 418 Batch    0/100   train_loss = 1.452\n",
      "Epoch 418 Batch   25/100   train_loss = 1.547\n",
      "Epoch 418 Batch   50/100   train_loss = 1.420\n",
      "Epoch 418 Batch   75/100   train_loss = 1.483\n",
      "Epoch 419 Batch    0/100   train_loss = 1.463\n",
      "Epoch 419 Batch   25/100   train_loss = 1.485\n",
      "Epoch 419 Batch   50/100   train_loss = 1.400\n",
      "Epoch 419 Batch   75/100   train_loss = 1.487\n",
      "Epoch 420 Batch    0/100   train_loss = 1.478\n",
      "Epoch 420 Batch   25/100   train_loss = 1.506\n",
      "Epoch 420 Batch   50/100   train_loss = 1.388\n",
      "Epoch 420 Batch   75/100   train_loss = 1.509\n",
      "Epoch 421 Batch    0/100   train_loss = 1.407\n",
      "Epoch 421 Batch   25/100   train_loss = 1.493\n",
      "Epoch 421 Batch   50/100   train_loss = 1.406\n",
      "Epoch 421 Batch   75/100   train_loss = 1.462\n",
      "Epoch 422 Batch    0/100   train_loss = 1.383\n",
      "Epoch 422 Batch   25/100   train_loss = 1.470\n",
      "Epoch 422 Batch   50/100   train_loss = 1.448\n",
      "Epoch 422 Batch   75/100   train_loss = 1.484\n",
      "Epoch 423 Batch    0/100   train_loss = 1.410\n",
      "Epoch 423 Batch   25/100   train_loss = 1.499\n",
      "Epoch 423 Batch   50/100   train_loss = 1.394\n",
      "Epoch 423 Batch   75/100   train_loss = 1.465\n",
      "Epoch 424 Batch    0/100   train_loss = 1.367\n",
      "Epoch 424 Batch   25/100   train_loss = 1.501\n",
      "Epoch 424 Batch   50/100   train_loss = 1.380\n",
      "Epoch 424 Batch   75/100   train_loss = 1.491\n",
      "Epoch 425 Batch    0/100   train_loss = 1.406\n",
      "Epoch 425 Batch   25/100   train_loss = 1.486\n",
      "Epoch 425 Batch   50/100   train_loss = 1.423\n",
      "Epoch 425 Batch   75/100   train_loss = 1.465\n",
      "Epoch 426 Batch    0/100   train_loss = 1.383\n",
      "Epoch 426 Batch   25/100   train_loss = 1.559\n",
      "Epoch 426 Batch   50/100   train_loss = 1.377\n",
      "Epoch 426 Batch   75/100   train_loss = 1.507\n",
      "Epoch 427 Batch    0/100   train_loss = 1.424\n",
      "Epoch 427 Batch   25/100   train_loss = 1.447\n",
      "Epoch 427 Batch   50/100   train_loss = 1.391\n",
      "Epoch 427 Batch   75/100   train_loss = 1.450\n",
      "Epoch 428 Batch    0/100   train_loss = 1.405\n",
      "Epoch 428 Batch   25/100   train_loss = 1.460\n",
      "Epoch 428 Batch   50/100   train_loss = 1.388\n",
      "Epoch 428 Batch   75/100   train_loss = 1.478\n",
      "Epoch 429 Batch    0/100   train_loss = 1.328\n",
      "Epoch 429 Batch   25/100   train_loss = 1.466\n",
      "Epoch 429 Batch   50/100   train_loss = 1.307\n",
      "Epoch 429 Batch   75/100   train_loss = 1.456\n",
      "Epoch 430 Batch    0/100   train_loss = 1.364\n",
      "Epoch 430 Batch   25/100   train_loss = 1.489\n",
      "Epoch 430 Batch   50/100   train_loss = 1.408\n",
      "Epoch 430 Batch   75/100   train_loss = 1.484\n",
      "Epoch 431 Batch    0/100   train_loss = 1.398\n",
      "Epoch 431 Batch   25/100   train_loss = 1.525\n",
      "Epoch 431 Batch   50/100   train_loss = 1.344\n",
      "Epoch 431 Batch   75/100   train_loss = 1.467\n",
      "Epoch 432 Batch    0/100   train_loss = 1.392\n",
      "Epoch 432 Batch   25/100   train_loss = 1.476\n",
      "Epoch 432 Batch   50/100   train_loss = 1.346\n",
      "Epoch 432 Batch   75/100   train_loss = 1.422\n",
      "Epoch 433 Batch    0/100   train_loss = 1.358\n",
      "Epoch 433 Batch   25/100   train_loss = 1.429\n",
      "Epoch 433 Batch   50/100   train_loss = 1.342\n",
      "Epoch 433 Batch   75/100   train_loss = 1.456\n",
      "Epoch 434 Batch    0/100   train_loss = 1.392\n",
      "Epoch 434 Batch   25/100   train_loss = 1.462\n",
      "Epoch 434 Batch   50/100   train_loss = 1.400\n",
      "Epoch 434 Batch   75/100   train_loss = 1.474\n",
      "Epoch 435 Batch    0/100   train_loss = 1.352\n",
      "Epoch 435 Batch   25/100   train_loss = 1.479\n",
      "Epoch 435 Batch   50/100   train_loss = 1.317\n",
      "Epoch 435 Batch   75/100   train_loss = 1.458\n",
      "Epoch 436 Batch    0/100   train_loss = 1.365\n",
      "Epoch 436 Batch   25/100   train_loss = 1.473\n",
      "Epoch 436 Batch   50/100   train_loss = 1.317\n",
      "Epoch 436 Batch   75/100   train_loss = 1.426\n",
      "Epoch 437 Batch    0/100   train_loss = 1.348\n",
      "Epoch 437 Batch   25/100   train_loss = 1.472\n",
      "Epoch 437 Batch   50/100   train_loss = 1.323\n",
      "Epoch 437 Batch   75/100   train_loss = 1.405\n",
      "Epoch 438 Batch    0/100   train_loss = 1.336\n",
      "Epoch 438 Batch   25/100   train_loss = 1.431\n",
      "Epoch 438 Batch   50/100   train_loss = 1.354\n",
      "Epoch 438 Batch   75/100   train_loss = 1.419\n",
      "Epoch 439 Batch    0/100   train_loss = 1.362\n",
      "Epoch 439 Batch   25/100   train_loss = 1.483\n",
      "Epoch 439 Batch   50/100   train_loss = 1.329\n",
      "Epoch 439 Batch   75/100   train_loss = 1.422\n",
      "Epoch 440 Batch    0/100   train_loss = 1.397\n",
      "Epoch 440 Batch   25/100   train_loss = 1.433\n",
      "Epoch 440 Batch   50/100   train_loss = 1.325\n",
      "Epoch 440 Batch   75/100   train_loss = 1.446\n",
      "Epoch 441 Batch    0/100   train_loss = 1.367\n",
      "Epoch 441 Batch   25/100   train_loss = 1.434\n",
      "Epoch 441 Batch   50/100   train_loss = 1.325\n",
      "Epoch 441 Batch   75/100   train_loss = 1.425\n",
      "Epoch 442 Batch    0/100   train_loss = 1.317\n",
      "Epoch 442 Batch   25/100   train_loss = 1.423\n",
      "Epoch 442 Batch   50/100   train_loss = 1.402\n",
      "Epoch 442 Batch   75/100   train_loss = 1.434\n",
      "Epoch 443 Batch    0/100   train_loss = 1.403\n",
      "Epoch 443 Batch   25/100   train_loss = 1.460\n",
      "Epoch 443 Batch   50/100   train_loss = 1.366\n",
      "Epoch 443 Batch   75/100   train_loss = 1.425\n",
      "Epoch 444 Batch    0/100   train_loss = 1.341\n",
      "Epoch 444 Batch   25/100   train_loss = 1.448\n",
      "Epoch 444 Batch   50/100   train_loss = 1.345\n",
      "Epoch 444 Batch   75/100   train_loss = 1.473\n",
      "Epoch 445 Batch    0/100   train_loss = 1.339\n",
      "Epoch 445 Batch   25/100   train_loss = 1.428\n",
      "Epoch 445 Batch   50/100   train_loss = 1.345\n",
      "Epoch 445 Batch   75/100   train_loss = 1.424\n",
      "Epoch 446 Batch    0/100   train_loss = 1.379\n",
      "Epoch 446 Batch   25/100   train_loss = 1.392\n",
      "Epoch 446 Batch   50/100   train_loss = 1.358\n",
      "Epoch 446 Batch   75/100   train_loss = 1.414\n",
      "Epoch 447 Batch    0/100   train_loss = 1.309\n",
      "Epoch 447 Batch   25/100   train_loss = 1.388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447 Batch   50/100   train_loss = 1.306\n",
      "Epoch 447 Batch   75/100   train_loss = 1.424\n",
      "Epoch 448 Batch    0/100   train_loss = 1.298\n",
      "Epoch 448 Batch   25/100   train_loss = 1.370\n",
      "Epoch 448 Batch   50/100   train_loss = 1.316\n",
      "Epoch 448 Batch   75/100   train_loss = 1.403\n",
      "Epoch 449 Batch    0/100   train_loss = 1.288\n",
      "Epoch 449 Batch   25/100   train_loss = 1.414\n",
      "Epoch 449 Batch   50/100   train_loss = 1.303\n",
      "Epoch 449 Batch   75/100   train_loss = 1.465\n",
      "Epoch 450 Batch    0/100   train_loss = 1.302\n",
      "Epoch 450 Batch   25/100   train_loss = 1.400\n",
      "Epoch 450 Batch   50/100   train_loss = 1.306\n",
      "Epoch 450 Batch   75/100   train_loss = 1.367\n",
      "Epoch 451 Batch    0/100   train_loss = 1.301\n",
      "Epoch 451 Batch   25/100   train_loss = 1.389\n",
      "Epoch 451 Batch   50/100   train_loss = 1.382\n",
      "Epoch 451 Batch   75/100   train_loss = 1.398\n",
      "Epoch 452 Batch    0/100   train_loss = 1.324\n",
      "Epoch 452 Batch   25/100   train_loss = 1.398\n",
      "Epoch 452 Batch   50/100   train_loss = 1.285\n",
      "Epoch 452 Batch   75/100   train_loss = 1.373\n",
      "Epoch 453 Batch    0/100   train_loss = 1.319\n",
      "Epoch 453 Batch   25/100   train_loss = 1.419\n",
      "Epoch 453 Batch   50/100   train_loss = 1.298\n",
      "Epoch 453 Batch   75/100   train_loss = 1.377\n",
      "Epoch 454 Batch    0/100   train_loss = 1.276\n",
      "Epoch 454 Batch   25/100   train_loss = 1.467\n",
      "Epoch 454 Batch   50/100   train_loss = 1.289\n",
      "Epoch 454 Batch   75/100   train_loss = 1.359\n",
      "Epoch 455 Batch    0/100   train_loss = 1.218\n",
      "Epoch 455 Batch   25/100   train_loss = 1.365\n",
      "Epoch 455 Batch   50/100   train_loss = 1.316\n",
      "Epoch 455 Batch   75/100   train_loss = 1.366\n",
      "Epoch 456 Batch    0/100   train_loss = 1.304\n",
      "Epoch 456 Batch   25/100   train_loss = 1.372\n",
      "Epoch 456 Batch   50/100   train_loss = 1.276\n",
      "Epoch 456 Batch   75/100   train_loss = 1.383\n",
      "Epoch 457 Batch    0/100   train_loss = 1.295\n",
      "Epoch 457 Batch   25/100   train_loss = 1.402\n",
      "Epoch 457 Batch   50/100   train_loss = 1.221\n",
      "Epoch 457 Batch   75/100   train_loss = 1.379\n",
      "Epoch 458 Batch    0/100   train_loss = 1.259\n",
      "Epoch 458 Batch   25/100   train_loss = 1.362\n",
      "Epoch 458 Batch   50/100   train_loss = 1.261\n",
      "Epoch 458 Batch   75/100   train_loss = 1.327\n",
      "Epoch 459 Batch    0/100   train_loss = 1.239\n",
      "Epoch 459 Batch   25/100   train_loss = 1.395\n",
      "Epoch 459 Batch   50/100   train_loss = 1.267\n",
      "Epoch 459 Batch   75/100   train_loss = 1.366\n",
      "Epoch 460 Batch    0/100   train_loss = 1.261\n",
      "Epoch 460 Batch   25/100   train_loss = 1.348\n",
      "Epoch 460 Batch   50/100   train_loss = 1.243\n",
      "Epoch 460 Batch   75/100   train_loss = 1.352\n",
      "Epoch 461 Batch    0/100   train_loss = 1.268\n",
      "Epoch 461 Batch   25/100   train_loss = 1.433\n",
      "Epoch 461 Batch   50/100   train_loss = 1.246\n",
      "Epoch 461 Batch   75/100   train_loss = 1.378\n",
      "Epoch 462 Batch    0/100   train_loss = 1.253\n",
      "Epoch 462 Batch   25/100   train_loss = 1.392\n",
      "Epoch 462 Batch   50/100   train_loss = 1.278\n",
      "Epoch 462 Batch   75/100   train_loss = 1.345\n",
      "Epoch 463 Batch    0/100   train_loss = 1.244\n",
      "Epoch 463 Batch   25/100   train_loss = 1.369\n",
      "Epoch 463 Batch   50/100   train_loss = 1.263\n",
      "Epoch 463 Batch   75/100   train_loss = 1.309\n",
      "Epoch 464 Batch    0/100   train_loss = 1.280\n",
      "Epoch 464 Batch   25/100   train_loss = 1.366\n",
      "Epoch 464 Batch   50/100   train_loss = 1.261\n",
      "Epoch 464 Batch   75/100   train_loss = 1.349\n",
      "Epoch 465 Batch    0/100   train_loss = 1.279\n",
      "Epoch 465 Batch   25/100   train_loss = 1.308\n",
      "Epoch 465 Batch   50/100   train_loss = 1.314\n",
      "Epoch 465 Batch   75/100   train_loss = 1.296\n",
      "Epoch 466 Batch    0/100   train_loss = 1.250\n",
      "Epoch 466 Batch   25/100   train_loss = 1.393\n",
      "Epoch 466 Batch   50/100   train_loss = 1.206\n",
      "Epoch 466 Batch   75/100   train_loss = 1.306\n",
      "Epoch 467 Batch    0/100   train_loss = 1.176\n",
      "Epoch 467 Batch   25/100   train_loss = 1.359\n",
      "Epoch 467 Batch   50/100   train_loss = 1.236\n",
      "Epoch 467 Batch   75/100   train_loss = 1.397\n",
      "Epoch 468 Batch    0/100   train_loss = 1.245\n",
      "Epoch 468 Batch   25/100   train_loss = 1.318\n",
      "Epoch 468 Batch   50/100   train_loss = 1.272\n",
      "Epoch 468 Batch   75/100   train_loss = 1.337\n",
      "Epoch 469 Batch    0/100   train_loss = 1.224\n",
      "Epoch 469 Batch   25/100   train_loss = 1.292\n",
      "Epoch 469 Batch   50/100   train_loss = 1.248\n",
      "Epoch 469 Batch   75/100   train_loss = 1.326\n",
      "Epoch 470 Batch    0/100   train_loss = 1.227\n",
      "Epoch 470 Batch   25/100   train_loss = 1.375\n",
      "Epoch 470 Batch   50/100   train_loss = 1.216\n",
      "Epoch 470 Batch   75/100   train_loss = 1.280\n",
      "Epoch 471 Batch    0/100   train_loss = 1.199\n",
      "Epoch 471 Batch   25/100   train_loss = 1.342\n",
      "Epoch 471 Batch   50/100   train_loss = 1.188\n",
      "Epoch 471 Batch   75/100   train_loss = 1.299\n",
      "Epoch 472 Batch    0/100   train_loss = 1.225\n",
      "Epoch 472 Batch   25/100   train_loss = 1.321\n",
      "Epoch 472 Batch   50/100   train_loss = 1.264\n",
      "Epoch 472 Batch   75/100   train_loss = 1.319\n",
      "Epoch 473 Batch    0/100   train_loss = 1.151\n",
      "Epoch 473 Batch   25/100   train_loss = 1.342\n",
      "Epoch 473 Batch   50/100   train_loss = 1.213\n",
      "Epoch 473 Batch   75/100   train_loss = 1.331\n",
      "Epoch 474 Batch    0/100   train_loss = 1.248\n",
      "Epoch 474 Batch   25/100   train_loss = 1.350\n",
      "Epoch 474 Batch   50/100   train_loss = 1.267\n",
      "Epoch 474 Batch   75/100   train_loss = 1.275\n",
      "Epoch 475 Batch    0/100   train_loss = 1.191\n",
      "Epoch 475 Batch   25/100   train_loss = 1.348\n",
      "Epoch 475 Batch   50/100   train_loss = 1.237\n",
      "Epoch 475 Batch   75/100   train_loss = 1.355\n",
      "Epoch 476 Batch    0/100   train_loss = 1.171\n",
      "Epoch 476 Batch   25/100   train_loss = 1.336\n",
      "Epoch 476 Batch   50/100   train_loss = 1.295\n",
      "Epoch 476 Batch   75/100   train_loss = 1.311\n",
      "Epoch 477 Batch    0/100   train_loss = 1.230\n",
      "Epoch 477 Batch   25/100   train_loss = 1.317\n",
      "Epoch 477 Batch   50/100   train_loss = 1.249\n",
      "Epoch 477 Batch   75/100   train_loss = 1.258\n",
      "Epoch 478 Batch    0/100   train_loss = 1.220\n",
      "Epoch 478 Batch   25/100   train_loss = 1.321\n",
      "Epoch 478 Batch   50/100   train_loss = 1.198\n",
      "Epoch 478 Batch   75/100   train_loss = 1.307\n",
      "Epoch 479 Batch    0/100   train_loss = 1.191\n",
      "Epoch 479 Batch   25/100   train_loss = 1.293\n",
      "Epoch 479 Batch   50/100   train_loss = 1.192\n",
      "Epoch 479 Batch   75/100   train_loss = 1.342\n",
      "Epoch 480 Batch    0/100   train_loss = 1.163\n",
      "Epoch 480 Batch   25/100   train_loss = 1.276\n",
      "Epoch 480 Batch   50/100   train_loss = 1.207\n",
      "Epoch 480 Batch   75/100   train_loss = 1.344\n",
      "Epoch 481 Batch    0/100   train_loss = 1.177\n",
      "Epoch 481 Batch   25/100   train_loss = 1.267\n",
      "Epoch 481 Batch   50/100   train_loss = 1.253\n",
      "Epoch 481 Batch   75/100   train_loss = 1.319\n",
      "Epoch 482 Batch    0/100   train_loss = 1.196\n",
      "Epoch 482 Batch   25/100   train_loss = 1.323\n",
      "Epoch 482 Batch   50/100   train_loss = 1.152\n",
      "Epoch 482 Batch   75/100   train_loss = 1.289\n",
      "Epoch 483 Batch    0/100   train_loss = 1.221\n",
      "Epoch 483 Batch   25/100   train_loss = 1.292\n",
      "Epoch 483 Batch   50/100   train_loss = 1.249\n",
      "Epoch 483 Batch   75/100   train_loss = 1.295\n",
      "Epoch 484 Batch    0/100   train_loss = 1.208\n",
      "Epoch 484 Batch   25/100   train_loss = 1.263\n",
      "Epoch 484 Batch   50/100   train_loss = 1.204\n",
      "Epoch 484 Batch   75/100   train_loss = 1.279\n",
      "Epoch 485 Batch    0/100   train_loss = 1.173\n",
      "Epoch 485 Batch   25/100   train_loss = 1.348\n",
      "Epoch 485 Batch   50/100   train_loss = 1.221\n",
      "Epoch 485 Batch   75/100   train_loss = 1.252\n",
      "Epoch 486 Batch    0/100   train_loss = 1.192\n",
      "Epoch 486 Batch   25/100   train_loss = 1.228\n",
      "Epoch 486 Batch   50/100   train_loss = 1.188\n",
      "Epoch 486 Batch   75/100   train_loss = 1.253\n",
      "Epoch 487 Batch    0/100   train_loss = 1.195\n",
      "Epoch 487 Batch   25/100   train_loss = 1.291\n",
      "Epoch 487 Batch   50/100   train_loss = 1.209\n",
      "Epoch 487 Batch   75/100   train_loss = 1.246\n",
      "Epoch 488 Batch    0/100   train_loss = 1.176\n",
      "Epoch 488 Batch   25/100   train_loss = 1.273\n",
      "Epoch 488 Batch   50/100   train_loss = 1.182\n",
      "Epoch 488 Batch   75/100   train_loss = 1.290\n",
      "Epoch 489 Batch    0/100   train_loss = 1.235\n",
      "Epoch 489 Batch   25/100   train_loss = 1.254\n",
      "Epoch 489 Batch   50/100   train_loss = 1.181\n",
      "Epoch 489 Batch   75/100   train_loss = 1.242\n",
      "Epoch 490 Batch    0/100   train_loss = 1.141\n",
      "Epoch 490 Batch   25/100   train_loss = 1.246\n",
      "Epoch 490 Batch   50/100   train_loss = 1.213\n",
      "Epoch 490 Batch   75/100   train_loss = 1.261\n",
      "Epoch 491 Batch    0/100   train_loss = 1.161\n",
      "Epoch 491 Batch   25/100   train_loss = 1.302\n",
      "Epoch 491 Batch   50/100   train_loss = 1.200\n",
      "Epoch 491 Batch   75/100   train_loss = 1.209\n",
      "Epoch 492 Batch    0/100   train_loss = 1.119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492 Batch   25/100   train_loss = 1.270\n",
      "Epoch 492 Batch   50/100   train_loss = 1.201\n",
      "Epoch 492 Batch   75/100   train_loss = 1.233\n",
      "Epoch 493 Batch    0/100   train_loss = 1.165\n",
      "Epoch 493 Batch   25/100   train_loss = 1.282\n",
      "Epoch 493 Batch   50/100   train_loss = 1.170\n",
      "Epoch 493 Batch   75/100   train_loss = 1.290\n",
      "Epoch 494 Batch    0/100   train_loss = 1.184\n",
      "Epoch 494 Batch   25/100   train_loss = 1.260\n",
      "Epoch 494 Batch   50/100   train_loss = 1.206\n",
      "Epoch 494 Batch   75/100   train_loss = 1.236\n",
      "Epoch 495 Batch    0/100   train_loss = 1.096\n",
      "Epoch 495 Batch   25/100   train_loss = 1.302\n",
      "Epoch 495 Batch   50/100   train_loss = 1.181\n",
      "Epoch 495 Batch   75/100   train_loss = 1.280\n",
      "Epoch 496 Batch    0/100   train_loss = 1.153\n",
      "Epoch 496 Batch   25/100   train_loss = 1.228\n",
      "Epoch 496 Batch   50/100   train_loss = 1.172\n",
      "Epoch 496 Batch   75/100   train_loss = 1.243\n",
      "Epoch 497 Batch    0/100   train_loss = 1.114\n",
      "Epoch 497 Batch   25/100   train_loss = 1.260\n",
      "Epoch 497 Batch   50/100   train_loss = 1.187\n",
      "Epoch 497 Batch   75/100   train_loss = 1.225\n",
      "Epoch 498 Batch    0/100   train_loss = 1.105\n",
      "Epoch 498 Batch   25/100   train_loss = 1.259\n",
      "Epoch 498 Batch   50/100   train_loss = 1.165\n",
      "Epoch 498 Batch   75/100   train_loss = 1.254\n",
      "Epoch 499 Batch    0/100   train_loss = 1.140\n",
      "Epoch 499 Batch   25/100   train_loss = 1.251\n",
      "Epoch 499 Batch   50/100   train_loss = 1.193\n",
      "Epoch 499 Batch   75/100   train_loss = 1.223\n",
      "Epoch 500 Batch    0/100   train_loss = 1.168\n",
      "Epoch 500 Batch   25/100   train_loss = 1.231\n",
      "Epoch 500 Batch   50/100   train_loss = 1.152\n",
      "Epoch 500 Batch   75/100   train_loss = 1.216\n",
      "Epoch 501 Batch    0/100   train_loss = 1.194\n",
      "Epoch 501 Batch   25/100   train_loss = 1.255\n",
      "Epoch 501 Batch   50/100   train_loss = 1.151\n",
      "Epoch 501 Batch   75/100   train_loss = 1.220\n",
      "Epoch 502 Batch    0/100   train_loss = 1.085\n",
      "Epoch 502 Batch   25/100   train_loss = 1.222\n",
      "Epoch 502 Batch   50/100   train_loss = 1.196\n",
      "Epoch 502 Batch   75/100   train_loss = 1.243\n",
      "Epoch 503 Batch    0/100   train_loss = 1.141\n",
      "Epoch 503 Batch   25/100   train_loss = 1.268\n",
      "Epoch 503 Batch   50/100   train_loss = 1.130\n",
      "Epoch 503 Batch   75/100   train_loss = 1.274\n",
      "Epoch 504 Batch    0/100   train_loss = 1.135\n",
      "Epoch 504 Batch   25/100   train_loss = 1.255\n",
      "Epoch 504 Batch   50/100   train_loss = 1.128\n",
      "Epoch 504 Batch   75/100   train_loss = 1.247\n",
      "Epoch 505 Batch    0/100   train_loss = 1.113\n",
      "Epoch 505 Batch   25/100   train_loss = 1.270\n",
      "Epoch 505 Batch   50/100   train_loss = 1.142\n",
      "Epoch 505 Batch   75/100   train_loss = 1.230\n",
      "Epoch 506 Batch    0/100   train_loss = 1.145\n",
      "Epoch 506 Batch   25/100   train_loss = 1.206\n",
      "Epoch 506 Batch   50/100   train_loss = 1.192\n",
      "Epoch 506 Batch   75/100   train_loss = 1.247\n",
      "Epoch 507 Batch    0/100   train_loss = 1.134\n",
      "Epoch 507 Batch   25/100   train_loss = 1.249\n",
      "Epoch 507 Batch   50/100   train_loss = 1.130\n",
      "Epoch 507 Batch   75/100   train_loss = 1.253\n",
      "Epoch 508 Batch    0/100   train_loss = 1.121\n",
      "Epoch 508 Batch   25/100   train_loss = 1.201\n",
      "Epoch 508 Batch   50/100   train_loss = 1.171\n",
      "Epoch 508 Batch   75/100   train_loss = 1.242\n",
      "Epoch 509 Batch    0/100   train_loss = 1.093\n",
      "Epoch 509 Batch   25/100   train_loss = 1.196\n",
      "Epoch 509 Batch   50/100   train_loss = 1.171\n",
      "Epoch 509 Batch   75/100   train_loss = 1.225\n",
      "Epoch 510 Batch    0/100   train_loss = 1.122\n",
      "Epoch 510 Batch   25/100   train_loss = 1.247\n",
      "Epoch 510 Batch   50/100   train_loss = 1.141\n",
      "Epoch 510 Batch   75/100   train_loss = 1.211\n",
      "Epoch 511 Batch    0/100   train_loss = 1.128\n",
      "Epoch 511 Batch   25/100   train_loss = 1.268\n",
      "Epoch 511 Batch   50/100   train_loss = 1.181\n",
      "Epoch 511 Batch   75/100   train_loss = 1.227\n",
      "Epoch 512 Batch    0/100   train_loss = 1.118\n",
      "Epoch 512 Batch   25/100   train_loss = 1.246\n",
      "Epoch 512 Batch   50/100   train_loss = 1.120\n",
      "Epoch 512 Batch   75/100   train_loss = 1.200\n",
      "Epoch 513 Batch    0/100   train_loss = 1.089\n",
      "Epoch 513 Batch   25/100   train_loss = 1.269\n",
      "Epoch 513 Batch   50/100   train_loss = 1.113\n",
      "Epoch 513 Batch   75/100   train_loss = 1.199\n",
      "Epoch 514 Batch    0/100   train_loss = 1.098\n",
      "Epoch 514 Batch   25/100   train_loss = 1.251\n",
      "Epoch 514 Batch   50/100   train_loss = 1.098\n",
      "Epoch 514 Batch   75/100   train_loss = 1.214\n",
      "Epoch 515 Batch    0/100   train_loss = 1.072\n",
      "Epoch 515 Batch   25/100   train_loss = 1.249\n",
      "Epoch 515 Batch   50/100   train_loss = 1.129\n",
      "Epoch 515 Batch   75/100   train_loss = 1.280\n",
      "Epoch 516 Batch    0/100   train_loss = 1.095\n",
      "Epoch 516 Batch   25/100   train_loss = 1.217\n",
      "Epoch 516 Batch   50/100   train_loss = 1.104\n",
      "Epoch 516 Batch   75/100   train_loss = 1.170\n",
      "Epoch 517 Batch    0/100   train_loss = 1.099\n",
      "Epoch 517 Batch   25/100   train_loss = 1.225\n",
      "Epoch 517 Batch   50/100   train_loss = 1.132\n",
      "Epoch 517 Batch   75/100   train_loss = 1.181\n",
      "Epoch 518 Batch    0/100   train_loss = 1.086\n",
      "Epoch 518 Batch   25/100   train_loss = 1.228\n",
      "Epoch 518 Batch   50/100   train_loss = 1.148\n",
      "Epoch 518 Batch   75/100   train_loss = 1.196\n",
      "Epoch 519 Batch    0/100   train_loss = 1.098\n",
      "Epoch 519 Batch   25/100   train_loss = 1.175\n",
      "Epoch 519 Batch   50/100   train_loss = 1.076\n",
      "Epoch 519 Batch   75/100   train_loss = 1.234\n",
      "Epoch 520 Batch    0/100   train_loss = 1.086\n",
      "Epoch 520 Batch   25/100   train_loss = 1.176\n",
      "Epoch 520 Batch   50/100   train_loss = 1.108\n",
      "Epoch 520 Batch   75/100   train_loss = 1.175\n",
      "Epoch 521 Batch    0/100   train_loss = 1.064\n",
      "Epoch 521 Batch   25/100   train_loss = 1.196\n",
      "Epoch 521 Batch   50/100   train_loss = 1.105\n",
      "Epoch 521 Batch   75/100   train_loss = 1.189\n",
      "Epoch 522 Batch    0/100   train_loss = 1.066\n",
      "Epoch 522 Batch   25/100   train_loss = 1.162\n",
      "Epoch 522 Batch   50/100   train_loss = 1.121\n",
      "Epoch 522 Batch   75/100   train_loss = 1.185\n",
      "Epoch 523 Batch    0/100   train_loss = 1.103\n",
      "Epoch 523 Batch   25/100   train_loss = 1.179\n",
      "Epoch 523 Batch   50/100   train_loss = 1.096\n",
      "Epoch 523 Batch   75/100   train_loss = 1.205\n",
      "Epoch 524 Batch    0/100   train_loss = 1.052\n",
      "Epoch 524 Batch   25/100   train_loss = 1.161\n",
      "Epoch 524 Batch   50/100   train_loss = 1.119\n",
      "Epoch 524 Batch   75/100   train_loss = 1.199\n",
      "Epoch 525 Batch    0/100   train_loss = 1.092\n",
      "Epoch 525 Batch   25/100   train_loss = 1.193\n",
      "Epoch 525 Batch   50/100   train_loss = 1.081\n",
      "Epoch 525 Batch   75/100   train_loss = 1.149\n",
      "Epoch 526 Batch    0/100   train_loss = 1.025\n",
      "Epoch 526 Batch   25/100   train_loss = 1.194\n",
      "Epoch 526 Batch   50/100   train_loss = 1.098\n",
      "Epoch 526 Batch   75/100   train_loss = 1.175\n",
      "Epoch 527 Batch    0/100   train_loss = 1.105\n",
      "Epoch 527 Batch   25/100   train_loss = 1.233\n",
      "Epoch 527 Batch   50/100   train_loss = 1.035\n",
      "Epoch 527 Batch   75/100   train_loss = 1.137\n",
      "Epoch 528 Batch    0/100   train_loss = 1.098\n",
      "Epoch 528 Batch   25/100   train_loss = 1.202\n",
      "Epoch 528 Batch   50/100   train_loss = 1.090\n",
      "Epoch 528 Batch   75/100   train_loss = 1.158\n",
      "Epoch 529 Batch    0/100   train_loss = 1.085\n",
      "Epoch 529 Batch   25/100   train_loss = 1.161\n",
      "Epoch 529 Batch   50/100   train_loss = 1.040\n",
      "Epoch 529 Batch   75/100   train_loss = 1.122\n",
      "Epoch 530 Batch    0/100   train_loss = 1.044\n",
      "Epoch 530 Batch   25/100   train_loss = 1.186\n",
      "Epoch 530 Batch   50/100   train_loss = 1.084\n",
      "Epoch 530 Batch   75/100   train_loss = 1.163\n",
      "Epoch 531 Batch    0/100   train_loss = 1.077\n",
      "Epoch 531 Batch   25/100   train_loss = 1.156\n",
      "Epoch 531 Batch   50/100   train_loss = 1.080\n",
      "Epoch 531 Batch   75/100   train_loss = 1.239\n",
      "Epoch 532 Batch    0/100   train_loss = 1.136\n",
      "Epoch 532 Batch   25/100   train_loss = 1.203\n",
      "Epoch 532 Batch   50/100   train_loss = 1.070\n",
      "Epoch 532 Batch   75/100   train_loss = 1.082\n",
      "Epoch 533 Batch    0/100   train_loss = 1.069\n",
      "Epoch 533 Batch   25/100   train_loss = 1.171\n",
      "Epoch 533 Batch   50/100   train_loss = 1.105\n",
      "Epoch 533 Batch   75/100   train_loss = 1.108\n",
      "Epoch 534 Batch    0/100   train_loss = 1.072\n",
      "Epoch 534 Batch   25/100   train_loss = 1.116\n",
      "Epoch 534 Batch   50/100   train_loss = 1.070\n",
      "Epoch 534 Batch   75/100   train_loss = 1.135\n",
      "Epoch 535 Batch    0/100   train_loss = 1.025\n",
      "Epoch 535 Batch   25/100   train_loss = 1.185\n",
      "Epoch 535 Batch   50/100   train_loss = 1.060\n",
      "Epoch 535 Batch   75/100   train_loss = 1.133\n",
      "Epoch 536 Batch    0/100   train_loss = 1.043\n",
      "Epoch 536 Batch   25/100   train_loss = 1.142\n",
      "Epoch 536 Batch   50/100   train_loss = 1.076\n",
      "Epoch 536 Batch   75/100   train_loss = 1.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 537 Batch    0/100   train_loss = 1.070\n",
      "Epoch 537 Batch   25/100   train_loss = 1.160\n",
      "Epoch 537 Batch   50/100   train_loss = 1.050\n",
      "Epoch 537 Batch   75/100   train_loss = 1.158\n",
      "Epoch 538 Batch    0/100   train_loss = 1.061\n",
      "Epoch 538 Batch   25/100   train_loss = 1.179\n",
      "Epoch 538 Batch   50/100   train_loss = 1.068\n",
      "Epoch 538 Batch   75/100   train_loss = 1.144\n",
      "Epoch 539 Batch    0/100   train_loss = 1.020\n",
      "Epoch 539 Batch   25/100   train_loss = 1.146\n",
      "Epoch 539 Batch   50/100   train_loss = 1.027\n",
      "Epoch 539 Batch   75/100   train_loss = 1.123\n",
      "Epoch 540 Batch    0/100   train_loss = 1.011\n",
      "Epoch 540 Batch   25/100   train_loss = 1.155\n",
      "Epoch 540 Batch   50/100   train_loss = 1.036\n",
      "Epoch 540 Batch   75/100   train_loss = 1.186\n",
      "Epoch 541 Batch    0/100   train_loss = 1.048\n",
      "Epoch 541 Batch   25/100   train_loss = 1.161\n",
      "Epoch 541 Batch   50/100   train_loss = 1.039\n",
      "Epoch 541 Batch   75/100   train_loss = 1.129\n",
      "Epoch 542 Batch    0/100   train_loss = 1.060\n",
      "Epoch 542 Batch   25/100   train_loss = 1.135\n",
      "Epoch 542 Batch   50/100   train_loss = 1.046\n",
      "Epoch 542 Batch   75/100   train_loss = 1.108\n",
      "Epoch 543 Batch    0/100   train_loss = 1.056\n",
      "Epoch 543 Batch   25/100   train_loss = 1.190\n",
      "Epoch 543 Batch   50/100   train_loss = 1.053\n",
      "Epoch 543 Batch   75/100   train_loss = 1.089\n",
      "Epoch 544 Batch    0/100   train_loss = 1.040\n",
      "Epoch 544 Batch   25/100   train_loss = 1.101\n",
      "Epoch 544 Batch   50/100   train_loss = 1.079\n",
      "Epoch 544 Batch   75/100   train_loss = 1.181\n",
      "Epoch 545 Batch    0/100   train_loss = 1.052\n",
      "Epoch 545 Batch   25/100   train_loss = 1.083\n",
      "Epoch 545 Batch   50/100   train_loss = 1.074\n",
      "Epoch 545 Batch   75/100   train_loss = 1.100\n",
      "Epoch 546 Batch    0/100   train_loss = 1.066\n",
      "Epoch 546 Batch   25/100   train_loss = 1.145\n",
      "Epoch 546 Batch   50/100   train_loss = 1.059\n",
      "Epoch 546 Batch   75/100   train_loss = 1.111\n",
      "Epoch 547 Batch    0/100   train_loss = 1.030\n",
      "Epoch 547 Batch   25/100   train_loss = 1.166\n",
      "Epoch 547 Batch   50/100   train_loss = 1.056\n",
      "Epoch 547 Batch   75/100   train_loss = 1.102\n",
      "Epoch 548 Batch    0/100   train_loss = 1.060\n",
      "Epoch 548 Batch   25/100   train_loss = 1.156\n",
      "Epoch 548 Batch   50/100   train_loss = 1.085\n",
      "Epoch 548 Batch   75/100   train_loss = 1.126\n",
      "Epoch 549 Batch    0/100   train_loss = 1.060\n",
      "Epoch 549 Batch   25/100   train_loss = 1.108\n",
      "Epoch 549 Batch   50/100   train_loss = 1.016\n",
      "Epoch 549 Batch   75/100   train_loss = 1.112\n",
      "Epoch 550 Batch    0/100   train_loss = 1.023\n",
      "Epoch 550 Batch   25/100   train_loss = 1.074\n",
      "Epoch 550 Batch   50/100   train_loss = 1.071\n",
      "Epoch 550 Batch   75/100   train_loss = 1.118\n",
      "Epoch 551 Batch    0/100   train_loss = 1.037\n",
      "Epoch 551 Batch   25/100   train_loss = 1.101\n",
      "Epoch 551 Batch   50/100   train_loss = 1.058\n",
      "Epoch 551 Batch   75/100   train_loss = 1.091\n",
      "Epoch 552 Batch    0/100   train_loss = 1.019\n",
      "Epoch 552 Batch   25/100   train_loss = 1.088\n",
      "Epoch 552 Batch   50/100   train_loss = 1.071\n",
      "Epoch 552 Batch   75/100   train_loss = 1.081\n",
      "Epoch 553 Batch    0/100   train_loss = 1.036\n",
      "Epoch 553 Batch   25/100   train_loss = 1.128\n",
      "Epoch 553 Batch   50/100   train_loss = 1.010\n",
      "Epoch 553 Batch   75/100   train_loss = 1.096\n",
      "Epoch 554 Batch    0/100   train_loss = 1.048\n",
      "Epoch 554 Batch   25/100   train_loss = 1.094\n",
      "Epoch 554 Batch   50/100   train_loss = 1.023\n",
      "Epoch 554 Batch   75/100   train_loss = 1.113\n",
      "Epoch 555 Batch    0/100   train_loss = 1.003\n",
      "Epoch 555 Batch   25/100   train_loss = 1.103\n",
      "Epoch 555 Batch   50/100   train_loss = 1.012\n",
      "Epoch 555 Batch   75/100   train_loss = 1.134\n",
      "Epoch 556 Batch    0/100   train_loss = 1.011\n",
      "Epoch 556 Batch   25/100   train_loss = 1.128\n",
      "Epoch 556 Batch   50/100   train_loss = 1.037\n",
      "Epoch 556 Batch   75/100   train_loss = 1.109\n",
      "Epoch 557 Batch    0/100   train_loss = 0.957\n",
      "Epoch 557 Batch   25/100   train_loss = 1.081\n",
      "Epoch 557 Batch   50/100   train_loss = 1.074\n",
      "Epoch 557 Batch   75/100   train_loss = 1.077\n",
      "Epoch 558 Batch    0/100   train_loss = 0.953\n",
      "Epoch 558 Batch   25/100   train_loss = 1.092\n",
      "Epoch 558 Batch   50/100   train_loss = 1.013\n",
      "Epoch 558 Batch   75/100   train_loss = 1.128\n",
      "Epoch 559 Batch    0/100   train_loss = 1.007\n",
      "Epoch 559 Batch   25/100   train_loss = 1.111\n",
      "Epoch 559 Batch   50/100   train_loss = 1.017\n",
      "Epoch 559 Batch   75/100   train_loss = 1.108\n",
      "Epoch 560 Batch    0/100   train_loss = 0.986\n",
      "Epoch 560 Batch   25/100   train_loss = 1.074\n",
      "Epoch 560 Batch   50/100   train_loss = 1.012\n",
      "Epoch 560 Batch   75/100   train_loss = 1.144\n",
      "Epoch 561 Batch    0/100   train_loss = 0.970\n",
      "Epoch 561 Batch   25/100   train_loss = 1.096\n",
      "Epoch 561 Batch   50/100   train_loss = 0.978\n",
      "Epoch 561 Batch   75/100   train_loss = 1.088\n",
      "Epoch 562 Batch    0/100   train_loss = 1.001\n",
      "Epoch 562 Batch   25/100   train_loss = 1.149\n",
      "Epoch 562 Batch   50/100   train_loss = 1.007\n",
      "Epoch 562 Batch   75/100   train_loss = 1.041\n",
      "Epoch 563 Batch    0/100   train_loss = 0.984\n",
      "Epoch 563 Batch   25/100   train_loss = 1.108\n",
      "Epoch 563 Batch   50/100   train_loss = 1.015\n",
      "Epoch 563 Batch   75/100   train_loss = 1.089\n",
      "Epoch 564 Batch    0/100   train_loss = 0.973\n",
      "Epoch 564 Batch   25/100   train_loss = 1.070\n",
      "Epoch 564 Batch   50/100   train_loss = 1.036\n",
      "Epoch 564 Batch   75/100   train_loss = 1.109\n",
      "Epoch 565 Batch    0/100   train_loss = 0.941\n",
      "Epoch 565 Batch   25/100   train_loss = 1.117\n",
      "Epoch 565 Batch   50/100   train_loss = 1.030\n",
      "Epoch 565 Batch   75/100   train_loss = 1.050\n",
      "Epoch 566 Batch    0/100   train_loss = 0.977\n",
      "Epoch 566 Batch   25/100   train_loss = 1.079\n",
      "Epoch 566 Batch   50/100   train_loss = 0.943\n",
      "Epoch 566 Batch   75/100   train_loss = 1.037\n",
      "Epoch 567 Batch    0/100   train_loss = 1.073\n",
      "Epoch 567 Batch   25/100   train_loss = 1.104\n",
      "Epoch 567 Batch   50/100   train_loss = 1.006\n",
      "Epoch 567 Batch   75/100   train_loss = 1.043\n",
      "Epoch 568 Batch    0/100   train_loss = 0.978\n",
      "Epoch 568 Batch   25/100   train_loss = 1.097\n",
      "Epoch 568 Batch   50/100   train_loss = 0.991\n",
      "Epoch 568 Batch   75/100   train_loss = 1.097\n",
      "Epoch 569 Batch    0/100   train_loss = 0.963\n",
      "Epoch 569 Batch   25/100   train_loss = 1.077\n",
      "Epoch 569 Batch   50/100   train_loss = 0.979\n",
      "Epoch 569 Batch   75/100   train_loss = 1.032\n",
      "Epoch 570 Batch    0/100   train_loss = 0.949\n",
      "Epoch 570 Batch   25/100   train_loss = 1.065\n",
      "Epoch 570 Batch   50/100   train_loss = 0.993\n",
      "Epoch 570 Batch   75/100   train_loss = 1.092\n",
      "Epoch 571 Batch    0/100   train_loss = 0.978\n",
      "Epoch 571 Batch   25/100   train_loss = 1.100\n",
      "Epoch 571 Batch   50/100   train_loss = 0.946\n",
      "Epoch 571 Batch   75/100   train_loss = 1.058\n",
      "Epoch 572 Batch    0/100   train_loss = 0.959\n",
      "Epoch 572 Batch   25/100   train_loss = 1.037\n",
      "Epoch 572 Batch   50/100   train_loss = 1.010\n",
      "Epoch 572 Batch   75/100   train_loss = 1.048\n",
      "Epoch 573 Batch    0/100   train_loss = 0.973\n",
      "Epoch 573 Batch   25/100   train_loss = 1.064\n",
      "Epoch 573 Batch   50/100   train_loss = 0.964\n",
      "Epoch 573 Batch   75/100   train_loss = 1.054\n",
      "Epoch 574 Batch    0/100   train_loss = 0.974\n",
      "Epoch 574 Batch   25/100   train_loss = 1.060\n",
      "Epoch 574 Batch   50/100   train_loss = 0.979\n",
      "Epoch 574 Batch   75/100   train_loss = 1.071\n",
      "Epoch 575 Batch    0/100   train_loss = 0.987\n",
      "Epoch 575 Batch   25/100   train_loss = 1.081\n",
      "Epoch 575 Batch   50/100   train_loss = 1.005\n",
      "Epoch 575 Batch   75/100   train_loss = 1.036\n",
      "Epoch 576 Batch    0/100   train_loss = 0.934\n",
      "Epoch 576 Batch   25/100   train_loss = 1.064\n",
      "Epoch 576 Batch   50/100   train_loss = 0.954\n",
      "Epoch 576 Batch   75/100   train_loss = 1.074\n",
      "Epoch 577 Batch    0/100   train_loss = 0.946\n",
      "Epoch 577 Batch   25/100   train_loss = 1.074\n",
      "Epoch 577 Batch   50/100   train_loss = 0.906\n",
      "Epoch 577 Batch   75/100   train_loss = 1.050\n",
      "Epoch 578 Batch    0/100   train_loss = 0.891\n",
      "Epoch 578 Batch   25/100   train_loss = 1.070\n",
      "Epoch 578 Batch   50/100   train_loss = 0.967\n",
      "Epoch 578 Batch   75/100   train_loss = 1.058\n",
      "Epoch 579 Batch    0/100   train_loss = 0.954\n",
      "Epoch 579 Batch   25/100   train_loss = 1.030\n",
      "Epoch 579 Batch   50/100   train_loss = 0.989\n",
      "Epoch 579 Batch   75/100   train_loss = 1.039\n",
      "Epoch 580 Batch    0/100   train_loss = 0.931\n",
      "Epoch 580 Batch   25/100   train_loss = 1.038\n",
      "Epoch 580 Batch   50/100   train_loss = 0.990\n",
      "Epoch 580 Batch   75/100   train_loss = 1.022\n",
      "Epoch 581 Batch    0/100   train_loss = 0.935\n",
      "Epoch 581 Batch   25/100   train_loss = 1.058\n",
      "Epoch 581 Batch   50/100   train_loss = 0.961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581 Batch   75/100   train_loss = 1.073\n",
      "Epoch 582 Batch    0/100   train_loss = 0.957\n",
      "Epoch 582 Batch   25/100   train_loss = 1.093\n",
      "Epoch 582 Batch   50/100   train_loss = 0.973\n",
      "Epoch 582 Batch   75/100   train_loss = 1.076\n",
      "Epoch 583 Batch    0/100   train_loss = 0.938\n",
      "Epoch 583 Batch   25/100   train_loss = 1.011\n",
      "Epoch 583 Batch   50/100   train_loss = 0.938\n",
      "Epoch 583 Batch   75/100   train_loss = 1.086\n",
      "Epoch 584 Batch    0/100   train_loss = 0.889\n",
      "Epoch 584 Batch   25/100   train_loss = 1.038\n",
      "Epoch 584 Batch   50/100   train_loss = 0.944\n",
      "Epoch 584 Batch   75/100   train_loss = 1.031\n",
      "Epoch 585 Batch    0/100   train_loss = 0.927\n",
      "Epoch 585 Batch   25/100   train_loss = 1.080\n",
      "Epoch 585 Batch   50/100   train_loss = 0.966\n",
      "Epoch 585 Batch   75/100   train_loss = 1.016\n",
      "Epoch 586 Batch    0/100   train_loss = 0.974\n",
      "Epoch 586 Batch   25/100   train_loss = 1.049\n",
      "Epoch 586 Batch   50/100   train_loss = 0.940\n",
      "Epoch 586 Batch   75/100   train_loss = 1.033\n",
      "Epoch 587 Batch    0/100   train_loss = 0.971\n",
      "Epoch 587 Batch   25/100   train_loss = 1.079\n",
      "Epoch 587 Batch   50/100   train_loss = 0.965\n",
      "Epoch 587 Batch   75/100   train_loss = 1.033\n",
      "Epoch 588 Batch    0/100   train_loss = 0.975\n",
      "Epoch 588 Batch   25/100   train_loss = 1.047\n",
      "Epoch 588 Batch   50/100   train_loss = 0.942\n",
      "Epoch 588 Batch   75/100   train_loss = 0.995\n",
      "Epoch 589 Batch    0/100   train_loss = 0.955\n",
      "Epoch 589 Batch   25/100   train_loss = 1.059\n",
      "Epoch 589 Batch   50/100   train_loss = 0.958\n",
      "Epoch 589 Batch   75/100   train_loss = 1.052\n",
      "Epoch 590 Batch    0/100   train_loss = 0.923\n",
      "Epoch 590 Batch   25/100   train_loss = 1.016\n",
      "Epoch 590 Batch   50/100   train_loss = 0.963\n",
      "Epoch 590 Batch   75/100   train_loss = 1.012\n",
      "Epoch 591 Batch    0/100   train_loss = 0.895\n",
      "Epoch 591 Batch   25/100   train_loss = 1.057\n",
      "Epoch 591 Batch   50/100   train_loss = 0.953\n",
      "Epoch 591 Batch   75/100   train_loss = 1.025\n",
      "Epoch 592 Batch    0/100   train_loss = 0.955\n",
      "Epoch 592 Batch   25/100   train_loss = 1.072\n",
      "Epoch 592 Batch   50/100   train_loss = 0.954\n",
      "Epoch 592 Batch   75/100   train_loss = 0.971\n",
      "Epoch 593 Batch    0/100   train_loss = 0.927\n",
      "Epoch 593 Batch   25/100   train_loss = 0.999\n",
      "Epoch 593 Batch   50/100   train_loss = 0.944\n",
      "Epoch 593 Batch   75/100   train_loss = 1.021\n",
      "Epoch 594 Batch    0/100   train_loss = 0.932\n",
      "Epoch 594 Batch   25/100   train_loss = 1.019\n",
      "Epoch 594 Batch   50/100   train_loss = 0.926\n",
      "Epoch 594 Batch   75/100   train_loss = 1.030\n",
      "Epoch 595 Batch    0/100   train_loss = 0.942\n",
      "Epoch 595 Batch   25/100   train_loss = 1.036\n",
      "Epoch 595 Batch   50/100   train_loss = 0.957\n",
      "Epoch 595 Batch   75/100   train_loss = 0.983\n",
      "Epoch 596 Batch    0/100   train_loss = 0.917\n",
      "Epoch 596 Batch   25/100   train_loss = 1.028\n",
      "Epoch 596 Batch   50/100   train_loss = 0.928\n",
      "Epoch 596 Batch   75/100   train_loss = 0.973\n",
      "Epoch 597 Batch    0/100   train_loss = 0.933\n",
      "Epoch 597 Batch   25/100   train_loss = 1.015\n",
      "Epoch 597 Batch   50/100   train_loss = 0.963\n",
      "Epoch 597 Batch   75/100   train_loss = 1.021\n",
      "Epoch 598 Batch    0/100   train_loss = 0.925\n",
      "Epoch 598 Batch   25/100   train_loss = 0.997\n",
      "Epoch 598 Batch   50/100   train_loss = 0.925\n",
      "Epoch 598 Batch   75/100   train_loss = 1.035\n",
      "Epoch 599 Batch    0/100   train_loss = 0.932\n",
      "Epoch 599 Batch   25/100   train_loss = 1.024\n",
      "Epoch 599 Batch   50/100   train_loss = 0.896\n",
      "Epoch 599 Batch   75/100   train_loss = 0.998\n",
      "Epoch 600 Batch    0/100   train_loss = 0.887\n",
      "Epoch 600 Batch   25/100   train_loss = 1.001\n",
      "Epoch 600 Batch   50/100   train_loss = 0.963\n",
      "Epoch 600 Batch   75/100   train_loss = 1.022\n",
      "Epoch 601 Batch    0/100   train_loss = 0.948\n",
      "Epoch 601 Batch   25/100   train_loss = 1.029\n",
      "Epoch 601 Batch   50/100   train_loss = 0.934\n",
      "Epoch 601 Batch   75/100   train_loss = 0.927\n",
      "Epoch 602 Batch    0/100   train_loss = 0.890\n",
      "Epoch 602 Batch   25/100   train_loss = 1.004\n",
      "Epoch 602 Batch   50/100   train_loss = 0.911\n",
      "Epoch 602 Batch   75/100   train_loss = 0.997\n",
      "Epoch 603 Batch    0/100   train_loss = 0.936\n",
      "Epoch 603 Batch   25/100   train_loss = 1.041\n",
      "Epoch 603 Batch   50/100   train_loss = 0.937\n",
      "Epoch 603 Batch   75/100   train_loss = 1.009\n",
      "Epoch 604 Batch    0/100   train_loss = 0.897\n",
      "Epoch 604 Batch   25/100   train_loss = 1.018\n",
      "Epoch 604 Batch   50/100   train_loss = 0.919\n",
      "Epoch 604 Batch   75/100   train_loss = 1.037\n",
      "Epoch 605 Batch    0/100   train_loss = 0.965\n",
      "Epoch 605 Batch   25/100   train_loss = 1.019\n",
      "Epoch 605 Batch   50/100   train_loss = 0.906\n",
      "Epoch 605 Batch   75/100   train_loss = 1.003\n",
      "Epoch 606 Batch    0/100   train_loss = 0.913\n",
      "Epoch 606 Batch   25/100   train_loss = 0.987\n",
      "Epoch 606 Batch   50/100   train_loss = 0.897\n",
      "Epoch 606 Batch   75/100   train_loss = 0.996\n",
      "Epoch 607 Batch    0/100   train_loss = 0.881\n",
      "Epoch 607 Batch   25/100   train_loss = 1.008\n",
      "Epoch 607 Batch   50/100   train_loss = 0.905\n",
      "Epoch 607 Batch   75/100   train_loss = 0.988\n",
      "Epoch 608 Batch    0/100   train_loss = 0.889\n",
      "Epoch 608 Batch   25/100   train_loss = 0.998\n",
      "Epoch 608 Batch   50/100   train_loss = 0.929\n",
      "Epoch 608 Batch   75/100   train_loss = 0.947\n",
      "Epoch 609 Batch    0/100   train_loss = 0.958\n",
      "Epoch 609 Batch   25/100   train_loss = 1.000\n",
      "Epoch 609 Batch   50/100   train_loss = 0.942\n",
      "Epoch 609 Batch   75/100   train_loss = 1.011\n",
      "Epoch 610 Batch    0/100   train_loss = 0.869\n",
      "Epoch 610 Batch   25/100   train_loss = 0.995\n",
      "Epoch 610 Batch   50/100   train_loss = 0.917\n",
      "Epoch 610 Batch   75/100   train_loss = 0.943\n",
      "Epoch 611 Batch    0/100   train_loss = 0.883\n",
      "Epoch 611 Batch   25/100   train_loss = 1.011\n",
      "Epoch 611 Batch   50/100   train_loss = 0.907\n",
      "Epoch 611 Batch   75/100   train_loss = 0.960\n",
      "Epoch 612 Batch    0/100   train_loss = 0.943\n",
      "Epoch 612 Batch   25/100   train_loss = 1.011\n",
      "Epoch 612 Batch   50/100   train_loss = 0.905\n",
      "Epoch 612 Batch   75/100   train_loss = 0.937\n",
      "Epoch 613 Batch    0/100   train_loss = 0.881\n",
      "Epoch 613 Batch   25/100   train_loss = 0.967\n",
      "Epoch 613 Batch   50/100   train_loss = 0.901\n",
      "Epoch 613 Batch   75/100   train_loss = 0.995\n",
      "Epoch 614 Batch    0/100   train_loss = 0.889\n",
      "Epoch 614 Batch   25/100   train_loss = 0.992\n",
      "Epoch 614 Batch   50/100   train_loss = 0.903\n",
      "Epoch 614 Batch   75/100   train_loss = 0.939\n",
      "Epoch 615 Batch    0/100   train_loss = 0.883\n",
      "Epoch 615 Batch   25/100   train_loss = 0.980\n",
      "Epoch 615 Batch   50/100   train_loss = 0.918\n",
      "Epoch 615 Batch   75/100   train_loss = 0.984\n",
      "Epoch 616 Batch    0/100   train_loss = 0.873\n",
      "Epoch 616 Batch   25/100   train_loss = 0.989\n",
      "Epoch 616 Batch   50/100   train_loss = 0.908\n",
      "Epoch 616 Batch   75/100   train_loss = 0.969\n",
      "Epoch 617 Batch    0/100   train_loss = 0.844\n",
      "Epoch 617 Batch   25/100   train_loss = 0.951\n",
      "Epoch 617 Batch   50/100   train_loss = 0.921\n",
      "Epoch 617 Batch   75/100   train_loss = 0.983\n",
      "Epoch 618 Batch    0/100   train_loss = 0.847\n",
      "Epoch 618 Batch   25/100   train_loss = 0.995\n",
      "Epoch 618 Batch   50/100   train_loss = 0.859\n",
      "Epoch 618 Batch   75/100   train_loss = 0.950\n",
      "Epoch 619 Batch    0/100   train_loss = 0.859\n",
      "Epoch 619 Batch   25/100   train_loss = 1.001\n",
      "Epoch 619 Batch   50/100   train_loss = 0.876\n",
      "Epoch 619 Batch   75/100   train_loss = 0.998\n",
      "Epoch 620 Batch    0/100   train_loss = 0.885\n",
      "Epoch 620 Batch   25/100   train_loss = 0.971\n",
      "Epoch 620 Batch   50/100   train_loss = 0.881\n",
      "Epoch 620 Batch   75/100   train_loss = 1.034\n",
      "Epoch 621 Batch    0/100   train_loss = 0.865\n",
      "Epoch 621 Batch   25/100   train_loss = 1.021\n",
      "Epoch 621 Batch   50/100   train_loss = 0.870\n",
      "Epoch 621 Batch   75/100   train_loss = 0.970\n",
      "Epoch 622 Batch    0/100   train_loss = 0.856\n",
      "Epoch 622 Batch   25/100   train_loss = 0.991\n",
      "Epoch 622 Batch   50/100   train_loss = 0.905\n",
      "Epoch 622 Batch   75/100   train_loss = 1.007\n",
      "Epoch 623 Batch    0/100   train_loss = 0.838\n",
      "Epoch 623 Batch   25/100   train_loss = 0.985\n",
      "Epoch 623 Batch   50/100   train_loss = 0.908\n",
      "Epoch 623 Batch   75/100   train_loss = 0.930\n",
      "Epoch 624 Batch    0/100   train_loss = 0.896\n",
      "Epoch 624 Batch   25/100   train_loss = 0.962\n",
      "Epoch 624 Batch   50/100   train_loss = 0.901\n",
      "Epoch 624 Batch   75/100   train_loss = 0.967\n",
      "Epoch 625 Batch    0/100   train_loss = 0.840\n",
      "Epoch 625 Batch   25/100   train_loss = 0.951\n",
      "Epoch 625 Batch   50/100   train_loss = 0.915\n",
      "Epoch 625 Batch   75/100   train_loss = 0.982\n",
      "Epoch 626 Batch    0/100   train_loss = 0.863\n",
      "Epoch 626 Batch   25/100   train_loss = 0.965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 626 Batch   50/100   train_loss = 0.871\n",
      "Epoch 626 Batch   75/100   train_loss = 0.919\n",
      "Epoch 627 Batch    0/100   train_loss = 0.885\n",
      "Epoch 627 Batch   25/100   train_loss = 0.956\n",
      "Epoch 627 Batch   50/100   train_loss = 0.873\n",
      "Epoch 627 Batch   75/100   train_loss = 0.948\n",
      "Epoch 628 Batch    0/100   train_loss = 0.844\n",
      "Epoch 628 Batch   25/100   train_loss = 0.963\n",
      "Epoch 628 Batch   50/100   train_loss = 0.873\n",
      "Epoch 628 Batch   75/100   train_loss = 0.996\n",
      "Epoch 629 Batch    0/100   train_loss = 0.864\n",
      "Epoch 629 Batch   25/100   train_loss = 0.963\n",
      "Epoch 629 Batch   50/100   train_loss = 0.891\n",
      "Epoch 629 Batch   75/100   train_loss = 0.980\n",
      "Epoch 630 Batch    0/100   train_loss = 0.899\n",
      "Epoch 630 Batch   25/100   train_loss = 0.930\n",
      "Epoch 630 Batch   50/100   train_loss = 0.871\n",
      "Epoch 630 Batch   75/100   train_loss = 0.971\n",
      "Epoch 631 Batch    0/100   train_loss = 0.846\n",
      "Epoch 631 Batch   25/100   train_loss = 0.983\n",
      "Epoch 631 Batch   50/100   train_loss = 0.901\n",
      "Epoch 631 Batch   75/100   train_loss = 1.015\n",
      "Epoch 632 Batch    0/100   train_loss = 0.841\n",
      "Epoch 632 Batch   25/100   train_loss = 0.954\n",
      "Epoch 632 Batch   50/100   train_loss = 0.836\n",
      "Epoch 632 Batch   75/100   train_loss = 0.978\n",
      "Epoch 633 Batch    0/100   train_loss = 0.836\n",
      "Epoch 633 Batch   25/100   train_loss = 0.923\n",
      "Epoch 633 Batch   50/100   train_loss = 0.900\n",
      "Epoch 633 Batch   75/100   train_loss = 0.951\n",
      "Epoch 634 Batch    0/100   train_loss = 0.893\n",
      "Epoch 634 Batch   25/100   train_loss = 0.967\n",
      "Epoch 634 Batch   50/100   train_loss = 0.884\n",
      "Epoch 634 Batch   75/100   train_loss = 0.935\n",
      "Epoch 635 Batch    0/100   train_loss = 0.891\n",
      "Epoch 635 Batch   25/100   train_loss = 0.980\n",
      "Epoch 635 Batch   50/100   train_loss = 0.879\n",
      "Epoch 635 Batch   75/100   train_loss = 0.927\n",
      "Epoch 636 Batch    0/100   train_loss = 0.825\n",
      "Epoch 636 Batch   25/100   train_loss = 0.992\n",
      "Epoch 636 Batch   50/100   train_loss = 0.874\n",
      "Epoch 636 Batch   75/100   train_loss = 0.921\n",
      "Epoch 637 Batch    0/100   train_loss = 0.866\n",
      "Epoch 637 Batch   25/100   train_loss = 0.958\n",
      "Epoch 637 Batch   50/100   train_loss = 0.856\n",
      "Epoch 637 Batch   75/100   train_loss = 0.974\n",
      "Epoch 638 Batch    0/100   train_loss = 0.844\n",
      "Epoch 638 Batch   25/100   train_loss = 0.940\n",
      "Epoch 638 Batch   50/100   train_loss = 0.843\n",
      "Epoch 638 Batch   75/100   train_loss = 0.926\n",
      "Epoch 639 Batch    0/100   train_loss = 0.847\n",
      "Epoch 639 Batch   25/100   train_loss = 0.945\n",
      "Epoch 639 Batch   50/100   train_loss = 0.855\n",
      "Epoch 639 Batch   75/100   train_loss = 0.930\n",
      "Epoch 640 Batch    0/100   train_loss = 0.812\n",
      "Epoch 640 Batch   25/100   train_loss = 0.950\n",
      "Epoch 640 Batch   50/100   train_loss = 0.892\n",
      "Epoch 640 Batch   75/100   train_loss = 0.940\n",
      "Epoch 641 Batch    0/100   train_loss = 0.840\n",
      "Epoch 641 Batch   25/100   train_loss = 0.952\n",
      "Epoch 641 Batch   50/100   train_loss = 0.888\n",
      "Epoch 641 Batch   75/100   train_loss = 0.922\n",
      "Epoch 642 Batch    0/100   train_loss = 0.872\n",
      "Epoch 642 Batch   25/100   train_loss = 0.943\n",
      "Epoch 642 Batch   50/100   train_loss = 0.839\n",
      "Epoch 642 Batch   75/100   train_loss = 0.954\n",
      "Epoch 643 Batch    0/100   train_loss = 0.815\n",
      "Epoch 643 Batch   25/100   train_loss = 0.921\n",
      "Epoch 643 Batch   50/100   train_loss = 0.881\n",
      "Epoch 643 Batch   75/100   train_loss = 0.901\n",
      "Epoch 644 Batch    0/100   train_loss = 0.853\n",
      "Epoch 644 Batch   25/100   train_loss = 0.955\n",
      "Epoch 644 Batch   50/100   train_loss = 0.829\n",
      "Epoch 644 Batch   75/100   train_loss = 0.952\n",
      "Epoch 645 Batch    0/100   train_loss = 0.807\n",
      "Epoch 645 Batch   25/100   train_loss = 0.958\n",
      "Epoch 645 Batch   50/100   train_loss = 0.882\n",
      "Epoch 645 Batch   75/100   train_loss = 0.926\n",
      "Epoch 646 Batch    0/100   train_loss = 0.792\n",
      "Epoch 646 Batch   25/100   train_loss = 0.949\n",
      "Epoch 646 Batch   50/100   train_loss = 0.855\n",
      "Epoch 646 Batch   75/100   train_loss = 0.930\n",
      "Epoch 647 Batch    0/100   train_loss = 0.840\n",
      "Epoch 647 Batch   25/100   train_loss = 0.936\n",
      "Epoch 647 Batch   50/100   train_loss = 0.847\n",
      "Epoch 647 Batch   75/100   train_loss = 0.949\n",
      "Epoch 648 Batch    0/100   train_loss = 0.789\n",
      "Epoch 648 Batch   25/100   train_loss = 0.958\n",
      "Epoch 648 Batch   50/100   train_loss = 0.825\n",
      "Epoch 648 Batch   75/100   train_loss = 0.896\n",
      "Epoch 649 Batch    0/100   train_loss = 0.821\n",
      "Epoch 649 Batch   25/100   train_loss = 0.963\n",
      "Epoch 649 Batch   50/100   train_loss = 0.849\n",
      "Epoch 649 Batch   75/100   train_loss = 0.930\n",
      "Epoch 650 Batch    0/100   train_loss = 0.799\n",
      "Epoch 650 Batch   25/100   train_loss = 0.968\n",
      "Epoch 650 Batch   50/100   train_loss = 0.832\n",
      "Epoch 650 Batch   75/100   train_loss = 0.934\n",
      "Epoch 651 Batch    0/100   train_loss = 0.830\n",
      "Epoch 651 Batch   25/100   train_loss = 0.966\n",
      "Epoch 651 Batch   50/100   train_loss = 0.864\n",
      "Epoch 651 Batch   75/100   train_loss = 0.957\n",
      "Epoch 652 Batch    0/100   train_loss = 0.793\n",
      "Epoch 652 Batch   25/100   train_loss = 0.907\n",
      "Epoch 652 Batch   50/100   train_loss = 0.860\n",
      "Epoch 652 Batch   75/100   train_loss = 0.934\n",
      "Epoch 653 Batch    0/100   train_loss = 0.815\n",
      "Epoch 653 Batch   25/100   train_loss = 0.937\n",
      "Epoch 653 Batch   50/100   train_loss = 0.850\n",
      "Epoch 653 Batch   75/100   train_loss = 0.909\n",
      "Epoch 654 Batch    0/100   train_loss = 0.828\n",
      "Epoch 654 Batch   25/100   train_loss = 0.913\n",
      "Epoch 654 Batch   50/100   train_loss = 0.812\n",
      "Epoch 654 Batch   75/100   train_loss = 0.868\n",
      "Epoch 655 Batch    0/100   train_loss = 0.811\n",
      "Epoch 655 Batch   25/100   train_loss = 0.926\n",
      "Epoch 655 Batch   50/100   train_loss = 0.831\n",
      "Epoch 655 Batch   75/100   train_loss = 0.892\n",
      "Epoch 656 Batch    0/100   train_loss = 0.836\n",
      "Epoch 656 Batch   25/100   train_loss = 0.943\n",
      "Epoch 656 Batch   50/100   train_loss = 0.855\n",
      "Epoch 656 Batch   75/100   train_loss = 0.901\n",
      "Epoch 657 Batch    0/100   train_loss = 0.799\n",
      "Epoch 657 Batch   25/100   train_loss = 0.927\n",
      "Epoch 657 Batch   50/100   train_loss = 0.835\n",
      "Epoch 657 Batch   75/100   train_loss = 0.915\n",
      "Epoch 658 Batch    0/100   train_loss = 0.784\n",
      "Epoch 658 Batch   25/100   train_loss = 0.880\n",
      "Epoch 658 Batch   50/100   train_loss = 0.855\n",
      "Epoch 658 Batch   75/100   train_loss = 0.904\n",
      "Epoch 659 Batch    0/100   train_loss = 0.807\n",
      "Epoch 659 Batch   25/100   train_loss = 0.891\n",
      "Epoch 659 Batch   50/100   train_loss = 0.868\n",
      "Epoch 659 Batch   75/100   train_loss = 0.908\n",
      "Epoch 660 Batch    0/100   train_loss = 0.807\n",
      "Epoch 660 Batch   25/100   train_loss = 0.908\n",
      "Epoch 660 Batch   50/100   train_loss = 0.804\n",
      "Epoch 660 Batch   75/100   train_loss = 0.908\n",
      "Epoch 661 Batch    0/100   train_loss = 0.807\n",
      "Epoch 661 Batch   25/100   train_loss = 0.863\n",
      "Epoch 661 Batch   50/100   train_loss = 0.758\n",
      "Epoch 661 Batch   75/100   train_loss = 0.888\n",
      "Epoch 662 Batch    0/100   train_loss = 0.795\n",
      "Epoch 662 Batch   25/100   train_loss = 0.918\n",
      "Epoch 662 Batch   50/100   train_loss = 0.809\n",
      "Epoch 662 Batch   75/100   train_loss = 0.923\n",
      "Epoch 663 Batch    0/100   train_loss = 0.795\n",
      "Epoch 663 Batch   25/100   train_loss = 0.930\n",
      "Epoch 663 Batch   50/100   train_loss = 0.837\n",
      "Epoch 663 Batch   75/100   train_loss = 0.875\n",
      "Epoch 664 Batch    0/100   train_loss = 0.831\n",
      "Epoch 664 Batch   25/100   train_loss = 0.917\n",
      "Epoch 664 Batch   50/100   train_loss = 0.809\n",
      "Epoch 664 Batch   75/100   train_loss = 0.879\n",
      "Epoch 665 Batch    0/100   train_loss = 0.809\n",
      "Epoch 665 Batch   25/100   train_loss = 0.923\n",
      "Epoch 665 Batch   50/100   train_loss = 0.831\n",
      "Epoch 665 Batch   75/100   train_loss = 0.917\n",
      "Epoch 666 Batch    0/100   train_loss = 0.822\n",
      "Epoch 666 Batch   25/100   train_loss = 0.903\n",
      "Epoch 666 Batch   50/100   train_loss = 0.830\n",
      "Epoch 666 Batch   75/100   train_loss = 0.922\n",
      "Epoch 667 Batch    0/100   train_loss = 0.838\n",
      "Epoch 667 Batch   25/100   train_loss = 0.905\n",
      "Epoch 667 Batch   50/100   train_loss = 0.841\n",
      "Epoch 667 Batch   75/100   train_loss = 0.906\n",
      "Epoch 668 Batch    0/100   train_loss = 0.801\n",
      "Epoch 668 Batch   25/100   train_loss = 0.905\n",
      "Epoch 668 Batch   50/100   train_loss = 0.827\n",
      "Epoch 668 Batch   75/100   train_loss = 0.888\n",
      "Epoch 669 Batch    0/100   train_loss = 0.790\n",
      "Epoch 669 Batch   25/100   train_loss = 0.893\n",
      "Epoch 669 Batch   50/100   train_loss = 0.836\n",
      "Epoch 669 Batch   75/100   train_loss = 0.865\n",
      "Epoch 670 Batch    0/100   train_loss = 0.790\n",
      "Epoch 670 Batch   25/100   train_loss = 0.927\n",
      "Epoch 670 Batch   50/100   train_loss = 0.830\n",
      "Epoch 670 Batch   75/100   train_loss = 0.895\n",
      "Epoch 671 Batch    0/100   train_loss = 0.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671 Batch   25/100   train_loss = 0.898\n",
      "Epoch 671 Batch   50/100   train_loss = 0.752\n",
      "Epoch 671 Batch   75/100   train_loss = 0.866\n",
      "Epoch 672 Batch    0/100   train_loss = 0.814\n",
      "Epoch 672 Batch   25/100   train_loss = 0.881\n",
      "Epoch 672 Batch   50/100   train_loss = 0.772\n",
      "Epoch 672 Batch   75/100   train_loss = 0.892\n",
      "Epoch 673 Batch    0/100   train_loss = 0.770\n",
      "Epoch 673 Batch   25/100   train_loss = 0.913\n",
      "Epoch 673 Batch   50/100   train_loss = 0.852\n",
      "Epoch 673 Batch   75/100   train_loss = 0.875\n",
      "Epoch 674 Batch    0/100   train_loss = 0.802\n",
      "Epoch 674 Batch   25/100   train_loss = 0.931\n",
      "Epoch 674 Batch   50/100   train_loss = 0.814\n",
      "Epoch 674 Batch   75/100   train_loss = 0.911\n",
      "Epoch 675 Batch    0/100   train_loss = 0.809\n",
      "Epoch 675 Batch   25/100   train_loss = 0.930\n",
      "Epoch 675 Batch   50/100   train_loss = 0.821\n",
      "Epoch 675 Batch   75/100   train_loss = 0.887\n",
      "Epoch 676 Batch    0/100   train_loss = 0.774\n",
      "Epoch 676 Batch   25/100   train_loss = 0.845\n",
      "Epoch 676 Batch   50/100   train_loss = 0.768\n",
      "Epoch 676 Batch   75/100   train_loss = 0.872\n",
      "Epoch 677 Batch    0/100   train_loss = 0.765\n",
      "Epoch 677 Batch   25/100   train_loss = 0.922\n",
      "Epoch 677 Batch   50/100   train_loss = 0.810\n",
      "Epoch 677 Batch   75/100   train_loss = 0.896\n",
      "Epoch 678 Batch    0/100   train_loss = 0.793\n",
      "Epoch 678 Batch   25/100   train_loss = 0.909\n",
      "Epoch 678 Batch   50/100   train_loss = 0.841\n",
      "Epoch 678 Batch   75/100   train_loss = 0.838\n",
      "Epoch 679 Batch    0/100   train_loss = 0.801\n",
      "Epoch 679 Batch   25/100   train_loss = 0.913\n",
      "Epoch 679 Batch   50/100   train_loss = 0.825\n",
      "Epoch 679 Batch   75/100   train_loss = 0.887\n",
      "Epoch 680 Batch    0/100   train_loss = 0.786\n",
      "Epoch 680 Batch   25/100   train_loss = 0.837\n",
      "Epoch 680 Batch   50/100   train_loss = 0.792\n",
      "Epoch 680 Batch   75/100   train_loss = 0.846\n",
      "Epoch 681 Batch    0/100   train_loss = 0.798\n",
      "Epoch 681 Batch   25/100   train_loss = 0.839\n",
      "Epoch 681 Batch   50/100   train_loss = 0.771\n",
      "Epoch 681 Batch   75/100   train_loss = 0.815\n",
      "Epoch 682 Batch    0/100   train_loss = 0.748\n",
      "Epoch 682 Batch   25/100   train_loss = 0.915\n",
      "Epoch 682 Batch   50/100   train_loss = 0.802\n",
      "Epoch 682 Batch   75/100   train_loss = 0.875\n",
      "Epoch 683 Batch    0/100   train_loss = 0.788\n",
      "Epoch 683 Batch   25/100   train_loss = 0.895\n",
      "Epoch 683 Batch   50/100   train_loss = 0.827\n",
      "Epoch 683 Batch   75/100   train_loss = 0.847\n",
      "Epoch 684 Batch    0/100   train_loss = 0.821\n",
      "Epoch 684 Batch   25/100   train_loss = 0.873\n",
      "Epoch 684 Batch   50/100   train_loss = 0.811\n",
      "Epoch 684 Batch   75/100   train_loss = 0.919\n",
      "Epoch 685 Batch    0/100   train_loss = 0.760\n",
      "Epoch 685 Batch   25/100   train_loss = 0.891\n",
      "Epoch 685 Batch   50/100   train_loss = 0.784\n",
      "Epoch 685 Batch   75/100   train_loss = 0.858\n",
      "Epoch 686 Batch    0/100   train_loss = 0.769\n",
      "Epoch 686 Batch   25/100   train_loss = 0.867\n",
      "Epoch 686 Batch   50/100   train_loss = 0.750\n",
      "Epoch 686 Batch   75/100   train_loss = 0.846\n",
      "Epoch 687 Batch    0/100   train_loss = 0.783\n",
      "Epoch 687 Batch   25/100   train_loss = 0.882\n",
      "Epoch 687 Batch   50/100   train_loss = 0.826\n",
      "Epoch 687 Batch   75/100   train_loss = 0.855\n",
      "Epoch 688 Batch    0/100   train_loss = 0.739\n",
      "Epoch 688 Batch   25/100   train_loss = 0.875\n",
      "Epoch 688 Batch   50/100   train_loss = 0.774\n",
      "Epoch 688 Batch   75/100   train_loss = 0.837\n",
      "Epoch 689 Batch    0/100   train_loss = 0.766\n",
      "Epoch 689 Batch   25/100   train_loss = 0.893\n",
      "Epoch 689 Batch   50/100   train_loss = 0.818\n",
      "Epoch 689 Batch   75/100   train_loss = 0.790\n",
      "Epoch 690 Batch    0/100   train_loss = 0.791\n",
      "Epoch 690 Batch   25/100   train_loss = 0.846\n",
      "Epoch 690 Batch   50/100   train_loss = 0.784\n",
      "Epoch 690 Batch   75/100   train_loss = 0.899\n",
      "Epoch 691 Batch    0/100   train_loss = 0.749\n",
      "Epoch 691 Batch   25/100   train_loss = 0.909\n",
      "Epoch 691 Batch   50/100   train_loss = 0.782\n",
      "Epoch 691 Batch   75/100   train_loss = 0.917\n",
      "Epoch 692 Batch    0/100   train_loss = 0.745\n",
      "Epoch 692 Batch   25/100   train_loss = 0.872\n",
      "Epoch 692 Batch   50/100   train_loss = 0.805\n",
      "Epoch 692 Batch   75/100   train_loss = 0.895\n",
      "Epoch 693 Batch    0/100   train_loss = 0.763\n",
      "Epoch 693 Batch   25/100   train_loss = 0.872\n",
      "Epoch 693 Batch   50/100   train_loss = 0.792\n",
      "Epoch 693 Batch   75/100   train_loss = 0.860\n",
      "Epoch 694 Batch    0/100   train_loss = 0.755\n",
      "Epoch 694 Batch   25/100   train_loss = 0.869\n",
      "Epoch 694 Batch   50/100   train_loss = 0.826\n",
      "Epoch 694 Batch   75/100   train_loss = 0.821\n",
      "Epoch 695 Batch    0/100   train_loss = 0.786\n",
      "Epoch 695 Batch   25/100   train_loss = 0.872\n",
      "Epoch 695 Batch   50/100   train_loss = 0.801\n",
      "Epoch 695 Batch   75/100   train_loss = 0.862\n",
      "Epoch 696 Batch    0/100   train_loss = 0.798\n",
      "Epoch 696 Batch   25/100   train_loss = 0.863\n",
      "Epoch 696 Batch   50/100   train_loss = 0.818\n",
      "Epoch 696 Batch   75/100   train_loss = 0.878\n",
      "Epoch 697 Batch    0/100   train_loss = 0.735\n",
      "Epoch 697 Batch   25/100   train_loss = 0.887\n",
      "Epoch 697 Batch   50/100   train_loss = 0.779\n",
      "Epoch 697 Batch   75/100   train_loss = 0.841\n",
      "Epoch 698 Batch    0/100   train_loss = 0.746\n",
      "Epoch 698 Batch   25/100   train_loss = 0.841\n",
      "Epoch 698 Batch   50/100   train_loss = 0.839\n",
      "Epoch 698 Batch   75/100   train_loss = 0.846\n",
      "Epoch 699 Batch    0/100   train_loss = 0.776\n",
      "Epoch 699 Batch   25/100   train_loss = 0.876\n",
      "Epoch 699 Batch   50/100   train_loss = 0.783\n",
      "Epoch 699 Batch   75/100   train_loss = 0.867\n",
      "Epoch 700 Batch    0/100   train_loss = 0.751\n",
      "Epoch 700 Batch   25/100   train_loss = 0.876\n",
      "Epoch 700 Batch   50/100   train_loss = 0.774\n",
      "Epoch 700 Batch   75/100   train_loss = 0.849\n",
      "Epoch 701 Batch    0/100   train_loss = 0.771\n",
      "Epoch 701 Batch   25/100   train_loss = 0.868\n",
      "Epoch 701 Batch   50/100   train_loss = 0.789\n",
      "Epoch 701 Batch   75/100   train_loss = 0.840\n",
      "Epoch 702 Batch    0/100   train_loss = 0.724\n",
      "Epoch 702 Batch   25/100   train_loss = 0.882\n",
      "Epoch 702 Batch   50/100   train_loss = 0.764\n",
      "Epoch 702 Batch   75/100   train_loss = 0.850\n",
      "Epoch 703 Batch    0/100   train_loss = 0.730\n",
      "Epoch 703 Batch   25/100   train_loss = 0.889\n",
      "Epoch 703 Batch   50/100   train_loss = 0.795\n",
      "Epoch 703 Batch   75/100   train_loss = 0.838\n",
      "Epoch 704 Batch    0/100   train_loss = 0.721\n",
      "Epoch 704 Batch   25/100   train_loss = 0.821\n",
      "Epoch 704 Batch   50/100   train_loss = 0.803\n",
      "Epoch 704 Batch   75/100   train_loss = 0.886\n",
      "Epoch 705 Batch    0/100   train_loss = 0.747\n",
      "Epoch 705 Batch   25/100   train_loss = 0.859\n",
      "Epoch 705 Batch   50/100   train_loss = 0.784\n",
      "Epoch 705 Batch   75/100   train_loss = 0.859\n",
      "Epoch 706 Batch    0/100   train_loss = 0.759\n",
      "Epoch 706 Batch   25/100   train_loss = 0.859\n",
      "Epoch 706 Batch   50/100   train_loss = 0.783\n",
      "Epoch 706 Batch   75/100   train_loss = 0.811\n",
      "Epoch 707 Batch    0/100   train_loss = 0.730\n",
      "Epoch 707 Batch   25/100   train_loss = 0.864\n",
      "Epoch 707 Batch   50/100   train_loss = 0.775\n",
      "Epoch 707 Batch   75/100   train_loss = 0.796\n",
      "Epoch 708 Batch    0/100   train_loss = 0.761\n",
      "Epoch 708 Batch   25/100   train_loss = 0.847\n",
      "Epoch 708 Batch   50/100   train_loss = 0.780\n",
      "Epoch 708 Batch   75/100   train_loss = 0.812\n",
      "Epoch 709 Batch    0/100   train_loss = 0.736\n",
      "Epoch 709 Batch   25/100   train_loss = 0.880\n",
      "Epoch 709 Batch   50/100   train_loss = 0.769\n",
      "Epoch 709 Batch   75/100   train_loss = 0.858\n",
      "Epoch 710 Batch    0/100   train_loss = 0.727\n",
      "Epoch 710 Batch   25/100   train_loss = 0.893\n",
      "Epoch 710 Batch   50/100   train_loss = 0.750\n",
      "Epoch 710 Batch   75/100   train_loss = 0.829\n",
      "Epoch 711 Batch    0/100   train_loss = 0.744\n",
      "Epoch 711 Batch   25/100   train_loss = 0.863\n",
      "Epoch 711 Batch   50/100   train_loss = 0.786\n",
      "Epoch 711 Batch   75/100   train_loss = 0.822\n",
      "Epoch 712 Batch    0/100   train_loss = 0.735\n",
      "Epoch 712 Batch   25/100   train_loss = 0.868\n",
      "Epoch 712 Batch   50/100   train_loss = 0.768\n",
      "Epoch 712 Batch   75/100   train_loss = 0.809\n",
      "Epoch 713 Batch    0/100   train_loss = 0.760\n",
      "Epoch 713 Batch   25/100   train_loss = 0.846\n",
      "Epoch 713 Batch   50/100   train_loss = 0.756\n",
      "Epoch 713 Batch   75/100   train_loss = 0.830\n",
      "Epoch 714 Batch    0/100   train_loss = 0.730\n",
      "Epoch 714 Batch   25/100   train_loss = 0.866\n",
      "Epoch 714 Batch   50/100   train_loss = 0.766\n",
      "Epoch 714 Batch   75/100   train_loss = 0.821\n",
      "Epoch 715 Batch    0/100   train_loss = 0.722\n",
      "Epoch 715 Batch   25/100   train_loss = 0.856\n",
      "Epoch 715 Batch   50/100   train_loss = 0.759\n",
      "Epoch 715 Batch   75/100   train_loss = 0.851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 716 Batch    0/100   train_loss = 0.732\n",
      "Epoch 716 Batch   25/100   train_loss = 0.856\n",
      "Epoch 716 Batch   50/100   train_loss = 0.722\n",
      "Epoch 716 Batch   75/100   train_loss = 0.815\n",
      "Epoch 717 Batch    0/100   train_loss = 0.706\n",
      "Epoch 717 Batch   25/100   train_loss = 0.869\n",
      "Epoch 717 Batch   50/100   train_loss = 0.776\n",
      "Epoch 717 Batch   75/100   train_loss = 0.781\n",
      "Epoch 718 Batch    0/100   train_loss = 0.733\n",
      "Epoch 718 Batch   25/100   train_loss = 0.835\n",
      "Epoch 718 Batch   50/100   train_loss = 0.753\n",
      "Epoch 718 Batch   75/100   train_loss = 0.810\n",
      "Epoch 719 Batch    0/100   train_loss = 0.735\n",
      "Epoch 719 Batch   25/100   train_loss = 0.820\n",
      "Epoch 719 Batch   50/100   train_loss = 0.760\n",
      "Epoch 719 Batch   75/100   train_loss = 0.825\n",
      "Epoch 720 Batch    0/100   train_loss = 0.751\n",
      "Epoch 720 Batch   25/100   train_loss = 0.839\n",
      "Epoch 720 Batch   50/100   train_loss = 0.757\n",
      "Epoch 720 Batch   75/100   train_loss = 0.843\n",
      "Epoch 721 Batch    0/100   train_loss = 0.703\n",
      "Epoch 721 Batch   25/100   train_loss = 0.848\n",
      "Epoch 721 Batch   50/100   train_loss = 0.733\n",
      "Epoch 721 Batch   75/100   train_loss = 0.810\n",
      "Epoch 722 Batch    0/100   train_loss = 0.716\n",
      "Epoch 722 Batch   25/100   train_loss = 0.851\n",
      "Epoch 722 Batch   50/100   train_loss = 0.730\n",
      "Epoch 722 Batch   75/100   train_loss = 0.793\n",
      "Epoch 723 Batch    0/100   train_loss = 0.713\n",
      "Epoch 723 Batch   25/100   train_loss = 0.841\n",
      "Epoch 723 Batch   50/100   train_loss = 0.738\n",
      "Epoch 723 Batch   75/100   train_loss = 0.827\n",
      "Epoch 724 Batch    0/100   train_loss = 0.722\n",
      "Epoch 724 Batch   25/100   train_loss = 0.830\n",
      "Epoch 724 Batch   50/100   train_loss = 0.737\n",
      "Epoch 724 Batch   75/100   train_loss = 0.800\n",
      "Epoch 725 Batch    0/100   train_loss = 0.718\n",
      "Epoch 725 Batch   25/100   train_loss = 0.814\n",
      "Epoch 725 Batch   50/100   train_loss = 0.771\n",
      "Epoch 725 Batch   75/100   train_loss = 0.802\n",
      "Epoch 726 Batch    0/100   train_loss = 0.698\n",
      "Epoch 726 Batch   25/100   train_loss = 0.846\n",
      "Epoch 726 Batch   50/100   train_loss = 0.734\n",
      "Epoch 726 Batch   75/100   train_loss = 0.822\n",
      "Epoch 727 Batch    0/100   train_loss = 0.723\n",
      "Epoch 727 Batch   25/100   train_loss = 0.866\n",
      "Epoch 727 Batch   50/100   train_loss = 0.753\n",
      "Epoch 727 Batch   75/100   train_loss = 0.820\n",
      "Epoch 728 Batch    0/100   train_loss = 0.730\n",
      "Epoch 728 Batch   25/100   train_loss = 0.846\n",
      "Epoch 728 Batch   50/100   train_loss = 0.758\n",
      "Epoch 728 Batch   75/100   train_loss = 0.803\n",
      "Epoch 729 Batch    0/100   train_loss = 0.720\n",
      "Epoch 729 Batch   25/100   train_loss = 0.821\n",
      "Epoch 729 Batch   50/100   train_loss = 0.738\n",
      "Epoch 729 Batch   75/100   train_loss = 0.807\n",
      "Epoch 730 Batch    0/100   train_loss = 0.682\n",
      "Epoch 730 Batch   25/100   train_loss = 0.839\n",
      "Epoch 730 Batch   50/100   train_loss = 0.765\n",
      "Epoch 730 Batch   75/100   train_loss = 0.797\n",
      "Epoch 731 Batch    0/100   train_loss = 0.713\n",
      "Epoch 731 Batch   25/100   train_loss = 0.865\n",
      "Epoch 731 Batch   50/100   train_loss = 0.723\n",
      "Epoch 731 Batch   75/100   train_loss = 0.779\n",
      "Epoch 732 Batch    0/100   train_loss = 0.730\n",
      "Epoch 732 Batch   25/100   train_loss = 0.839\n",
      "Epoch 732 Batch   50/100   train_loss = 0.742\n",
      "Epoch 732 Batch   75/100   train_loss = 0.788\n",
      "Epoch 733 Batch    0/100   train_loss = 0.725\n",
      "Epoch 733 Batch   25/100   train_loss = 0.802\n",
      "Epoch 733 Batch   50/100   train_loss = 0.732\n",
      "Epoch 733 Batch   75/100   train_loss = 0.814\n",
      "Epoch 734 Batch    0/100   train_loss = 0.685\n",
      "Epoch 734 Batch   25/100   train_loss = 0.781\n",
      "Epoch 734 Batch   50/100   train_loss = 0.759\n",
      "Epoch 734 Batch   75/100   train_loss = 0.799\n",
      "Epoch 735 Batch    0/100   train_loss = 0.726\n",
      "Epoch 735 Batch   25/100   train_loss = 0.815\n",
      "Epoch 735 Batch   50/100   train_loss = 0.730\n",
      "Epoch 735 Batch   75/100   train_loss = 0.809\n",
      "Epoch 736 Batch    0/100   train_loss = 0.686\n",
      "Epoch 736 Batch   25/100   train_loss = 0.815\n",
      "Epoch 736 Batch   50/100   train_loss = 0.723\n",
      "Epoch 736 Batch   75/100   train_loss = 0.755\n",
      "Epoch 737 Batch    0/100   train_loss = 0.730\n",
      "Epoch 737 Batch   25/100   train_loss = 0.792\n",
      "Epoch 737 Batch   50/100   train_loss = 0.739\n",
      "Epoch 737 Batch   75/100   train_loss = 0.774\n",
      "Epoch 738 Batch    0/100   train_loss = 0.697\n",
      "Epoch 738 Batch   25/100   train_loss = 0.826\n",
      "Epoch 738 Batch   50/100   train_loss = 0.738\n",
      "Epoch 738 Batch   75/100   train_loss = 0.793\n",
      "Epoch 739 Batch    0/100   train_loss = 0.686\n",
      "Epoch 739 Batch   25/100   train_loss = 0.836\n",
      "Epoch 739 Batch   50/100   train_loss = 0.711\n",
      "Epoch 739 Batch   75/100   train_loss = 0.799\n",
      "Epoch 740 Batch    0/100   train_loss = 0.700\n",
      "Epoch 740 Batch   25/100   train_loss = 0.840\n",
      "Epoch 740 Batch   50/100   train_loss = 0.721\n",
      "Epoch 740 Batch   75/100   train_loss = 0.738\n",
      "Epoch 741 Batch    0/100   train_loss = 0.696\n",
      "Epoch 741 Batch   25/100   train_loss = 0.804\n",
      "Epoch 741 Batch   50/100   train_loss = 0.741\n",
      "Epoch 741 Batch   75/100   train_loss = 0.779\n",
      "Epoch 742 Batch    0/100   train_loss = 0.712\n",
      "Epoch 742 Batch   25/100   train_loss = 0.808\n",
      "Epoch 742 Batch   50/100   train_loss = 0.708\n",
      "Epoch 742 Batch   75/100   train_loss = 0.810\n",
      "Epoch 743 Batch    0/100   train_loss = 0.701\n",
      "Epoch 743 Batch   25/100   train_loss = 0.823\n",
      "Epoch 743 Batch   50/100   train_loss = 0.745\n",
      "Epoch 743 Batch   75/100   train_loss = 0.816\n",
      "Epoch 744 Batch    0/100   train_loss = 0.673\n",
      "Epoch 744 Batch   25/100   train_loss = 0.807\n",
      "Epoch 744 Batch   50/100   train_loss = 0.685\n",
      "Epoch 744 Batch   75/100   train_loss = 0.786\n",
      "Epoch 745 Batch    0/100   train_loss = 0.705\n",
      "Epoch 745 Batch   25/100   train_loss = 0.836\n",
      "Epoch 745 Batch   50/100   train_loss = 0.737\n",
      "Epoch 745 Batch   75/100   train_loss = 0.772\n",
      "Epoch 746 Batch    0/100   train_loss = 0.648\n",
      "Epoch 746 Batch   25/100   train_loss = 0.793\n",
      "Epoch 746 Batch   50/100   train_loss = 0.740\n",
      "Epoch 746 Batch   75/100   train_loss = 0.777\n",
      "Epoch 747 Batch    0/100   train_loss = 0.702\n",
      "Epoch 747 Batch   25/100   train_loss = 0.789\n",
      "Epoch 747 Batch   50/100   train_loss = 0.739\n",
      "Epoch 747 Batch   75/100   train_loss = 0.787\n",
      "Epoch 748 Batch    0/100   train_loss = 0.701\n",
      "Epoch 748 Batch   25/100   train_loss = 0.782\n",
      "Epoch 748 Batch   50/100   train_loss = 0.722\n",
      "Epoch 748 Batch   75/100   train_loss = 0.813\n",
      "Epoch 749 Batch    0/100   train_loss = 0.693\n",
      "Epoch 749 Batch   25/100   train_loss = 0.789\n",
      "Epoch 749 Batch   50/100   train_loss = 0.694\n",
      "Epoch 749 Batch   75/100   train_loss = 0.790\n",
      "Epoch 750 Batch    0/100   train_loss = 0.713\n",
      "Epoch 750 Batch   25/100   train_loss = 0.840\n",
      "Epoch 750 Batch   50/100   train_loss = 0.737\n",
      "Epoch 750 Batch   75/100   train_loss = 0.780\n",
      "Epoch 751 Batch    0/100   train_loss = 0.700\n",
      "Epoch 751 Batch   25/100   train_loss = 0.822\n",
      "Epoch 751 Batch   50/100   train_loss = 0.705\n",
      "Epoch 751 Batch   75/100   train_loss = 0.786\n",
      "Epoch 752 Batch    0/100   train_loss = 0.689\n",
      "Epoch 752 Batch   25/100   train_loss = 0.788\n",
      "Epoch 752 Batch   50/100   train_loss = 0.712\n",
      "Epoch 752 Batch   75/100   train_loss = 0.770\n",
      "Epoch 753 Batch    0/100   train_loss = 0.639\n",
      "Epoch 753 Batch   25/100   train_loss = 0.772\n",
      "Epoch 753 Batch   50/100   train_loss = 0.716\n",
      "Epoch 753 Batch   75/100   train_loss = 0.769\n",
      "Epoch 754 Batch    0/100   train_loss = 0.692\n",
      "Epoch 754 Batch   25/100   train_loss = 0.797\n",
      "Epoch 754 Batch   50/100   train_loss = 0.709\n",
      "Epoch 754 Batch   75/100   train_loss = 0.794\n",
      "Epoch 755 Batch    0/100   train_loss = 0.662\n",
      "Epoch 755 Batch   25/100   train_loss = 0.808\n",
      "Epoch 755 Batch   50/100   train_loss = 0.726\n",
      "Epoch 755 Batch   75/100   train_loss = 0.783\n",
      "Epoch 756 Batch    0/100   train_loss = 0.711\n",
      "Epoch 756 Batch   25/100   train_loss = 0.787\n",
      "Epoch 756 Batch   50/100   train_loss = 0.695\n",
      "Epoch 756 Batch   75/100   train_loss = 0.759\n",
      "Epoch 757 Batch    0/100   train_loss = 0.675\n",
      "Epoch 757 Batch   25/100   train_loss = 0.796\n",
      "Epoch 757 Batch   50/100   train_loss = 0.712\n",
      "Epoch 757 Batch   75/100   train_loss = 0.802\n",
      "Epoch 758 Batch    0/100   train_loss = 0.678\n",
      "Epoch 758 Batch   25/100   train_loss = 0.797\n",
      "Epoch 758 Batch   50/100   train_loss = 0.719\n",
      "Epoch 758 Batch   75/100   train_loss = 0.764\n",
      "Epoch 759 Batch    0/100   train_loss = 0.707\n",
      "Epoch 759 Batch   25/100   train_loss = 0.792\n",
      "Epoch 759 Batch   50/100   train_loss = 0.733\n",
      "Epoch 759 Batch   75/100   train_loss = 0.773\n",
      "Epoch 760 Batch    0/100   train_loss = 0.704\n",
      "Epoch 760 Batch   25/100   train_loss = 0.803\n",
      "Epoch 760 Batch   50/100   train_loss = 0.744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760 Batch   75/100   train_loss = 0.767\n",
      "Epoch 761 Batch    0/100   train_loss = 0.711\n",
      "Epoch 761 Batch   25/100   train_loss = 0.807\n",
      "Epoch 761 Batch   50/100   train_loss = 0.723\n",
      "Epoch 761 Batch   75/100   train_loss = 0.781\n",
      "Epoch 762 Batch    0/100   train_loss = 0.650\n",
      "Epoch 762 Batch   25/100   train_loss = 0.785\n",
      "Epoch 762 Batch   50/100   train_loss = 0.700\n",
      "Epoch 762 Batch   75/100   train_loss = 0.793\n",
      "Epoch 763 Batch    0/100   train_loss = 0.661\n",
      "Epoch 763 Batch   25/100   train_loss = 0.812\n",
      "Epoch 763 Batch   50/100   train_loss = 0.681\n",
      "Epoch 763 Batch   75/100   train_loss = 0.733\n",
      "Epoch 764 Batch    0/100   train_loss = 0.688\n",
      "Epoch 764 Batch   25/100   train_loss = 0.798\n",
      "Epoch 764 Batch   50/100   train_loss = 0.736\n",
      "Epoch 764 Batch   75/100   train_loss = 0.747\n",
      "Epoch 765 Batch    0/100   train_loss = 0.683\n",
      "Epoch 765 Batch   25/100   train_loss = 0.777\n",
      "Epoch 765 Batch   50/100   train_loss = 0.696\n",
      "Epoch 765 Batch   75/100   train_loss = 0.762\n",
      "Epoch 766 Batch    0/100   train_loss = 0.677\n",
      "Epoch 766 Batch   25/100   train_loss = 0.773\n",
      "Epoch 766 Batch   50/100   train_loss = 0.691\n",
      "Epoch 766 Batch   75/100   train_loss = 0.766\n",
      "Epoch 767 Batch    0/100   train_loss = 0.652\n",
      "Epoch 767 Batch   25/100   train_loss = 0.807\n",
      "Epoch 767 Batch   50/100   train_loss = 0.693\n",
      "Epoch 767 Batch   75/100   train_loss = 0.775\n",
      "Epoch 768 Batch    0/100   train_loss = 0.673\n",
      "Epoch 768 Batch   25/100   train_loss = 0.821\n",
      "Epoch 768 Batch   50/100   train_loss = 0.705\n",
      "Epoch 768 Batch   75/100   train_loss = 0.745\n",
      "Epoch 769 Batch    0/100   train_loss = 0.670\n",
      "Epoch 769 Batch   25/100   train_loss = 0.790\n",
      "Epoch 769 Batch   50/100   train_loss = 0.733\n",
      "Epoch 769 Batch   75/100   train_loss = 0.721\n",
      "Epoch 770 Batch    0/100   train_loss = 0.660\n",
      "Epoch 770 Batch   25/100   train_loss = 0.761\n",
      "Epoch 770 Batch   50/100   train_loss = 0.726\n",
      "Epoch 770 Batch   75/100   train_loss = 0.800\n",
      "Epoch 771 Batch    0/100   train_loss = 0.698\n",
      "Epoch 771 Batch   25/100   train_loss = 0.781\n",
      "Epoch 771 Batch   50/100   train_loss = 0.706\n",
      "Epoch 771 Batch   75/100   train_loss = 0.747\n",
      "Epoch 772 Batch    0/100   train_loss = 0.646\n",
      "Epoch 772 Batch   25/100   train_loss = 0.769\n",
      "Epoch 772 Batch   50/100   train_loss = 0.689\n",
      "Epoch 772 Batch   75/100   train_loss = 0.781\n",
      "Epoch 773 Batch    0/100   train_loss = 0.678\n",
      "Epoch 773 Batch   25/100   train_loss = 0.774\n",
      "Epoch 773 Batch   50/100   train_loss = 0.672\n",
      "Epoch 773 Batch   75/100   train_loss = 0.747\n",
      "Epoch 774 Batch    0/100   train_loss = 0.668\n",
      "Epoch 774 Batch   25/100   train_loss = 0.793\n",
      "Epoch 774 Batch   50/100   train_loss = 0.690\n",
      "Epoch 774 Batch   75/100   train_loss = 0.723\n",
      "Epoch 775 Batch    0/100   train_loss = 0.645\n",
      "Epoch 775 Batch   25/100   train_loss = 0.779\n",
      "Epoch 775 Batch   50/100   train_loss = 0.707\n",
      "Epoch 775 Batch   75/100   train_loss = 0.781\n",
      "Epoch 776 Batch    0/100   train_loss = 0.668\n",
      "Epoch 776 Batch   25/100   train_loss = 0.766\n",
      "Epoch 776 Batch   50/100   train_loss = 0.707\n",
      "Epoch 776 Batch   75/100   train_loss = 0.717\n",
      "Epoch 777 Batch    0/100   train_loss = 0.664\n",
      "Epoch 777 Batch   25/100   train_loss = 0.825\n",
      "Epoch 777 Batch   50/100   train_loss = 0.717\n",
      "Epoch 777 Batch   75/100   train_loss = 0.725\n",
      "Epoch 778 Batch    0/100   train_loss = 0.668\n",
      "Epoch 778 Batch   25/100   train_loss = 0.788\n",
      "Epoch 778 Batch   50/100   train_loss = 0.682\n",
      "Epoch 778 Batch   75/100   train_loss = 0.754\n",
      "Epoch 779 Batch    0/100   train_loss = 0.649\n",
      "Epoch 779 Batch   25/100   train_loss = 0.771\n",
      "Epoch 779 Batch   50/100   train_loss = 0.706\n",
      "Epoch 779 Batch   75/100   train_loss = 0.760\n",
      "Epoch 780 Batch    0/100   train_loss = 0.640\n",
      "Epoch 780 Batch   25/100   train_loss = 0.796\n",
      "Epoch 780 Batch   50/100   train_loss = 0.679\n",
      "Epoch 780 Batch   75/100   train_loss = 0.743\n",
      "Epoch 781 Batch    0/100   train_loss = 0.659\n",
      "Epoch 781 Batch   25/100   train_loss = 0.771\n",
      "Epoch 781 Batch   50/100   train_loss = 0.693\n",
      "Epoch 781 Batch   75/100   train_loss = 0.758\n",
      "Epoch 782 Batch    0/100   train_loss = 0.676\n",
      "Epoch 782 Batch   25/100   train_loss = 0.778\n",
      "Epoch 782 Batch   50/100   train_loss = 0.717\n",
      "Epoch 782 Batch   75/100   train_loss = 0.763\n",
      "Epoch 783 Batch    0/100   train_loss = 0.652\n",
      "Epoch 783 Batch   25/100   train_loss = 0.822\n",
      "Epoch 783 Batch   50/100   train_loss = 0.687\n",
      "Epoch 783 Batch   75/100   train_loss = 0.750\n",
      "Epoch 784 Batch    0/100   train_loss = 0.645\n",
      "Epoch 784 Batch   25/100   train_loss = 0.805\n",
      "Epoch 784 Batch   50/100   train_loss = 0.663\n",
      "Epoch 784 Batch   75/100   train_loss = 0.737\n",
      "Epoch 785 Batch    0/100   train_loss = 0.670\n",
      "Epoch 785 Batch   25/100   train_loss = 0.769\n",
      "Epoch 785 Batch   50/100   train_loss = 0.671\n",
      "Epoch 785 Batch   75/100   train_loss = 0.723\n",
      "Epoch 786 Batch    0/100   train_loss = 0.641\n",
      "Epoch 786 Batch   25/100   train_loss = 0.786\n",
      "Epoch 786 Batch   50/100   train_loss = 0.704\n",
      "Epoch 786 Batch   75/100   train_loss = 0.748\n",
      "Epoch 787 Batch    0/100   train_loss = 0.688\n",
      "Epoch 787 Batch   25/100   train_loss = 0.796\n",
      "Epoch 787 Batch   50/100   train_loss = 0.700\n",
      "Epoch 787 Batch   75/100   train_loss = 0.735\n",
      "Epoch 788 Batch    0/100   train_loss = 0.632\n",
      "Epoch 788 Batch   25/100   train_loss = 0.788\n",
      "Epoch 788 Batch   50/100   train_loss = 0.701\n",
      "Epoch 788 Batch   75/100   train_loss = 0.760\n",
      "Epoch 789 Batch    0/100   train_loss = 0.633\n",
      "Epoch 789 Batch   25/100   train_loss = 0.762\n",
      "Epoch 789 Batch   50/100   train_loss = 0.702\n",
      "Epoch 789 Batch   75/100   train_loss = 0.725\n",
      "Epoch 790 Batch    0/100   train_loss = 0.622\n",
      "Epoch 790 Batch   25/100   train_loss = 0.771\n",
      "Epoch 790 Batch   50/100   train_loss = 0.718\n",
      "Epoch 790 Batch   75/100   train_loss = 0.729\n",
      "Epoch 791 Batch    0/100   train_loss = 0.628\n",
      "Epoch 791 Batch   25/100   train_loss = 0.753\n",
      "Epoch 791 Batch   50/100   train_loss = 0.695\n",
      "Epoch 791 Batch   75/100   train_loss = 0.732\n",
      "Epoch 792 Batch    0/100   train_loss = 0.667\n",
      "Epoch 792 Batch   25/100   train_loss = 0.790\n",
      "Epoch 792 Batch   50/100   train_loss = 0.686\n",
      "Epoch 792 Batch   75/100   train_loss = 0.724\n",
      "Epoch 793 Batch    0/100   train_loss = 0.622\n",
      "Epoch 793 Batch   25/100   train_loss = 0.754\n",
      "Epoch 793 Batch   50/100   train_loss = 0.686\n",
      "Epoch 793 Batch   75/100   train_loss = 0.739\n",
      "Epoch 794 Batch    0/100   train_loss = 0.631\n",
      "Epoch 794 Batch   25/100   train_loss = 0.753\n",
      "Epoch 794 Batch   50/100   train_loss = 0.660\n",
      "Epoch 794 Batch   75/100   train_loss = 0.700\n",
      "Epoch 795 Batch    0/100   train_loss = 0.630\n",
      "Epoch 795 Batch   25/100   train_loss = 0.757\n",
      "Epoch 795 Batch   50/100   train_loss = 0.627\n",
      "Epoch 795 Batch   75/100   train_loss = 0.753\n",
      "Epoch 796 Batch    0/100   train_loss = 0.621\n",
      "Epoch 796 Batch   25/100   train_loss = 0.773\n",
      "Epoch 796 Batch   50/100   train_loss = 0.683\n",
      "Epoch 796 Batch   75/100   train_loss = 0.716\n",
      "Epoch 797 Batch    0/100   train_loss = 0.653\n",
      "Epoch 797 Batch   25/100   train_loss = 0.750\n",
      "Epoch 797 Batch   50/100   train_loss = 0.682\n",
      "Epoch 797 Batch   75/100   train_loss = 0.715\n",
      "Epoch 798 Batch    0/100   train_loss = 0.643\n",
      "Epoch 798 Batch   25/100   train_loss = 0.772\n",
      "Epoch 798 Batch   50/100   train_loss = 0.712\n",
      "Epoch 798 Batch   75/100   train_loss = 0.744\n",
      "Epoch 799 Batch    0/100   train_loss = 0.628\n",
      "Epoch 799 Batch   25/100   train_loss = 0.781\n",
      "Epoch 799 Batch   50/100   train_loss = 0.699\n",
      "Epoch 799 Batch   75/100   train_loss = 0.747\n",
      "Epoch 800 Batch    0/100   train_loss = 0.619\n",
      "Epoch 800 Batch   25/100   train_loss = 0.791\n",
      "Epoch 800 Batch   50/100   train_loss = 0.671\n",
      "Epoch 800 Batch   75/100   train_loss = 0.741\n",
      "Epoch 801 Batch    0/100   train_loss = 0.680\n",
      "Epoch 801 Batch   25/100   train_loss = 0.772\n",
      "Epoch 801 Batch   50/100   train_loss = 0.682\n",
      "Epoch 801 Batch   75/100   train_loss = 0.738\n",
      "Epoch 802 Batch    0/100   train_loss = 0.633\n",
      "Epoch 802 Batch   25/100   train_loss = 0.740\n",
      "Epoch 802 Batch   50/100   train_loss = 0.687\n",
      "Epoch 802 Batch   75/100   train_loss = 0.727\n",
      "Epoch 803 Batch    0/100   train_loss = 0.664\n",
      "Epoch 803 Batch   25/100   train_loss = 0.742\n",
      "Epoch 803 Batch   50/100   train_loss = 0.666\n",
      "Epoch 803 Batch   75/100   train_loss = 0.722\n",
      "Epoch 804 Batch    0/100   train_loss = 0.684\n",
      "Epoch 804 Batch   25/100   train_loss = 0.765\n",
      "Epoch 804 Batch   50/100   train_loss = 0.699\n",
      "Epoch 804 Batch   75/100   train_loss = 0.741\n",
      "Epoch 805 Batch    0/100   train_loss = 0.619\n",
      "Epoch 805 Batch   25/100   train_loss = 0.787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 805 Batch   50/100   train_loss = 0.654\n",
      "Epoch 805 Batch   75/100   train_loss = 0.717\n",
      "Epoch 806 Batch    0/100   train_loss = 0.615\n",
      "Epoch 806 Batch   25/100   train_loss = 0.740\n",
      "Epoch 806 Batch   50/100   train_loss = 0.676\n",
      "Epoch 806 Batch   75/100   train_loss = 0.736\n",
      "Epoch 807 Batch    0/100   train_loss = 0.640\n",
      "Epoch 807 Batch   25/100   train_loss = 0.744\n",
      "Epoch 807 Batch   50/100   train_loss = 0.678\n",
      "Epoch 807 Batch   75/100   train_loss = 0.715\n",
      "Epoch 808 Batch    0/100   train_loss = 0.642\n",
      "Epoch 808 Batch   25/100   train_loss = 0.777\n",
      "Epoch 808 Batch   50/100   train_loss = 0.678\n",
      "Epoch 808 Batch   75/100   train_loss = 0.728\n",
      "Epoch 809 Batch    0/100   train_loss = 0.596\n",
      "Epoch 809 Batch   25/100   train_loss = 0.738\n",
      "Epoch 809 Batch   50/100   train_loss = 0.631\n",
      "Epoch 809 Batch   75/100   train_loss = 0.737\n",
      "Epoch 810 Batch    0/100   train_loss = 0.643\n",
      "Epoch 810 Batch   25/100   train_loss = 0.751\n",
      "Epoch 810 Batch   50/100   train_loss = 0.693\n",
      "Epoch 810 Batch   75/100   train_loss = 0.726\n",
      "Epoch 811 Batch    0/100   train_loss = 0.592\n",
      "Epoch 811 Batch   25/100   train_loss = 0.755\n",
      "Epoch 811 Batch   50/100   train_loss = 0.634\n",
      "Epoch 811 Batch   75/100   train_loss = 0.697\n",
      "Epoch 812 Batch    0/100   train_loss = 0.619\n",
      "Epoch 812 Batch   25/100   train_loss = 0.737\n",
      "Epoch 812 Batch   50/100   train_loss = 0.679\n",
      "Epoch 812 Batch   75/100   train_loss = 0.700\n",
      "Epoch 813 Batch    0/100   train_loss = 0.604\n",
      "Epoch 813 Batch   25/100   train_loss = 0.736\n",
      "Epoch 813 Batch   50/100   train_loss = 0.646\n",
      "Epoch 813 Batch   75/100   train_loss = 0.693\n",
      "Epoch 814 Batch    0/100   train_loss = 0.620\n",
      "Epoch 814 Batch   25/100   train_loss = 0.728\n",
      "Epoch 814 Batch   50/100   train_loss = 0.656\n",
      "Epoch 814 Batch   75/100   train_loss = 0.692\n",
      "Epoch 815 Batch    0/100   train_loss = 0.630\n",
      "Epoch 815 Batch   25/100   train_loss = 0.744\n",
      "Epoch 815 Batch   50/100   train_loss = 0.684\n",
      "Epoch 815 Batch   75/100   train_loss = 0.720\n",
      "Epoch 816 Batch    0/100   train_loss = 0.650\n",
      "Epoch 816 Batch   25/100   train_loss = 0.753\n",
      "Epoch 816 Batch   50/100   train_loss = 0.672\n",
      "Epoch 816 Batch   75/100   train_loss = 0.764\n",
      "Epoch 817 Batch    0/100   train_loss = 0.631\n",
      "Epoch 817 Batch   25/100   train_loss = 0.743\n",
      "Epoch 817 Batch   50/100   train_loss = 0.613\n",
      "Epoch 817 Batch   75/100   train_loss = 0.706\n",
      "Epoch 818 Batch    0/100   train_loss = 0.635\n",
      "Epoch 818 Batch   25/100   train_loss = 0.728\n",
      "Epoch 818 Batch   50/100   train_loss = 0.663\n",
      "Epoch 818 Batch   75/100   train_loss = 0.713\n",
      "Epoch 819 Batch    0/100   train_loss = 0.638\n",
      "Epoch 819 Batch   25/100   train_loss = 0.705\n",
      "Epoch 819 Batch   50/100   train_loss = 0.636\n",
      "Epoch 819 Batch   75/100   train_loss = 0.719\n",
      "Epoch 820 Batch    0/100   train_loss = 0.602\n",
      "Epoch 820 Batch   25/100   train_loss = 0.737\n",
      "Epoch 820 Batch   50/100   train_loss = 0.631\n",
      "Epoch 820 Batch   75/100   train_loss = 0.708\n",
      "Epoch 821 Batch    0/100   train_loss = 0.638\n",
      "Epoch 821 Batch   25/100   train_loss = 0.730\n",
      "Epoch 821 Batch   50/100   train_loss = 0.678\n",
      "Epoch 821 Batch   75/100   train_loss = 0.690\n",
      "Epoch 822 Batch    0/100   train_loss = 0.617\n",
      "Epoch 822 Batch   25/100   train_loss = 0.725\n",
      "Epoch 822 Batch   50/100   train_loss = 0.645\n",
      "Epoch 822 Batch   75/100   train_loss = 0.731\n",
      "Epoch 823 Batch    0/100   train_loss = 0.645\n",
      "Epoch 823 Batch   25/100   train_loss = 0.737\n",
      "Epoch 823 Batch   50/100   train_loss = 0.693\n",
      "Epoch 823 Batch   75/100   train_loss = 0.722\n",
      "Epoch 824 Batch    0/100   train_loss = 0.603\n",
      "Epoch 824 Batch   25/100   train_loss = 0.743\n",
      "Epoch 824 Batch   50/100   train_loss = 0.649\n",
      "Epoch 824 Batch   75/100   train_loss = 0.694\n",
      "Epoch 825 Batch    0/100   train_loss = 0.616\n",
      "Epoch 825 Batch   25/100   train_loss = 0.710\n",
      "Epoch 825 Batch   50/100   train_loss = 0.663\n",
      "Epoch 825 Batch   75/100   train_loss = 0.700\n",
      "Epoch 826 Batch    0/100   train_loss = 0.590\n",
      "Epoch 826 Batch   25/100   train_loss = 0.828\n",
      "Epoch 826 Batch   50/100   train_loss = 0.616\n",
      "Epoch 826 Batch   75/100   train_loss = 0.705\n",
      "Epoch 827 Batch    0/100   train_loss = 0.621\n",
      "Epoch 827 Batch   25/100   train_loss = 0.725\n",
      "Epoch 827 Batch   50/100   train_loss = 0.632\n",
      "Epoch 827 Batch   75/100   train_loss = 0.700\n",
      "Epoch 828 Batch    0/100   train_loss = 0.633\n",
      "Epoch 828 Batch   25/100   train_loss = 0.728\n",
      "Epoch 828 Batch   50/100   train_loss = 0.637\n",
      "Epoch 828 Batch   75/100   train_loss = 0.666\n",
      "Epoch 829 Batch    0/100   train_loss = 0.638\n",
      "Epoch 829 Batch   25/100   train_loss = 0.749\n",
      "Epoch 829 Batch   50/100   train_loss = 0.674\n",
      "Epoch 829 Batch   75/100   train_loss = 0.660\n",
      "Epoch 830 Batch    0/100   train_loss = 0.600\n",
      "Epoch 830 Batch   25/100   train_loss = 0.715\n",
      "Epoch 830 Batch   50/100   train_loss = 0.625\n",
      "Epoch 830 Batch   75/100   train_loss = 0.688\n",
      "Epoch 831 Batch    0/100   train_loss = 0.632\n",
      "Epoch 831 Batch   25/100   train_loss = 0.703\n",
      "Epoch 831 Batch   50/100   train_loss = 0.651\n",
      "Epoch 831 Batch   75/100   train_loss = 0.716\n",
      "Epoch 832 Batch    0/100   train_loss = 0.600\n",
      "Epoch 832 Batch   25/100   train_loss = 0.713\n",
      "Epoch 832 Batch   50/100   train_loss = 0.637\n",
      "Epoch 832 Batch   75/100   train_loss = 0.714\n",
      "Epoch 833 Batch    0/100   train_loss = 0.599\n",
      "Epoch 833 Batch   25/100   train_loss = 0.744\n",
      "Epoch 833 Batch   50/100   train_loss = 0.685\n",
      "Epoch 833 Batch   75/100   train_loss = 0.699\n",
      "Epoch 834 Batch    0/100   train_loss = 0.629\n",
      "Epoch 834 Batch   25/100   train_loss = 0.741\n",
      "Epoch 834 Batch   50/100   train_loss = 0.670\n",
      "Epoch 834 Batch   75/100   train_loss = 0.711\n",
      "Epoch 835 Batch    0/100   train_loss = 0.584\n",
      "Epoch 835 Batch   25/100   train_loss = 0.738\n",
      "Epoch 835 Batch   50/100   train_loss = 0.638\n",
      "Epoch 835 Batch   75/100   train_loss = 0.689\n",
      "Epoch 836 Batch    0/100   train_loss = 0.602\n",
      "Epoch 836 Batch   25/100   train_loss = 0.717\n",
      "Epoch 836 Batch   50/100   train_loss = 0.667\n",
      "Epoch 836 Batch   75/100   train_loss = 0.705\n",
      "Epoch 837 Batch    0/100   train_loss = 0.605\n",
      "Epoch 837 Batch   25/100   train_loss = 0.735\n",
      "Epoch 837 Batch   50/100   train_loss = 0.644\n",
      "Epoch 837 Batch   75/100   train_loss = 0.700\n",
      "Epoch 838 Batch    0/100   train_loss = 0.616\n",
      "Epoch 838 Batch   25/100   train_loss = 0.736\n",
      "Epoch 838 Batch   50/100   train_loss = 0.654\n",
      "Epoch 838 Batch   75/100   train_loss = 0.735\n",
      "Epoch 839 Batch    0/100   train_loss = 0.617\n",
      "Epoch 839 Batch   25/100   train_loss = 0.687\n",
      "Epoch 839 Batch   50/100   train_loss = 0.659\n",
      "Epoch 839 Batch   75/100   train_loss = 0.713\n",
      "Epoch 840 Batch    0/100   train_loss = 0.622\n",
      "Epoch 840 Batch   25/100   train_loss = 0.780\n",
      "Epoch 840 Batch   50/100   train_loss = 0.640\n",
      "Epoch 840 Batch   75/100   train_loss = 0.696\n",
      "Epoch 841 Batch    0/100   train_loss = 0.586\n",
      "Epoch 841 Batch   25/100   train_loss = 0.730\n",
      "Epoch 841 Batch   50/100   train_loss = 0.623\n",
      "Epoch 841 Batch   75/100   train_loss = 0.725\n",
      "Epoch 842 Batch    0/100   train_loss = 0.604\n",
      "Epoch 842 Batch   25/100   train_loss = 0.725\n",
      "Epoch 842 Batch   50/100   train_loss = 0.625\n",
      "Epoch 842 Batch   75/100   train_loss = 0.693\n",
      "Epoch 843 Batch    0/100   train_loss = 0.610\n",
      "Epoch 843 Batch   25/100   train_loss = 0.771\n",
      "Epoch 843 Batch   50/100   train_loss = 0.640\n",
      "Epoch 843 Batch   75/100   train_loss = 0.721\n",
      "Epoch 844 Batch    0/100   train_loss = 0.595\n",
      "Epoch 844 Batch   25/100   train_loss = 0.717\n",
      "Epoch 844 Batch   50/100   train_loss = 0.630\n",
      "Epoch 844 Batch   75/100   train_loss = 0.668\n",
      "Epoch 845 Batch    0/100   train_loss = 0.633\n",
      "Epoch 845 Batch   25/100   train_loss = 0.719\n",
      "Epoch 845 Batch   50/100   train_loss = 0.618\n",
      "Epoch 845 Batch   75/100   train_loss = 0.709\n",
      "Epoch 846 Batch    0/100   train_loss = 0.579\n",
      "Epoch 846 Batch   25/100   train_loss = 0.707\n",
      "Epoch 846 Batch   50/100   train_loss = 0.637\n",
      "Epoch 846 Batch   75/100   train_loss = 0.697\n",
      "Epoch 847 Batch    0/100   train_loss = 0.587\n",
      "Epoch 847 Batch   25/100   train_loss = 0.729\n",
      "Epoch 847 Batch   50/100   train_loss = 0.616\n",
      "Epoch 847 Batch   75/100   train_loss = 0.692\n",
      "Epoch 848 Batch    0/100   train_loss = 0.575\n",
      "Epoch 848 Batch   25/100   train_loss = 0.741\n",
      "Epoch 848 Batch   50/100   train_loss = 0.649\n",
      "Epoch 848 Batch   75/100   train_loss = 0.671\n",
      "Epoch 849 Batch    0/100   train_loss = 0.601\n",
      "Epoch 849 Batch   25/100   train_loss = 0.733\n",
      "Epoch 849 Batch   50/100   train_loss = 0.641\n",
      "Epoch 849 Batch   75/100   train_loss = 0.703\n",
      "Epoch 850 Batch    0/100   train_loss = 0.592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850 Batch   25/100   train_loss = 0.715\n",
      "Epoch 850 Batch   50/100   train_loss = 0.629\n",
      "Epoch 850 Batch   75/100   train_loss = 0.685\n",
      "Epoch 851 Batch    0/100   train_loss = 0.623\n",
      "Epoch 851 Batch   25/100   train_loss = 0.741\n",
      "Epoch 851 Batch   50/100   train_loss = 0.639\n",
      "Epoch 851 Batch   75/100   train_loss = 0.682\n",
      "Epoch 852 Batch    0/100   train_loss = 0.602\n",
      "Epoch 852 Batch   25/100   train_loss = 0.709\n",
      "Epoch 852 Batch   50/100   train_loss = 0.660\n",
      "Epoch 852 Batch   75/100   train_loss = 0.696\n",
      "Epoch 853 Batch    0/100   train_loss = 0.589\n",
      "Epoch 853 Batch   25/100   train_loss = 0.728\n",
      "Epoch 853 Batch   50/100   train_loss = 0.640\n",
      "Epoch 853 Batch   75/100   train_loss = 0.688\n",
      "Epoch 854 Batch    0/100   train_loss = 0.561\n",
      "Epoch 854 Batch   25/100   train_loss = 0.715\n",
      "Epoch 854 Batch   50/100   train_loss = 0.646\n",
      "Epoch 854 Batch   75/100   train_loss = 0.645\n",
      "Epoch 855 Batch    0/100   train_loss = 0.575\n",
      "Epoch 855 Batch   25/100   train_loss = 0.702\n",
      "Epoch 855 Batch   50/100   train_loss = 0.627\n",
      "Epoch 855 Batch   75/100   train_loss = 0.682\n",
      "Epoch 856 Batch    0/100   train_loss = 0.601\n",
      "Epoch 856 Batch   25/100   train_loss = 0.713\n",
      "Epoch 856 Batch   50/100   train_loss = 0.636\n",
      "Epoch 856 Batch   75/100   train_loss = 0.726\n",
      "Epoch 857 Batch    0/100   train_loss = 0.633\n",
      "Epoch 857 Batch   25/100   train_loss = 0.689\n",
      "Epoch 857 Batch   50/100   train_loss = 0.629\n",
      "Epoch 857 Batch   75/100   train_loss = 0.659\n",
      "Epoch 858 Batch    0/100   train_loss = 0.598\n",
      "Epoch 858 Batch   25/100   train_loss = 0.725\n",
      "Epoch 858 Batch   50/100   train_loss = 0.633\n",
      "Epoch 858 Batch   75/100   train_loss = 0.664\n",
      "Epoch 859 Batch    0/100   train_loss = 0.609\n",
      "Epoch 859 Batch   25/100   train_loss = 0.710\n",
      "Epoch 859 Batch   50/100   train_loss = 0.621\n",
      "Epoch 859 Batch   75/100   train_loss = 0.661\n",
      "Epoch 860 Batch    0/100   train_loss = 0.623\n",
      "Epoch 860 Batch   25/100   train_loss = 0.759\n",
      "Epoch 860 Batch   50/100   train_loss = 0.636\n",
      "Epoch 860 Batch   75/100   train_loss = 0.670\n",
      "Epoch 861 Batch    0/100   train_loss = 0.590\n",
      "Epoch 861 Batch   25/100   train_loss = 0.712\n",
      "Epoch 861 Batch   50/100   train_loss = 0.670\n",
      "Epoch 861 Batch   75/100   train_loss = 0.634\n",
      "Epoch 862 Batch    0/100   train_loss = 0.578\n",
      "Epoch 862 Batch   25/100   train_loss = 0.733\n",
      "Epoch 862 Batch   50/100   train_loss = 0.641\n",
      "Epoch 862 Batch   75/100   train_loss = 0.675\n",
      "Epoch 863 Batch    0/100   train_loss = 0.565\n",
      "Epoch 863 Batch   25/100   train_loss = 0.731\n",
      "Epoch 863 Batch   50/100   train_loss = 0.628\n",
      "Epoch 863 Batch   75/100   train_loss = 0.631\n",
      "Epoch 864 Batch    0/100   train_loss = 0.576\n",
      "Epoch 864 Batch   25/100   train_loss = 0.755\n",
      "Epoch 864 Batch   50/100   train_loss = 0.653\n",
      "Epoch 864 Batch   75/100   train_loss = 0.692\n",
      "Epoch 865 Batch    0/100   train_loss = 0.568\n",
      "Epoch 865 Batch   25/100   train_loss = 0.714\n",
      "Epoch 865 Batch   50/100   train_loss = 0.650\n",
      "Epoch 865 Batch   75/100   train_loss = 0.702\n",
      "Epoch 866 Batch    0/100   train_loss = 0.582\n",
      "Epoch 866 Batch   25/100   train_loss = 0.694\n",
      "Epoch 866 Batch   50/100   train_loss = 0.597\n",
      "Epoch 866 Batch   75/100   train_loss = 0.637\n",
      "Epoch 867 Batch    0/100   train_loss = 0.587\n",
      "Epoch 867 Batch   25/100   train_loss = 0.734\n",
      "Epoch 867 Batch   50/100   train_loss = 0.651\n",
      "Epoch 867 Batch   75/100   train_loss = 0.668\n",
      "Epoch 868 Batch    0/100   train_loss = 0.582\n",
      "Epoch 868 Batch   25/100   train_loss = 0.725\n",
      "Epoch 868 Batch   50/100   train_loss = 0.584\n",
      "Epoch 868 Batch   75/100   train_loss = 0.662\n",
      "Epoch 869 Batch    0/100   train_loss = 0.606\n",
      "Epoch 869 Batch   25/100   train_loss = 0.695\n",
      "Epoch 869 Batch   50/100   train_loss = 0.644\n",
      "Epoch 869 Batch   75/100   train_loss = 0.682\n",
      "Epoch 870 Batch    0/100   train_loss = 0.590\n",
      "Epoch 870 Batch   25/100   train_loss = 0.714\n",
      "Epoch 870 Batch   50/100   train_loss = 0.580\n",
      "Epoch 870 Batch   75/100   train_loss = 0.660\n",
      "Epoch 871 Batch    0/100   train_loss = 0.613\n",
      "Epoch 871 Batch   25/100   train_loss = 0.706\n",
      "Epoch 871 Batch   50/100   train_loss = 0.618\n",
      "Epoch 871 Batch   75/100   train_loss = 0.633\n",
      "Epoch 872 Batch    0/100   train_loss = 0.587\n",
      "Epoch 872 Batch   25/100   train_loss = 0.724\n",
      "Epoch 872 Batch   50/100   train_loss = 0.639\n",
      "Epoch 872 Batch   75/100   train_loss = 0.624\n",
      "Epoch 873 Batch    0/100   train_loss = 0.568\n",
      "Epoch 873 Batch   25/100   train_loss = 0.673\n",
      "Epoch 873 Batch   50/100   train_loss = 0.645\n",
      "Epoch 873 Batch   75/100   train_loss = 0.645\n",
      "Epoch 874 Batch    0/100   train_loss = 0.585\n",
      "Epoch 874 Batch   25/100   train_loss = 0.692\n",
      "Epoch 874 Batch   50/100   train_loss = 0.606\n",
      "Epoch 874 Batch   75/100   train_loss = 0.639\n",
      "Epoch 875 Batch    0/100   train_loss = 0.574\n",
      "Epoch 875 Batch   25/100   train_loss = 0.700\n",
      "Epoch 875 Batch   50/100   train_loss = 0.613\n",
      "Epoch 875 Batch   75/100   train_loss = 0.599\n",
      "Epoch 876 Batch    0/100   train_loss = 0.608\n",
      "Epoch 876 Batch   25/100   train_loss = 0.718\n",
      "Epoch 876 Batch   50/100   train_loss = 0.612\n",
      "Epoch 876 Batch   75/100   train_loss = 0.666\n",
      "Epoch 877 Batch    0/100   train_loss = 0.531\n",
      "Epoch 877 Batch   25/100   train_loss = 0.719\n",
      "Epoch 877 Batch   50/100   train_loss = 0.628\n",
      "Epoch 877 Batch   75/100   train_loss = 0.707\n",
      "Epoch 878 Batch    0/100   train_loss = 0.565\n",
      "Epoch 878 Batch   25/100   train_loss = 0.704\n",
      "Epoch 878 Batch   50/100   train_loss = 0.610\n",
      "Epoch 878 Batch   75/100   train_loss = 0.698\n",
      "Epoch 879 Batch    0/100   train_loss = 0.591\n",
      "Epoch 879 Batch   25/100   train_loss = 0.707\n",
      "Epoch 879 Batch   50/100   train_loss = 0.609\n",
      "Epoch 879 Batch   75/100   train_loss = 0.612\n",
      "Epoch 880 Batch    0/100   train_loss = 0.545\n",
      "Epoch 880 Batch   25/100   train_loss = 0.716\n",
      "Epoch 880 Batch   50/100   train_loss = 0.612\n",
      "Epoch 880 Batch   75/100   train_loss = 0.646\n",
      "Epoch 881 Batch    0/100   train_loss = 0.585\n",
      "Epoch 881 Batch   25/100   train_loss = 0.682\n",
      "Epoch 881 Batch   50/100   train_loss = 0.603\n",
      "Epoch 881 Batch   75/100   train_loss = 0.665\n",
      "Epoch 882 Batch    0/100   train_loss = 0.568\n",
      "Epoch 882 Batch   25/100   train_loss = 0.712\n",
      "Epoch 882 Batch   50/100   train_loss = 0.617\n",
      "Epoch 882 Batch   75/100   train_loss = 0.643\n",
      "Epoch 883 Batch    0/100   train_loss = 0.579\n",
      "Epoch 883 Batch   25/100   train_loss = 0.726\n",
      "Epoch 883 Batch   50/100   train_loss = 0.609\n",
      "Epoch 883 Batch   75/100   train_loss = 0.661\n",
      "Epoch 884 Batch    0/100   train_loss = 0.567\n",
      "Epoch 884 Batch   25/100   train_loss = 0.709\n",
      "Epoch 884 Batch   50/100   train_loss = 0.596\n",
      "Epoch 884 Batch   75/100   train_loss = 0.701\n",
      "Epoch 885 Batch    0/100   train_loss = 0.604\n",
      "Epoch 885 Batch   25/100   train_loss = 0.642\n",
      "Epoch 885 Batch   50/100   train_loss = 0.588\n",
      "Epoch 885 Batch   75/100   train_loss = 0.636\n",
      "Epoch 886 Batch    0/100   train_loss = 0.608\n",
      "Epoch 886 Batch   25/100   train_loss = 0.699\n",
      "Epoch 886 Batch   50/100   train_loss = 0.645\n",
      "Epoch 886 Batch   75/100   train_loss = 0.615\n",
      "Epoch 887 Batch    0/100   train_loss = 0.583\n",
      "Epoch 887 Batch   25/100   train_loss = 0.692\n",
      "Epoch 887 Batch   50/100   train_loss = 0.620\n",
      "Epoch 887 Batch   75/100   train_loss = 0.653\n",
      "Epoch 888 Batch    0/100   train_loss = 0.553\n",
      "Epoch 888 Batch   25/100   train_loss = 0.706\n",
      "Epoch 888 Batch   50/100   train_loss = 0.611\n",
      "Epoch 888 Batch   75/100   train_loss = 0.683\n",
      "Epoch 889 Batch    0/100   train_loss = 0.545\n",
      "Epoch 889 Batch   25/100   train_loss = 0.711\n",
      "Epoch 889 Batch   50/100   train_loss = 0.619\n",
      "Epoch 889 Batch   75/100   train_loss = 0.625\n",
      "Epoch 890 Batch    0/100   train_loss = 0.574\n",
      "Epoch 890 Batch   25/100   train_loss = 0.696\n",
      "Epoch 890 Batch   50/100   train_loss = 0.622\n",
      "Epoch 890 Batch   75/100   train_loss = 0.664\n",
      "Epoch 891 Batch    0/100   train_loss = 0.553\n",
      "Epoch 891 Batch   25/100   train_loss = 0.679\n",
      "Epoch 891 Batch   50/100   train_loss = 0.630\n",
      "Epoch 891 Batch   75/100   train_loss = 0.641\n",
      "Epoch 892 Batch    0/100   train_loss = 0.556\n",
      "Epoch 892 Batch   25/100   train_loss = 0.671\n",
      "Epoch 892 Batch   50/100   train_loss = 0.613\n",
      "Epoch 892 Batch   75/100   train_loss = 0.664\n",
      "Epoch 893 Batch    0/100   train_loss = 0.555\n",
      "Epoch 893 Batch   25/100   train_loss = 0.687\n",
      "Epoch 893 Batch   50/100   train_loss = 0.619\n",
      "Epoch 893 Batch   75/100   train_loss = 0.632\n",
      "Epoch 894 Batch    0/100   train_loss = 0.559\n",
      "Epoch 894 Batch   25/100   train_loss = 0.677\n",
      "Epoch 894 Batch   50/100   train_loss = 0.609\n",
      "Epoch 894 Batch   75/100   train_loss = 0.624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895 Batch    0/100   train_loss = 0.546\n",
      "Epoch 895 Batch   25/100   train_loss = 0.700\n",
      "Epoch 895 Batch   50/100   train_loss = 0.613\n",
      "Epoch 895 Batch   75/100   train_loss = 0.634\n",
      "Epoch 896 Batch    0/100   train_loss = 0.557\n",
      "Epoch 896 Batch   25/100   train_loss = 0.687\n",
      "Epoch 896 Batch   50/100   train_loss = 0.617\n",
      "Epoch 896 Batch   75/100   train_loss = 0.634\n",
      "Epoch 897 Batch    0/100   train_loss = 0.566\n",
      "Epoch 897 Batch   25/100   train_loss = 0.727\n",
      "Epoch 897 Batch   50/100   train_loss = 0.618\n",
      "Epoch 897 Batch   75/100   train_loss = 0.662\n",
      "Epoch 898 Batch    0/100   train_loss = 0.543\n",
      "Epoch 898 Batch   25/100   train_loss = 0.682\n",
      "Epoch 898 Batch   50/100   train_loss = 0.600\n",
      "Epoch 898 Batch   75/100   train_loss = 0.640\n",
      "Epoch 899 Batch    0/100   train_loss = 0.546\n",
      "Epoch 899 Batch   25/100   train_loss = 0.694\n",
      "Epoch 899 Batch   50/100   train_loss = 0.608\n",
      "Epoch 899 Batch   75/100   train_loss = 0.633\n",
      "Epoch 900 Batch    0/100   train_loss = 0.565\n",
      "Epoch 900 Batch   25/100   train_loss = 0.717\n",
      "Epoch 900 Batch   50/100   train_loss = 0.620\n",
      "Epoch 900 Batch   75/100   train_loss = 0.639\n",
      "Epoch 901 Batch    0/100   train_loss = 0.563\n",
      "Epoch 901 Batch   25/100   train_loss = 0.695\n",
      "Epoch 901 Batch   50/100   train_loss = 0.617\n",
      "Epoch 901 Batch   75/100   train_loss = 0.624\n",
      "Epoch 902 Batch    0/100   train_loss = 0.586\n",
      "Epoch 902 Batch   25/100   train_loss = 0.655\n",
      "Epoch 902 Batch   50/100   train_loss = 0.586\n",
      "Epoch 902 Batch   75/100   train_loss = 0.629\n",
      "Epoch 903 Batch    0/100   train_loss = 0.531\n",
      "Epoch 903 Batch   25/100   train_loss = 0.688\n",
      "Epoch 903 Batch   50/100   train_loss = 0.629\n",
      "Epoch 903 Batch   75/100   train_loss = 0.663\n",
      "Epoch 904 Batch    0/100   train_loss = 0.581\n",
      "Epoch 904 Batch   25/100   train_loss = 0.701\n",
      "Epoch 904 Batch   50/100   train_loss = 0.587\n",
      "Epoch 904 Batch   75/100   train_loss = 0.665\n",
      "Epoch 905 Batch    0/100   train_loss = 0.545\n",
      "Epoch 905 Batch   25/100   train_loss = 0.697\n",
      "Epoch 905 Batch   50/100   train_loss = 0.596\n",
      "Epoch 905 Batch   75/100   train_loss = 0.664\n",
      "Epoch 906 Batch    0/100   train_loss = 0.546\n",
      "Epoch 906 Batch   25/100   train_loss = 0.691\n",
      "Epoch 906 Batch   50/100   train_loss = 0.588\n",
      "Epoch 906 Batch   75/100   train_loss = 0.617\n",
      "Epoch 907 Batch    0/100   train_loss = 0.545\n",
      "Epoch 907 Batch   25/100   train_loss = 0.716\n",
      "Epoch 907 Batch   50/100   train_loss = 0.599\n",
      "Epoch 907 Batch   75/100   train_loss = 0.648\n",
      "Epoch 908 Batch    0/100   train_loss = 0.554\n",
      "Epoch 908 Batch   25/100   train_loss = 0.696\n",
      "Epoch 908 Batch   50/100   train_loss = 0.597\n",
      "Epoch 908 Batch   75/100   train_loss = 0.654\n",
      "Epoch 909 Batch    0/100   train_loss = 0.573\n",
      "Epoch 909 Batch   25/100   train_loss = 0.673\n",
      "Epoch 909 Batch   50/100   train_loss = 0.572\n",
      "Epoch 909 Batch   75/100   train_loss = 0.659\n",
      "Epoch 910 Batch    0/100   train_loss = 0.575\n",
      "Epoch 910 Batch   25/100   train_loss = 0.669\n",
      "Epoch 910 Batch   50/100   train_loss = 0.620\n",
      "Epoch 910 Batch   75/100   train_loss = 0.616\n",
      "Epoch 911 Batch    0/100   train_loss = 0.554\n",
      "Epoch 911 Batch   25/100   train_loss = 0.661\n",
      "Epoch 911 Batch   50/100   train_loss = 0.585\n",
      "Epoch 911 Batch   75/100   train_loss = 0.630\n",
      "Epoch 912 Batch    0/100   train_loss = 0.566\n",
      "Epoch 912 Batch   25/100   train_loss = 0.672\n",
      "Epoch 912 Batch   50/100   train_loss = 0.586\n",
      "Epoch 912 Batch   75/100   train_loss = 0.627\n",
      "Epoch 913 Batch    0/100   train_loss = 0.535\n",
      "Epoch 913 Batch   25/100   train_loss = 0.706\n",
      "Epoch 913 Batch   50/100   train_loss = 0.558\n",
      "Epoch 913 Batch   75/100   train_loss = 0.613\n",
      "Epoch 914 Batch    0/100   train_loss = 0.539\n",
      "Epoch 914 Batch   25/100   train_loss = 0.679\n",
      "Epoch 914 Batch   50/100   train_loss = 0.600\n",
      "Epoch 914 Batch   75/100   train_loss = 0.600\n",
      "Epoch 915 Batch    0/100   train_loss = 0.544\n",
      "Epoch 915 Batch   25/100   train_loss = 0.705\n",
      "Epoch 915 Batch   50/100   train_loss = 0.609\n",
      "Epoch 915 Batch   75/100   train_loss = 0.640\n",
      "Epoch 916 Batch    0/100   train_loss = 0.545\n",
      "Epoch 916 Batch   25/100   train_loss = 0.668\n",
      "Epoch 916 Batch   50/100   train_loss = 0.564\n",
      "Epoch 916 Batch   75/100   train_loss = 0.659\n",
      "Epoch 917 Batch    0/100   train_loss = 0.584\n",
      "Epoch 917 Batch   25/100   train_loss = 0.699\n",
      "Epoch 917 Batch   50/100   train_loss = 0.597\n",
      "Epoch 917 Batch   75/100   train_loss = 0.623\n",
      "Epoch 918 Batch    0/100   train_loss = 0.535\n",
      "Epoch 918 Batch   25/100   train_loss = 0.711\n",
      "Epoch 918 Batch   50/100   train_loss = 0.594\n",
      "Epoch 918 Batch   75/100   train_loss = 0.655\n",
      "Epoch 919 Batch    0/100   train_loss = 0.560\n",
      "Epoch 919 Batch   25/100   train_loss = 0.645\n",
      "Epoch 919 Batch   50/100   train_loss = 0.606\n",
      "Epoch 919 Batch   75/100   train_loss = 0.642\n",
      "Epoch 920 Batch    0/100   train_loss = 0.554\n",
      "Epoch 920 Batch   25/100   train_loss = 0.623\n",
      "Epoch 920 Batch   50/100   train_loss = 0.628\n",
      "Epoch 920 Batch   75/100   train_loss = 0.635\n",
      "Epoch 921 Batch    0/100   train_loss = 0.533\n",
      "Epoch 921 Batch   25/100   train_loss = 0.648\n",
      "Epoch 921 Batch   50/100   train_loss = 0.626\n",
      "Epoch 921 Batch   75/100   train_loss = 0.596\n",
      "Epoch 922 Batch    0/100   train_loss = 0.552\n",
      "Epoch 922 Batch   25/100   train_loss = 0.673\n",
      "Epoch 922 Batch   50/100   train_loss = 0.586\n",
      "Epoch 922 Batch   75/100   train_loss = 0.604\n",
      "Epoch 923 Batch    0/100   train_loss = 0.562\n",
      "Epoch 923 Batch   25/100   train_loss = 0.675\n",
      "Epoch 923 Batch   50/100   train_loss = 0.630\n",
      "Epoch 923 Batch   75/100   train_loss = 0.600\n",
      "Epoch 924 Batch    0/100   train_loss = 0.532\n",
      "Epoch 924 Batch   25/100   train_loss = 0.669\n",
      "Epoch 924 Batch   50/100   train_loss = 0.559\n",
      "Epoch 924 Batch   75/100   train_loss = 0.624\n",
      "Epoch 925 Batch    0/100   train_loss = 0.540\n",
      "Epoch 925 Batch   25/100   train_loss = 0.661\n",
      "Epoch 925 Batch   50/100   train_loss = 0.589\n",
      "Epoch 925 Batch   75/100   train_loss = 0.598\n",
      "Epoch 926 Batch    0/100   train_loss = 0.546\n",
      "Epoch 926 Batch   25/100   train_loss = 0.685\n",
      "Epoch 926 Batch   50/100   train_loss = 0.583\n",
      "Epoch 926 Batch   75/100   train_loss = 0.623\n",
      "Epoch 927 Batch    0/100   train_loss = 0.553\n",
      "Epoch 927 Batch   25/100   train_loss = 0.687\n",
      "Epoch 927 Batch   50/100   train_loss = 0.556\n",
      "Epoch 927 Batch   75/100   train_loss = 0.618\n",
      "Epoch 928 Batch    0/100   train_loss = 0.504\n",
      "Epoch 928 Batch   25/100   train_loss = 0.678\n",
      "Epoch 928 Batch   50/100   train_loss = 0.586\n",
      "Epoch 928 Batch   75/100   train_loss = 0.668\n",
      "Epoch 929 Batch    0/100   train_loss = 0.491\n",
      "Epoch 929 Batch   25/100   train_loss = 0.662\n",
      "Epoch 929 Batch   50/100   train_loss = 0.598\n",
      "Epoch 929 Batch   75/100   train_loss = 0.603\n",
      "Epoch 930 Batch    0/100   train_loss = 0.539\n",
      "Epoch 930 Batch   25/100   train_loss = 0.695\n",
      "Epoch 930 Batch   50/100   train_loss = 0.608\n",
      "Epoch 930 Batch   75/100   train_loss = 0.631\n",
      "Epoch 931 Batch    0/100   train_loss = 0.540\n",
      "Epoch 931 Batch   25/100   train_loss = 0.650\n",
      "Epoch 931 Batch   50/100   train_loss = 0.570\n",
      "Epoch 931 Batch   75/100   train_loss = 0.650\n",
      "Epoch 932 Batch    0/100   train_loss = 0.538\n",
      "Epoch 932 Batch   25/100   train_loss = 0.662\n",
      "Epoch 932 Batch   50/100   train_loss = 0.580\n",
      "Epoch 932 Batch   75/100   train_loss = 0.623\n",
      "Epoch 933 Batch    0/100   train_loss = 0.523\n",
      "Epoch 933 Batch   25/100   train_loss = 0.680\n",
      "Epoch 933 Batch   50/100   train_loss = 0.569\n",
      "Epoch 933 Batch   75/100   train_loss = 0.642\n",
      "Epoch 934 Batch    0/100   train_loss = 0.569\n",
      "Epoch 934 Batch   25/100   train_loss = 0.647\n",
      "Epoch 934 Batch   50/100   train_loss = 0.589\n",
      "Epoch 934 Batch   75/100   train_loss = 0.636\n",
      "Epoch 935 Batch    0/100   train_loss = 0.558\n",
      "Epoch 935 Batch   25/100   train_loss = 0.667\n",
      "Epoch 935 Batch   50/100   train_loss = 0.596\n",
      "Epoch 935 Batch   75/100   train_loss = 0.645\n",
      "Epoch 936 Batch    0/100   train_loss = 0.533\n",
      "Epoch 936 Batch   25/100   train_loss = 0.676\n",
      "Epoch 936 Batch   50/100   train_loss = 0.589\n",
      "Epoch 936 Batch   75/100   train_loss = 0.628\n",
      "Epoch 937 Batch    0/100   train_loss = 0.510\n",
      "Epoch 937 Batch   25/100   train_loss = 0.677\n",
      "Epoch 937 Batch   50/100   train_loss = 0.592\n",
      "Epoch 937 Batch   75/100   train_loss = 0.605\n",
      "Epoch 938 Batch    0/100   train_loss = 0.569\n",
      "Epoch 938 Batch   25/100   train_loss = 0.678\n",
      "Epoch 938 Batch   50/100   train_loss = 0.566\n",
      "Epoch 938 Batch   75/100   train_loss = 0.608\n",
      "Epoch 939 Batch    0/100   train_loss = 0.548\n",
      "Epoch 939 Batch   25/100   train_loss = 0.678\n",
      "Epoch 939 Batch   50/100   train_loss = 0.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 939 Batch   75/100   train_loss = 0.631\n",
      "Epoch 940 Batch    0/100   train_loss = 0.519\n",
      "Epoch 940 Batch   25/100   train_loss = 0.654\n",
      "Epoch 940 Batch   50/100   train_loss = 0.587\n",
      "Epoch 940 Batch   75/100   train_loss = 0.610\n",
      "Epoch 941 Batch    0/100   train_loss = 0.580\n",
      "Epoch 941 Batch   25/100   train_loss = 0.653\n",
      "Epoch 941 Batch   50/100   train_loss = 0.558\n",
      "Epoch 941 Batch   75/100   train_loss = 0.621\n",
      "Epoch 942 Batch    0/100   train_loss = 0.536\n",
      "Epoch 942 Batch   25/100   train_loss = 0.680\n",
      "Epoch 942 Batch   50/100   train_loss = 0.568\n",
      "Epoch 942 Batch   75/100   train_loss = 0.608\n",
      "Epoch 943 Batch    0/100   train_loss = 0.552\n",
      "Epoch 943 Batch   25/100   train_loss = 0.670\n",
      "Epoch 943 Batch   50/100   train_loss = 0.594\n",
      "Epoch 943 Batch   75/100   train_loss = 0.623\n",
      "Epoch 944 Batch    0/100   train_loss = 0.528\n",
      "Epoch 944 Batch   25/100   train_loss = 0.647\n",
      "Epoch 944 Batch   50/100   train_loss = 0.596\n",
      "Epoch 944 Batch   75/100   train_loss = 0.584\n",
      "Epoch 945 Batch    0/100   train_loss = 0.552\n",
      "Epoch 945 Batch   25/100   train_loss = 0.633\n",
      "Epoch 945 Batch   50/100   train_loss = 0.591\n",
      "Epoch 945 Batch   75/100   train_loss = 0.637\n",
      "Epoch 946 Batch    0/100   train_loss = 0.514\n",
      "Epoch 946 Batch   25/100   train_loss = 0.653\n",
      "Epoch 946 Batch   50/100   train_loss = 0.558\n",
      "Epoch 946 Batch   75/100   train_loss = 0.613\n",
      "Epoch 947 Batch    0/100   train_loss = 0.542\n",
      "Epoch 947 Batch   25/100   train_loss = 0.659\n",
      "Epoch 947 Batch   50/100   train_loss = 0.586\n",
      "Epoch 947 Batch   75/100   train_loss = 0.612\n",
      "Epoch 948 Batch    0/100   train_loss = 0.532\n",
      "Epoch 948 Batch   25/100   train_loss = 0.665\n",
      "Epoch 948 Batch   50/100   train_loss = 0.593\n",
      "Epoch 948 Batch   75/100   train_loss = 0.627\n",
      "Epoch 949 Batch    0/100   train_loss = 0.546\n",
      "Epoch 949 Batch   25/100   train_loss = 0.631\n",
      "Epoch 949 Batch   50/100   train_loss = 0.582\n",
      "Epoch 949 Batch   75/100   train_loss = 0.616\n",
      "Epoch 950 Batch    0/100   train_loss = 0.519\n",
      "Epoch 950 Batch   25/100   train_loss = 0.649\n",
      "Epoch 950 Batch   50/100   train_loss = 0.604\n",
      "Epoch 950 Batch   75/100   train_loss = 0.614\n",
      "Epoch 951 Batch    0/100   train_loss = 0.524\n",
      "Epoch 951 Batch   25/100   train_loss = 0.662\n",
      "Epoch 951 Batch   50/100   train_loss = 0.582\n",
      "Epoch 951 Batch   75/100   train_loss = 0.632\n",
      "Epoch 952 Batch    0/100   train_loss = 0.531\n",
      "Epoch 952 Batch   25/100   train_loss = 0.655\n",
      "Epoch 952 Batch   50/100   train_loss = 0.595\n",
      "Epoch 952 Batch   75/100   train_loss = 0.604\n",
      "Epoch 953 Batch    0/100   train_loss = 0.538\n",
      "Epoch 953 Batch   25/100   train_loss = 0.628\n",
      "Epoch 953 Batch   50/100   train_loss = 0.573\n",
      "Epoch 953 Batch   75/100   train_loss = 0.641\n",
      "Epoch 954 Batch    0/100   train_loss = 0.520\n",
      "Epoch 954 Batch   25/100   train_loss = 0.657\n",
      "Epoch 954 Batch   50/100   train_loss = 0.592\n",
      "Epoch 954 Batch   75/100   train_loss = 0.599\n",
      "Epoch 955 Batch    0/100   train_loss = 0.524\n",
      "Epoch 955 Batch   25/100   train_loss = 0.626\n",
      "Epoch 955 Batch   50/100   train_loss = 0.575\n",
      "Epoch 955 Batch   75/100   train_loss = 0.593\n",
      "Epoch 956 Batch    0/100   train_loss = 0.531\n",
      "Epoch 956 Batch   25/100   train_loss = 0.640\n",
      "Epoch 956 Batch   50/100   train_loss = 0.565\n",
      "Epoch 956 Batch   75/100   train_loss = 0.557\n",
      "Epoch 957 Batch    0/100   train_loss = 0.548\n",
      "Epoch 957 Batch   25/100   train_loss = 0.666\n",
      "Epoch 957 Batch   50/100   train_loss = 0.558\n",
      "Epoch 957 Batch   75/100   train_loss = 0.613\n",
      "Epoch 958 Batch    0/100   train_loss = 0.528\n",
      "Epoch 958 Batch   25/100   train_loss = 0.665\n",
      "Epoch 958 Batch   50/100   train_loss = 0.604\n",
      "Epoch 958 Batch   75/100   train_loss = 0.573\n",
      "Epoch 959 Batch    0/100   train_loss = 0.504\n",
      "Epoch 959 Batch   25/100   train_loss = 0.668\n",
      "Epoch 959 Batch   50/100   train_loss = 0.562\n",
      "Epoch 959 Batch   75/100   train_loss = 0.607\n",
      "Epoch 960 Batch    0/100   train_loss = 0.513\n",
      "Epoch 960 Batch   25/100   train_loss = 0.629\n",
      "Epoch 960 Batch   50/100   train_loss = 0.531\n",
      "Epoch 960 Batch   75/100   train_loss = 0.599\n",
      "Epoch 961 Batch    0/100   train_loss = 0.535\n",
      "Epoch 961 Batch   25/100   train_loss = 0.672\n",
      "Epoch 961 Batch   50/100   train_loss = 0.568\n",
      "Epoch 961 Batch   75/100   train_loss = 0.599\n",
      "Epoch 962 Batch    0/100   train_loss = 0.512\n",
      "Epoch 962 Batch   25/100   train_loss = 0.677\n",
      "Epoch 962 Batch   50/100   train_loss = 0.556\n",
      "Epoch 962 Batch   75/100   train_loss = 0.599\n",
      "Epoch 963 Batch    0/100   train_loss = 0.507\n",
      "Epoch 963 Batch   25/100   train_loss = 0.663\n",
      "Epoch 963 Batch   50/100   train_loss = 0.577\n",
      "Epoch 963 Batch   75/100   train_loss = 0.579\n",
      "Epoch 964 Batch    0/100   train_loss = 0.560\n",
      "Epoch 964 Batch   25/100   train_loss = 0.663\n",
      "Epoch 964 Batch   50/100   train_loss = 0.583\n",
      "Epoch 964 Batch   75/100   train_loss = 0.622\n",
      "Epoch 965 Batch    0/100   train_loss = 0.484\n",
      "Epoch 965 Batch   25/100   train_loss = 0.650\n",
      "Epoch 965 Batch   50/100   train_loss = 0.567\n",
      "Epoch 965 Batch   75/100   train_loss = 0.596\n",
      "Epoch 966 Batch    0/100   train_loss = 0.535\n",
      "Epoch 966 Batch   25/100   train_loss = 0.678\n",
      "Epoch 966 Batch   50/100   train_loss = 0.557\n",
      "Epoch 966 Batch   75/100   train_loss = 0.594\n",
      "Epoch 967 Batch    0/100   train_loss = 0.548\n",
      "Epoch 967 Batch   25/100   train_loss = 0.658\n",
      "Epoch 967 Batch   50/100   train_loss = 0.566\n",
      "Epoch 967 Batch   75/100   train_loss = 0.587\n",
      "Epoch 968 Batch    0/100   train_loss = 0.486\n",
      "Epoch 968 Batch   25/100   train_loss = 0.668\n",
      "Epoch 968 Batch   50/100   train_loss = 0.552\n",
      "Epoch 968 Batch   75/100   train_loss = 0.575\n",
      "Epoch 969 Batch    0/100   train_loss = 0.544\n",
      "Epoch 969 Batch   25/100   train_loss = 0.654\n",
      "Epoch 969 Batch   50/100   train_loss = 0.588\n",
      "Epoch 969 Batch   75/100   train_loss = 0.604\n",
      "Epoch 970 Batch    0/100   train_loss = 0.532\n",
      "Epoch 970 Batch   25/100   train_loss = 0.665\n",
      "Epoch 970 Batch   50/100   train_loss = 0.586\n",
      "Epoch 970 Batch   75/100   train_loss = 0.609\n",
      "Epoch 971 Batch    0/100   train_loss = 0.502\n",
      "Epoch 971 Batch   25/100   train_loss = 0.649\n",
      "Epoch 971 Batch   50/100   train_loss = 0.528\n",
      "Epoch 971 Batch   75/100   train_loss = 0.616\n",
      "Epoch 972 Batch    0/100   train_loss = 0.507\n",
      "Epoch 972 Batch   25/100   train_loss = 0.664\n",
      "Epoch 972 Batch   50/100   train_loss = 0.563\n",
      "Epoch 972 Batch   75/100   train_loss = 0.571\n",
      "Epoch 973 Batch    0/100   train_loss = 0.501\n",
      "Epoch 973 Batch   25/100   train_loss = 0.633\n",
      "Epoch 973 Batch   50/100   train_loss = 0.567\n",
      "Epoch 973 Batch   75/100   train_loss = 0.568\n",
      "Epoch 974 Batch    0/100   train_loss = 0.506\n",
      "Epoch 974 Batch   25/100   train_loss = 0.642\n",
      "Epoch 974 Batch   50/100   train_loss = 0.573\n",
      "Epoch 974 Batch   75/100   train_loss = 0.592\n",
      "Epoch 975 Batch    0/100   train_loss = 0.519\n",
      "Epoch 975 Batch   25/100   train_loss = 0.646\n",
      "Epoch 975 Batch   50/100   train_loss = 0.545\n",
      "Epoch 975 Batch   75/100   train_loss = 0.594\n",
      "Epoch 976 Batch    0/100   train_loss = 0.499\n",
      "Epoch 976 Batch   25/100   train_loss = 0.641\n",
      "Epoch 976 Batch   50/100   train_loss = 0.546\n",
      "Epoch 976 Batch   75/100   train_loss = 0.587\n",
      "Epoch 977 Batch    0/100   train_loss = 0.490\n",
      "Epoch 977 Batch   25/100   train_loss = 0.659\n",
      "Epoch 977 Batch   50/100   train_loss = 0.550\n",
      "Epoch 977 Batch   75/100   train_loss = 0.591\n",
      "Epoch 978 Batch    0/100   train_loss = 0.487\n",
      "Epoch 978 Batch   25/100   train_loss = 0.670\n",
      "Epoch 978 Batch   50/100   train_loss = 0.577\n",
      "Epoch 978 Batch   75/100   train_loss = 0.577\n",
      "Epoch 979 Batch    0/100   train_loss = 0.503\n",
      "Epoch 979 Batch   25/100   train_loss = 0.655\n",
      "Epoch 979 Batch   50/100   train_loss = 0.544\n",
      "Epoch 979 Batch   75/100   train_loss = 0.597\n",
      "Epoch 980 Batch    0/100   train_loss = 0.524\n",
      "Epoch 980 Batch   25/100   train_loss = 0.645\n",
      "Epoch 980 Batch   50/100   train_loss = 0.610\n",
      "Epoch 980 Batch   75/100   train_loss = 0.577\n",
      "Epoch 981 Batch    0/100   train_loss = 0.506\n",
      "Epoch 981 Batch   25/100   train_loss = 0.621\n",
      "Epoch 981 Batch   50/100   train_loss = 0.560\n",
      "Epoch 981 Batch   75/100   train_loss = 0.583\n",
      "Epoch 982 Batch    0/100   train_loss = 0.512\n",
      "Epoch 982 Batch   25/100   train_loss = 0.631\n",
      "Epoch 982 Batch   50/100   train_loss = 0.596\n",
      "Epoch 982 Batch   75/100   train_loss = 0.561\n",
      "Epoch 983 Batch    0/100   train_loss = 0.518\n",
      "Epoch 983 Batch   25/100   train_loss = 0.655\n",
      "Epoch 983 Batch   50/100   train_loss = 0.574\n",
      "Epoch 983 Batch   75/100   train_loss = 0.598\n",
      "Epoch 984 Batch    0/100   train_loss = 0.503\n",
      "Epoch 984 Batch   25/100   train_loss = 0.635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984 Batch   50/100   train_loss = 0.572\n",
      "Epoch 984 Batch   75/100   train_loss = 0.577\n",
      "Epoch 985 Batch    0/100   train_loss = 0.497\n",
      "Epoch 985 Batch   25/100   train_loss = 0.665\n",
      "Epoch 985 Batch   50/100   train_loss = 0.555\n",
      "Epoch 985 Batch   75/100   train_loss = 0.594\n",
      "Epoch 986 Batch    0/100   train_loss = 0.493\n",
      "Epoch 986 Batch   25/100   train_loss = 0.640\n",
      "Epoch 986 Batch   50/100   train_loss = 0.558\n",
      "Epoch 986 Batch   75/100   train_loss = 0.611\n",
      "Epoch 987 Batch    0/100   train_loss = 0.520\n",
      "Epoch 987 Batch   25/100   train_loss = 0.630\n",
      "Epoch 987 Batch   50/100   train_loss = 0.563\n",
      "Epoch 987 Batch   75/100   train_loss = 0.608\n",
      "Epoch 988 Batch    0/100   train_loss = 0.499\n",
      "Epoch 988 Batch   25/100   train_loss = 0.661\n",
      "Epoch 988 Batch   50/100   train_loss = 0.575\n",
      "Epoch 988 Batch   75/100   train_loss = 0.610\n",
      "Epoch 989 Batch    0/100   train_loss = 0.523\n",
      "Epoch 989 Batch   25/100   train_loss = 0.612\n",
      "Epoch 989 Batch   50/100   train_loss = 0.604\n",
      "Epoch 989 Batch   75/100   train_loss = 0.584\n",
      "Epoch 990 Batch    0/100   train_loss = 0.533\n",
      "Epoch 990 Batch   25/100   train_loss = 0.635\n",
      "Epoch 990 Batch   50/100   train_loss = 0.500\n",
      "Epoch 990 Batch   75/100   train_loss = 0.590\n",
      "Epoch 991 Batch    0/100   train_loss = 0.501\n",
      "Epoch 991 Batch   25/100   train_loss = 0.626\n",
      "Epoch 991 Batch   50/100   train_loss = 0.572\n",
      "Epoch 991 Batch   75/100   train_loss = 0.602\n",
      "Epoch 992 Batch    0/100   train_loss = 0.496\n",
      "Epoch 992 Batch   25/100   train_loss = 0.639\n",
      "Epoch 992 Batch   50/100   train_loss = 0.547\n",
      "Epoch 992 Batch   75/100   train_loss = 0.587\n",
      "Epoch 993 Batch    0/100   train_loss = 0.526\n",
      "Epoch 993 Batch   25/100   train_loss = 0.605\n",
      "Epoch 993 Batch   50/100   train_loss = 0.564\n",
      "Epoch 993 Batch   75/100   train_loss = 0.584\n",
      "Epoch 994 Batch    0/100   train_loss = 0.514\n",
      "Epoch 994 Batch   25/100   train_loss = 0.653\n",
      "Epoch 994 Batch   50/100   train_loss = 0.540\n",
      "Epoch 994 Batch   75/100   train_loss = 0.565\n",
      "Epoch 995 Batch    0/100   train_loss = 0.491\n",
      "Epoch 995 Batch   25/100   train_loss = 0.641\n",
      "Epoch 995 Batch   50/100   train_loss = 0.573\n",
      "Epoch 995 Batch   75/100   train_loss = 0.614\n",
      "Epoch 996 Batch    0/100   train_loss = 0.489\n",
      "Epoch 996 Batch   25/100   train_loss = 0.662\n",
      "Epoch 996 Batch   50/100   train_loss = 0.589\n",
      "Epoch 996 Batch   75/100   train_loss = 0.555\n",
      "Epoch 997 Batch    0/100   train_loss = 0.516\n",
      "Epoch 997 Batch   25/100   train_loss = 0.645\n",
      "Epoch 997 Batch   50/100   train_loss = 0.555\n",
      "Epoch 997 Batch   75/100   train_loss = 0.603\n",
      "Epoch 998 Batch    0/100   train_loss = 0.560\n",
      "Epoch 998 Batch   25/100   train_loss = 0.669\n",
      "Epoch 998 Batch   50/100   train_loss = 0.583\n",
      "Epoch 998 Batch   75/100   train_loss = 0.567\n",
      "Epoch 999 Batch    0/100   train_loss = 0.529\n",
      "Epoch 999 Batch   25/100   train_loss = 0.637\n",
      "Epoch 999 Batch   50/100   train_loss = 0.543\n",
      "Epoch 999 Batch   75/100   train_loss = 0.581\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "batches = get_batches(int_text, batch_size, seq_length)\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(num_epochs):\n",
    "        state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "        for batch_i, (x, y) in enumerate(batches):\n",
    "            feed = {\n",
    "                input_text: x,\n",
    "                targets: y,\n",
    "                initial_state: state,\n",
    "                lr: learning_rate}\n",
    "            train_loss, state, _ = sess.run([cost, final_state, train_op], feed)\n",
    "\n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    len(batches),\n",
    "                    train_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_dir)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Parameters\n",
    "Save `seq_length` and `save_dir` for generating a new TV script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params((seq_length, save_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "seq_length, load_dir = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Generate Functions\n",
    "### Get Tensors\n",
    "Get tensors from `loaded_graph` using the function [`get_tensor_by_name()`](https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name).  Get the tensors using the following names:\n",
    "- \"input:0\"\n",
    "- \"initial_state:0\"\n",
    "- \"final_state:0\"\n",
    "- \"probs:0\"\n",
    "\n",
    "Return the tensors in the following tuple `(InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "    \"\"\"\n",
    "    Get input, initial state, final state, and probabilities tensor from <loaded_graph>\n",
    "    :param loaded_graph: TensorFlow graph loaded from file\n",
    "    :return: Tuple (InputTensor, InitialStateTensor, FinalStateTensor, ProbsTensor)\n",
    "    \"\"\"\n",
    "    # Get tensors from loaded_graph\n",
    "    input_tensor = loaded_graph.get_tensor_by_name(name=\"input:0\")\n",
    "    initial_state_tensor = loaded_graph.get_tensor_by_name(\"initial_state:0\")\n",
    "    final_state = loaded_graph.get_tensor_by_name(\"final_state:0\")\n",
    "    probs_tensor = loaded_graph.get_tensor_by_name(\"probs:0\")\n",
    "    return (input_tensor, initial_state_tensor, final_state, probs_tensor)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_tensors(get_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Word\n",
    "Implement the `pick_word()` function to select the next word using `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def pick_word(probabilities, int_to_vocab):\n",
    "    \"\"\"\n",
    "    Pick the next word in the generated text\n",
    "    :param probabilities: Probabilites of the next word\n",
    "    :param int_to_vocab: Dictionary of word ids as the keys and words as the values\n",
    "    :return: String of the predicted word\n",
    "    \"\"\"\n",
    "    # Get five highest values in probabilities\n",
    "    highest_prob_indexes = probabilities.argsort()[-5:]\n",
    "    \n",
    "    # Get random index\n",
    "    random_index = np.random.randint(4)\n",
    "    \n",
    "    # Use variables above to randomly find a word in dict\n",
    "    next_word = int_to_vocab[highest_prob_indexes[random_index]]\n",
    "    return next_word\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_pick_word(pick_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TV Script\n",
    "This will generate the TV script for you.  Set `gen_length` to the length of TV script you want to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "moe_szyslak: yeah. / canyonero we is whip than sick and of it's two for as my best fault could have i been her fraud with?(turns noise in world gun game job i haven't) see you your heard soon of this works in. car at isn't that's and buy one for your don\n",
      "dr!\n",
      "barney_gumble: you went from moe in! the can school door off his\". homer_simpson: up here all over i would just\n",
      "homer_simpson: you'll could go home! i drink or run this beer now\n",
      "here about brain? your romantic. one lousy lessons. for about my plant today? but drawin'\n",
      "bart_simpson: that back(arguing smile, in any outside. moe_szyslak: y'know vance can win-- i wearin' in the election people money who? us it was in, more whaaa!..(gary_chalmers: bar soon! you're things full a tough blood all over around for problems, lovers'(delighted months!\"\n",
      "gator: some.(air man ain't on) plastic and your telephone with till an bright were at me?\n"
     ]
    }
   ],
   "source": [
    "gen_length = 200\n",
    "# homer_simpson, moe_szyslak, or Barney_Gumble\n",
    "prime_word = 'moe_szyslak'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
    "\n",
    "    # Sentences generation setup\n",
    "    gen_sentences = [prime_word + ':']\n",
    "    prev_state = sess.run(initial_state, {input_text: np.array([[1]])})\n",
    "\n",
    "    # Generate sentences\n",
    "    for n in range(gen_length):\n",
    "        # Dynamic Input\n",
    "        dyn_input = [[vocab_to_int[word] for word in gen_sentences[-seq_length:]]]\n",
    "        dyn_seq_length = len(dyn_input[0])\n",
    "\n",
    "        # Get Prediction\n",
    "        probabilities, prev_state = sess.run(\n",
    "            [probs, final_state],\n",
    "            {input_text: dyn_input, initial_state: prev_state})\n",
    "        \n",
    "        pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab)\n",
    "\n",
    "        gen_sentences.append(pred_word)\n",
    "    \n",
    "    # Remove tokens\n",
    "    tv_script = ' '.join(gen_sentences)\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
    "    tv_script = tv_script.replace('\\n ', '\\n')\n",
    "    tv_script = tv_script.replace('( ', '(')\n",
    "        \n",
    "    print(tv_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TV Script is Nonsensical\n",
    "It's ok if the TV script doesn't make any sense.  We trained on less than a megabyte of text.  In order to get good results, you'll have to use a smaller vocabulary or get more data.  Luckily there's more data!  As we mentioned in the beggining of this project, this is a subset of [another dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data).  We didn't have you train on all the data, because that would take too long.  However, you are free to train your neural network on all the data.  After you complete the project, of course.\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
